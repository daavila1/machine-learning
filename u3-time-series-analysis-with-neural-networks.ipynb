{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["HvcNgfF1cDb4"],"toc_visible":true,"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fb9pUStUq6xf"},"source":["<img src = \"https://drive.google.com/uc?export=view&id=1z-EW8gVlIg4Zcp_HvN-BElP0KknNnfML\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"]},{"cell_type":"markdown","metadata":{"id":"6_GpZz1CNKaU"},"source":["# **Análisis de series de tiempo con redes neuronales**\n","---\n","En este material se presentarán las redes neuronales y, en particular, la implementación de un perceptrón multicapa con *Scikit-Learn*. Además, y para poner a prueba este tipo de modelo, se planteará un problema de análisis de series de tiempo, y se entrenará y evaluará un modelo para este proceso."]},{"cell_type":"markdown","metadata":{"id":"i0sRGgMB2FUF"},"source":["# **1. Dependencias**\n","---\n","Importamos las librerías necesarias y definimos algunas funciones básicas de visualización que vamos a usar en algunos ejemplos.\n"]},{"cell_type":"markdown","metadata":{"id":"qJgGczNUDVUN"},"source":["### **1.1. Dependencias**\n","---\n","Para la construcción de modelos y ejecución de procedimientos metodológicos de aprendizaje automático, utilizaremos la librería **Scikit-learn** (**`sklearn`**) y varias de sus funciones y conjuntos de datos."]},{"cell_type":"code","metadata":{"id":"1A1bWvdAsW_B"},"source":["# Actualizamos scikit-learn a la última versión\n","!pip install -U scikit-learn\n","\n","# Importamos scikit-learn\n","import sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JX8QpYhEsc4H"},"source":["Importamos además algunas librerías básicas y configuraciones de *Python*."]},{"cell_type":"code","metadata":{"id":"H5lk0elTiFy_"},"source":["# Librerías básicas NumPy, Pandas, Matplotlib y Seaborn.\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import seaborn as sns\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nmx-RGqF8Hls"},"source":["# Configuraciones para las librerías y módulos usados.\n","\n","# Ignoramos las advertencias o warnings.\n","import warnings\n","warnings.simplefilter(action='ignore')\n","\n","# Configuramos el formato por defecto de la\n","# librería de visualización Matplotlib.\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","mpl.rcParams['figure.dpi'] = 105\n","mpl.rcParams['figure.figsize'] = (9, 7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV_LBKWqukUV"},"source":["Utilizaremos *Plotly* para generar visualizaciones interactivas."]},{"cell_type":"code","metadata":{"id":"zikZ90RO0hZq"},"source":["!pip install -U plotly\n","import plotly\n","import plotly.graph_objects as go"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxNzX3sfq3gZ"},"source":["Este material se realizó con las siguientes versiones:\n","*  *Python*: 3.7.10\n","*  *Scikit-learn*: 0.24.1\n","*  *NumPy*:  1.19.5\n","*  *Pandas*:  1.1.5\n","*  *Matplotlib*:  3.2.2\n","*  *Seaborn*:  0.11.1\n","*  *Plotly*: 4.14.3"]},{"cell_type":"code","metadata":{"id":"jUMP_2CPqwRY"},"source":["# Versión de Python y las demás librerías.\n","!python --version\n","print('Scikit-learn', sklearn.__version__)\n","print('NumPy', np.__version__)\n","print('Pandas', pd.__version__)\n","print('Matplotlib', mpl.__version__)\n","print('Seaborn', sns.__version__)\n","print('Plotly', plotly.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJkrA1ustgup"},"source":["### **1.2. Funciones de utilidad y visualización**\n","---\n","\n","Para ilustrar los ejemplos discutidos en este material utilizaremos algunas funciones que permiten visualizar de manera general los datos, junto a las funciones de predicción obtenidas con cada modelo.\n","\n","> **Nota**: *Matplotlib* y *Seaborn* se encuentran por fuera del alcance de este módulo. No es necesario que entienda estas funciones en detalle para sacar partido del resto del contenido puesto a su disposición. Usted decide si leer o no estas funciones en profundidad. Si decide omitir esta sección, continúe directamente con la siguiente sección, en donde se discutirán los conjuntos de datos que vamos a utilizar."]},{"cell_type":"code","metadata":{"id":"MFDXpdM-ps_1"},"source":["# Función para visualizar un conjunto de datos de dos variables en un plano 2D.\n","def plot_data(X, y, model = None, ax = None, title=None):\n","\n","    if ax is None:\n","      _, ax = plt.subplots(dpi = 110)\n","\n","    if model is not None:\n","      pred_fun = gen_pred_fun(model)\n","      plot_decision_region(X, pred_fun, ax)\n","\n","    y_unique = np.unique(y)\n","    df = pd.DataFrame({'x1': X[:,0], 'x2': X[:,1], 'Clases': y})\n","    sns.set_theme()\n","    sns.scatterplot(data = df, x = 'x1', y = 'x2',\n","                    hue = 'Clases',style = 'Clases', ax = ax, palette = 'Set1').set_title(title)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZZQ_8SFDWcb"},"source":["# Función para visualizar la superficie de decisión de un clasificador.\n","def plot_decision_region(X, pred_fun, ax=None):\n","    min_x, max_x = np.min(X[:, 0]), np.max(X[:, 0])\n","    min_y, max_y = np.min(X[:, 1]), np.max(X[:, 1])\n","\n","    min_x = min_x - (max_x - min_x) * 0.05\n","    max_x = max_x + (max_x - min_x) * 0.05\n","    min_y = min_y - (max_y - min_y) * 0.05\n","    max_y = max_y + (max_y - min_y) * 0.05\n","\n","    x_vals = np.linspace(min_x, max_x, 100)\n","    y_vals = np.linspace(min_y, max_y, 100)\n","\n","    XX, YY = np.meshgrid(x_vals, y_vals)\n","    grid_r, grid_c = XX.shape\n","\n","    ZZ = np.zeros((grid_r, grid_c))\n","\n","    for i in range(grid_r):\n","        for j in range(grid_c):\n","            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n","\n","    cs = ax.contourf(XX, YY, ZZ, 100, cmap = plt.cm.Pastel1, vmin = 0, vmax = np.max(ZZ)* 9. / (np.max(ZZ) + 1), alpha = 0.75)\n","    ax.get_figure().colorbar(cs, ax=ax, )\n","    ax.set_xlabel(\"x\")\n","    ax.set_ylabel(\"y\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSfViWX6DcEY"},"source":["#Función para generar la función de predicción de un clasificador entrenado previamente.\n","def gen_pred_fun(clf):\n","    def pred_fun(x1, x2):\n","        x = np.array([[x1, x2]])\n","        return clf.predict(x)[0]\n","    return pred_fun"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOB30VXP-95x"},"source":["# Gráficar la predicción de los datos de temperatura.\n","\n","def plot_prediction(params, ys, test_date_index):\n","\n","  train_data = mintemp.loc[:test_date_index[0]]\n","  _y_test, _y_forward, _y_last = ys\n","  # Graficamos los valores predichos.\n","  fig = go.Figure(layout = dict(\n","       title = f'<b>Temperaturas medias semanales (1981-1990)</b> <br> {params}',\n","       dragmode= 'pan', width = 1200, height = 600))\n","\n","  fig.add_trace(go.Scatter(x = train_data.index,  # Datos originales hasta la primer semana predicha. (fechas)\n","                          y = train_data.values, # Datos originales hasta la primer semana predicha. (temperaturas)\n","                          mode = 'lines',\n","                          name = 'Valores de entrenamiento y pruebas'))\n","\n","  #Gráfica de los valores de prueba reales.\n","  fig.add_trace(go.Scatter(x = test_date_index,\n","                          y = _y_test,\n","                          mode='lines+markers',\n","                          name='Valores reales (y)'))\n","\n","\n","  #Gráfica de los valores predichos a partir de las ventanas de X_test.\n","  fig.add_trace(go.Scatter(x = test_date_index,\n","                          y = _y_forward,\n","                          mode = 'lines+markers',\n","                          name = 'Valores predichos a partir de datos reales'))\n","\n","  #Gráfica de los valores predichos a partir de ventanas creadas proceduralmente.\n","  fig.add_trace(go.Scatter(x = test_date_index,\n","                          y = _y_last,\n","                          mode='lines+markers',\n","                          name='Valores predichos a partir de datos predichos'))\n","\n","  fig.show(config = dict({'scrollZoom': True}))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RURwOVpHIb2P"},"source":["# **2. Conjuntos de datos**\n","---\n","\n","Para los ejemplos desarrollados en el transcurso de material, se usarán datos de  *Scikit-Learn* de carácter real (usando *Loaders*) y sintético (usando *Generators*)."]},{"cell_type":"markdown","metadata":{"id":"D0LuNr1jTrE-"},"source":["## **2.1. Conjunto de datos *Iris***\n","---\n","\n","En este material retomaremos el conjunto de datos *Iris* para ilustrar algunos ejemplos. Para esto, usaremos la función **`load_iris`** de *Scikit-Learn*."]},{"cell_type":"code","metadata":{"id":"1E4zU826S9mD"},"source":["# Loader del dataset iris\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","\n","X = iris.data\n","y = iris.target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwCxXcaMTRhS"},"source":["# Información general del conjunto.\n","\n","print(f'X ~ {X.shape[0]} muestras x {X.shape[1]} características.')\n","print(f'y ~ {y.shape[0]} muestras.')\n","print('\\nPrimeras 5 muestras:\\n', X[:5, :])\n","print('\\nPrimeras 5 etiquetas:\\n', y[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq-HxHnvTRhV"},"source":["#Graficamos en un área 2d\n","plot_data(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bITZMX0DRvFt"},"source":["## **2.2. Conjunto de datos sintético**\n","---\n","Además de *Iris*, vamos a trabajar con el conjunto de datos artificiales ***moons***. Para cargarlo usaremos la siguiente función:\n","\n","  * **`make_moons`**: Este conjunto de datos artificial genera dos variables asociadas a dos clases que representan dos medias lunas. *Scikit-Learn* permite a su vez introducir algo de ruido sobre las muestras creadas.\n"]},{"cell_type":"code","metadata":{"id":"PFxnv30KRvFx"},"source":["# Conjunto de datos sintético moons.\n","from sklearn.datasets import make_moons\n","\n","X, y = make_moons(n_samples=600,\n","                    noise=0.1,\n","                    random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ughx7e2lRvF4"},"source":["# Información general del conjunto.\n","print(f'X ~ {X.shape[0]} muestras x {X.shape[1]} características.')\n","print(f'y ~ {y.shape[0]} muestras.')\n","print('\\nPrimeras 5 muestras:\\n', X[:5, :])\n","print('\\nPrimeras 5 etiquetas:\\n', y[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3VglYMLRvGB"},"source":["# Graficamos en un área 2d.\n","plot_data(X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0RudrJngWDN_"},"source":["## **2.3. Conjunto de datos de temperaturas mínimas diarias**\n","---\n","\n","Para este material, en la sección de análisis de series de tiempo, utilizaremos el *dataset* [***Minimum Daily Temperatures***](https://www.kaggle.com/paulbrabban/daily-minimum-temperatures-in-melbourne). Este *dataset* almacena la temperatura mínima diaria (C°) en la ciudad de Melbourne, Australia en un periodo de 10 años, desde 1981 hasta 1990. En esta ocasión usaremos una versión distinta, que toma las medias semanales de temperatura mínima de estos datos.\n","\n","> Estos datos fueron tomados del siguiente enlace de [*Machine Learning Mastery*](https://github.com/jbrownlee/Datasets/blob/master/README.md), reprocesados con las medias semanales y fueron recopilados originalmente por *Australian Bureau of Meteorology*. La siguiente celda descarga el archivo:"]},{"cell_type":"code","metadata":{"id":"aLaSUvruWDOB","cellView":"form"},"source":["#@markdown **Ejecute esta celda para descargar el archivo en una serie.**\n","\n","url = 'https://drive.google.com/uc?export=download&id=1XvKsdBs6EG463iN3L1lQv9JXd9lW0JJC'\n","\n","mintemp = pd.read_csv(url, index_col = 0, parse_dates= True, squeeze = True)\n","mintemp.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoHmV4qSiFzf"},"source":["# **3. Red neuronal artificial**\n","---\n","\n","El perceptrón multicapa (*Multilayer Perceptron*, MLP en inglés) es un tipo especial de red neuronal artificial en el cual se apilan varias capas de neuronas artificiales o perceptrones. En inglés también se le denomina como ***Feedforward neural network***.\n","\n","El perceptrón multicapa está motivado por la poca capacidad del perceptrón sencillo de modelar funciones no lineales. En un *MLP* agrupamos tantas capas como necesitemos.\n","<center>\n","<img src=\"https://drive.google.com/uc?export=view&id=1DFV06d4-aMlCrXAiCuzOgB_0zbptGJI6\" align=\"middle\">\n","</center>\n","\n","Una red neuronal multicapa está generalmente conformada por:\n","\n","* **Capa de entrada:** recibe los datos de entrada.\n","* **Capa oculta:** cuenta con una o más neuronas.\n","* **Capa de activación:** aplica una función de activación sobre la salida de cada neurona de la capa oculta.\n","* **Cada de salida:** produce la predicción para completar la tarea supervisada. Puede ser de clasificación o regresión.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x1Cml8udiFzh"},"source":["## **3.1. Implementación con *Scikit-Learn***\n","---\n","\n","*Scikit-Learn* nos permite trabajar con redes de perceptrones multicapa usando **`sklearn.neural_network.MLPClassifier`**. Una red multicapa se puede entrenar usando **gradiente descendente**, y por tanto, se pueden usar métodos como **gradiente descendente estocástico** (**`sgd`**) u otros métodos de optimización. Cómo se describió en materiales anteriores, el valor del gradiente determina qué tanto debo modificar los pesos de la red o parámetros entrenables para resolver la tarea de predicción.\n","\n","\n","**`MLPClassifier`** permite definir esta arquitectura de la siguiente manera:\n","\n","* **Capa de entrada**: El tamaño de la capa de entrada es definido cuando se llama a la función **`fit()`**. El tamaño está definido por el número de características (o columnas) de la matriz de características `X`.\n","* **Capa(s) ocultas**: El número de capas ocultas y el tamaño de cada una es definido por el parámetro **`hidden_layer_size`** de la clase **`MLPClassifier`**. Este parámetro consiste en una tupla de $n$ elementos, donde $n$ es igual al número de capas ocultas. Cada elemento de la tupla determina el número de neuronas de esa capa oculta.\n","* **Función de activación**: Esta función se define usando el parámetro **`activation`**. Este parámetro puede tomar como valor las cadenas de texto **`logistic`**, **`relu`**, **`tanh`** o **`identity`**.\n"]},{"cell_type":"code","metadata":{"id":"y8AxX7V2uviM","cellView":"form"},"source":["#@markdown **Visualización**: funciones de activación posibles como hiperparámetros de **`MLPClassifier`**.\n","# Funciones de activación posibles\n","\n","from google.colab import widgets\n","tb = widgets.TabBar(['logistic', 'relu', 'tanh', 'identity'])\n","\n","x = np.linspace(-5,5, 1000)\n","\n","logistic = 1 / (1 + np.exp(-x))\n","relu = np.maximum(0, x)\n","tanh = np.tanh(x)\n","identity = x\n","\n","functions = [logistic, relu, tanh, identity]\n","titles = [r'Sigmoide logístico - $\\frac{1}{1 + \\exp{-x}}$',\n","          r'ReLU - $max(x, 0)$',\n","          'Tangente hiperbólico - $tanh(x)$',\n","          'Identidad - $x$']\n","\n","font = {'family': 'serif',\n","        'weight': 'normal',\n","        'size': 16}\n","\n","for i, function, title in zip(range(4), functions, titles):\n","  with tb.output_to(i, select= (i < 1)):\n","    fig, ax = plt.subplots(figsize = (9, 7), dpi = 105)\n","    ax.plot(x, function); ax.set_title(title, fontdict= font);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uys36bC4utdK"},"source":["* **Capa de salida**: Se define cuando se llama a la función **`fit()`**. La capa de salida contiene una única neurona, cuya función de activación se define con base al tipo de tarea de clasificación. Si es una tarea de clasificación binaria usa una función de activación logística. Si la tarea es multiclase se usa una función de activación *SoftMax*.\n","\n","Adicionalmente **`MLPClassifier`** recibe los siguientes parámetros:\n","\n","* **`solver`**: Puede ser **`lbfgs`**, **`sgd`** o **`adam`**. El *solver* *lbfgs* es una técnica de optimización muy útil para conjuntos pequeños, mientras que *sgd* y *adam* usan gradiente descendente estocástico y son apropiados para conjuntos de datos grandes.\n","* **`alpha`**: El parámetro $\\alpha$ representa el parámetro de regularización y permite penalizar aquellos pesos $w$ grandes."]},{"cell_type":"code","metadata":{"id":"onh2KV6EiFzi"},"source":["# Cargamos los datos en formato X, y\n","iris = load_iris()\n","X_iris = iris.data[:,[0, 2]]\n","y_iris = iris.target\n","\n","X_moons, y_moons = make_moons(n_samples=600,   # Número de observaciones o muestras.\n","                              noise=0.15,      # Cantidad de ruido aleatorio introducido.\n","                              random_state=0)  # Semilla aleatoria para garantizar la replicabilidad."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHqidnWpbAiO"},"source":["# Clasificador basado en una red neuronal multicapa.\n","from sklearn.neural_network import MLPClassifier\n","\n","# Clasificador para el conjunto Iris\n","clf_iris = MLPClassifier(solver='sgd', # Descenso del gradiente estocástico.\n","                    learning_rate='constant', # Tipo de tasa de aprendizaje.\n","                    learning_rate_init=0.001, # Tasa de aprendizaje inicial.\n","                    activation='relu', # Función de activación.\n","                                       # En este caso se usa la función de rectificación\n","                                       # lineal uniforme \"y = max(0, x)\"\n","                    max_iter=1000, # Iteraciones máximas\n","                    tol= 1e-4,          # Valor de tolerancia de la optimización.\n","                    hidden_layer_sizes=(10, 10)) # Tamaño de las capas ocultas."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktYyAEF4a1L-"},"source":["# Entrenamiento del modelo. Este proceso puede tardar.\n","\n","clf_iris.fit(X_iris, y_iris)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VreWsDT3MvRU"},"source":["Podemos observar la evolución del error de entrenamiento durante el proceso de optimización usando el atributo **`loss_curve`**."]},{"cell_type":"code","metadata":{"id":"ytJuuG2GBZr-"},"source":["# Curva de la función de pérdida del clasificador.\n","plt.figure(dpi = 120)\n","plt.ylabel('Error cuadrático medio')\n","plt.xlabel('Epochs')\n","plt.plot(clf_iris.loss_curve_);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zPbio9owFKR_"},"source":["Evaluamos el desempeño del clasificador sobre el conjunto de datos:"]},{"cell_type":"code","metadata":{"id":"FZ5vEOBEiFzm"},"source":["clf_iris.score(X_iris, y_iris)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSxNg9HrFKSU"},"source":["Visualizamos la superficie de decisión:"]},{"cell_type":"code","metadata":{"id":"x52AHSmUiFzq"},"source":["plot_data(X_iris, y_iris, clf_iris)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZkVs5A1BbuIZ"},"source":["Ahora, realizaremos el mismo proceso con los datos del *dataset* **moons**."]},{"cell_type":"code","metadata":{"id":"a2aFzIpNbtZq"},"source":["# Clasificador para el conjunto moons\n","clf_moons = MLPClassifier(solver='lbfgs', # Método recomendado para datasets pequeños.\n","                    activation='tanh',    # Función de activación. En este caso se usa la función tangente hiperbólica, con valores entre -1 y 1.\n","                    max_iter=1000,        # Cantidad máxima de iteraciones permitidas\n","                    tol=1e-4, # Tolerancia de la optimización. Si en una iteración no mejora el modelo por esta cantidad (score) se detiene la ejecución.\n","                    hidden_layer_sizes=(3, 3)) # Número de neuronas por cada capa oculta."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Xs3UYPn8Ec3"},"source":["# Entrenamiento del modelo. Este proceso puede tardar.\n","clf_moons.fit(X_moons, y_moons)\n","print(clf_moons.score(X_moons, y_moons))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVwqG0aD8IHN"},"source":["# Graficamos los resultados.\n","plot_data(X_moons, y_moons, clf_moons)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qdVL4SrpiFzt"},"source":["**`MLPClassifier`** también nos permite acceder a la matriz de parámetros $w$ y a los sesgos $w_0$. El atributo **`coefs_`** nos regresa una lista que corresponde a los parámetros aprendidos. A continuación, verificamos el tamaño de cada matriz y su respectivo valor:"]},{"cell_type":"code","metadata":{"id":"w6ojSz-EiFzt"},"source":["print([a.shape for a in clf_moons.coefs_])\n","for coefs_row in clf_moons.coefs_:\n","  print(coefs_row)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-FOv2tPOiFzw"},"source":["Para acceder a los sesgos, se puede usar **`.intercepts_`**"]},{"cell_type":"code","metadata":{"id":"ewIYwSFciFzx"},"source":["print([a.shape for a in clf_moons.intercepts_])\n","for intercept in clf_moons.intercepts_:\n","  print(intercept)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oe6bOOYZiFzz"},"source":["## **3.2. Ventajas y desventajas**\n","---\n","\n","> **Ventajas**\n","\n","* A través de las capas ocultas se pueden modelar relaciones de alto nivel entre las entradas. Por ejemplo, en el dominio de reconocimiento de objetos en imágenes, se puede aprender que el conjunto de dos ojos, una nariz y una boca forman la imagen de una cara.\n","* Las funciones de activación al ser no lineales le permiten al modelo aprender funciones de separación más elaboradas.\n","\n","> **Desventajas**\n","\n","La complejidad del modelo puede aumentar rápidamente con respecto al número de capas y de neuronas por capa. Contemple el caso de una red con las siguientes características:\n","* 1 capa de entrada de tamaño $50$.\n","* 1 capa oculta de $256$ neuronas.\n","* 1 capa oculta de $512$ neuronas.\n","* 1 capa de clasificación binaria.\n","\n","Bajo esta configuración tenemos que el número de parámetros está distribuido de la siguiente manera:\n","* Conexiones entre la capa de entrada y la primera capa oculta: $256*50\\ +\\ 256 = 13056$. Donde la segunda parte corresponde a los sesgos.\n","* Conexiones entre la primera capa oculta y la segunda capa oculta: $256*512\\ +\\ 512 = 131584$.\n","* Conexiones entre la segunda capa oculta y la capa de clasificación: $512\\ +\\ 1 = 513$.\n","* Para un total de $145153$ parámetros entrenables.\n","\n","> **Recomendaciones prácticas**\n","\n","* Hacer un escalamiento de los datos de entrada. **`MLPClassifier`** es muy sensible a la escala de los datos de entrada.\n","* Explorar el número de neuronas por capa y el parámetro $\\alpha$ usando **`GridSearchCV`**.\n","* Usar *lbfgs* como **`solver`** para conjuntos de datos pequeños. Mientras que *adam* es más recomendado para conjuntos de datos grandes."]},{"cell_type":"markdown","metadata":{"id":"yt4bpBdPRWuF"},"source":["# **4. Análisis de series de tiempo**\n","---\n","\n","![texto alternativo](https://cdn-images-1.medium.com/max/800/1*ScwIEwLmXPFhBP46QMpy_A.png)\n","\n","Las series de tiempo son una secuencia de observaciones indexadas por una variable temporal. Una de las aplicaciones más comunes del análisis de series de tiempo es la predicción de valores futuros utilizando datos históricos. Por ejemplo, se desea predecir el valor de la medida en el siguiente minuto, día, mes o año basados en los datos recolectados en los minutos, días, meses y/o años previos.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HvcNgfF1cDb4"},"source":["## **4.1 Validación cruzada para series de tiempo**\n","---\n","\n","Un problema de análisis de series de tiempo puede ser transformado en un problema de aprendizaje supervisado tomando una **ventana** de  las $k$ observaciones anteriores como los datos de entrada o predictores y el valor actual como el valor objetivo o valor explicado. El ancho de la ventana $w$ normalmente se explora como un hiperparámetro.\n","\n","Un aspecto importante a tener en cuenta en el análisis de series de tiempo es que la selección de los conjuntos de validación y entrenamiento para la validación cruzada o *cross validation* **no puede ser aleatorio** como se realiza en otros problemas de *machine learning* supervisado donde la secuencia y el tiempo no se toman en cuenta. En el análisis de series de tiempo estamos interesados en predecir un valor en el futuro. De esta manera, los datos de validación para series de tiempo siempre deben ocurrir temporalmente después de los datos de entrenamiento. Existen dos esquemas de validación cruzada para series de tiempo **_sliding window_** y **_forward chaining validation_** que pueden ser usados para la validación cruzada de series de tiempo.\n","\n","![texto alternativo](https://cdn-images-1.medium.com/max/800/1*h6HaTi1DKsNqEUjdECQV0A.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WmmqijRbhWK8"},"source":["## **4.2. Series de tiempo con redes neuronales artificiales**\n","---\n","\n","Ahora realizaremos la predicción para el *dataset* de temperaturas mínimas medias semanales. Carguemos nuevamente el objeto *Series*."]},{"cell_type":"code","metadata":{"id":"P9vfQblUxcUu"},"source":["# Objeto Series con el conjunto de datos.\n","url = 'https://drive.google.com/uc?export=download&id=1XvKsdBs6EG463iN3L1lQv9JXd9lW0JJC'\n","\n","mintemp = pd.read_csv(url, index_col = 0, parse_dates= True, squeeze = True)\n","mintemp.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2s8pq29mio5O"},"source":["# Información general del contenido de la serie.\n","mintemp.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4jEBqJBYX4WO"},"source":["Vamos a visualizar la serie de los valores de temperatura. Este será el valor que predeciremos."]},{"cell_type":"code","metadata":{"id":"TzF30WcPZLJB"},"source":["mintemp.plot(rot=90, figsize = (12, 5), fontsize = 13.5);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g9Phfc5Xetct"},"source":["Vamos a preparar el *dataset* para el modelado. Nuestro objetivo es entrenar un **modelo autorregresivo**, en el cual el valor de la serie de tiempo en un momento dado $X_i$ depende de los $k$ valores anteriores.\n","\n","La red neuronal debe tener $k$ entradas o *features* y $1$ salida, que corresponde al valor actual. Las *features* serán las $k$ observaciones previas, que corresponden a una **ventana** de tamaño $k$."]},{"cell_type":"code","metadata":{"id":"tTsfRf5NQVa4","cellView":"form"},"source":["#@markdown **Visualización:** demostración del concepto de ventanas de tiempo.\n","\n","#@markdown * **`n`**: Número de ventanas a visualizar.\n","n =   9#@param {type:\"integer\"}\n","#Visualización del concepto de ventana\n","\n","#@markdown * **`k`**: Tamaño de la ventana.\n","k =   10#@param {type:\"integer\"}\n","\n","fig, axes = plt.subplots(nrows = n//2, ncols= 2,  figsize = (8, 1.5*n), dpi = 110)\n","\n","for i, ax in enumerate(axes.flat):\n","  data =  mintemp.iloc[i: i + k]\n","  ax.set_title(f'Ventana {i + 1}')\n","  ax.plot(data.index[:-1], data.values[:-1], 'r')\n","  ax.plot(data.index[-1], data.values[-1], 'go', ms = 12)\n","  ax.plot(data.index[:-1], data.values[:-1], 'ro')\n","  ax.plot(data.index[-2:], data.values[-2:], 'g--')\n","  fig.autofmt_xdate()\n","fig.tight_layout()\n","\n","fig.legend(['Ventana', 'Valor']);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EAw1gu9ndV4J"},"source":["Para generar nuestro modelo vamos a iniciar con una ventana de tiempo de $20$ observaciones."]},{"cell_type":"code","metadata":{"id":"KJNs1Jk4c-Kf"},"source":["# Tamaño de la ventana. Puede cambiarlo si lo desea.\n","# Tenga en cuenta que el entrenamiento para valores mayores tardará más tiempo.\n","\n","k = 20"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z1nNGRrDdh0U"},"source":["Usaremos los registros de los primeros $7$ años del dataset (desde $1981$ hasta $1986$) para el conjunto de entrenamiento y validación y los siguientes $2$ (desde $1987$ hasta $1990$) para el conjunto de pruebas. Empezamos almacenándolos en arreglos de _NumPy_."]},{"cell_type":"code","metadata":{"id":"lAmvZ491bjTJ"},"source":["data_train = mintemp.loc[:'1986-12-31']  # Primeros 7 años\n","data_test  = mintemp.loc['1987-01-01':]  # Últimos 3 años.\n","\n","data_train.index[-1], data_test.index[0] # Fechas de inicio de ambos conjuntos."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qUeMgnEes8K"},"source":["# Función para obtener las ventanas de tiempo.\n","\n","def sliding_time(ts, window_size=1):\n","\n","  n = ts.shape[0] - window_size\n","  X = np.empty((n, window_size))\n","  y = np.empty(n)\n","\n","  for i in range(window_size, ts.shape[0]):\n","    y[i - window_size] = ts[i]\n","    X[i- window_size, 0:window_size] = np.array(ts[i - window_size:i])\n","\n","  return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"waIWf7Kofm4c"},"source":["# Creamos las ventanas y sus valores a predecir para entrenamiento y validación.\n","\n","X_train, y_train = sliding_time(data_train.values, window_size=k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MI68YbNrfzGM"},"source":["print(f\"Número de ejemplos de entrenamiento: {X_train.shape[0]} (Ventana de tamaño {X_train.shape[1]})\")\n","print(f\"Número de valores a predecir: {y_train.shape[0]}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZMymlsyjqGj"},"source":["# Creamos las ventanas y sus valores a predecir para entrenamiento y validación.\n","X_test, y_test = sliding_time(data_test.values, window_size=k)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZHp4wyOjqGo"},"source":["print(f\"Número de ejemplos de entrenamiento: {X_test.shape[0]} (Ventana de tamaño {X_test.shape[1]})\")\n","print(f\"Número de valores a predecir: {y_test.shape[0]}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ibjUrNiw53dO"},"source":["La fila $X_i$ de $X$ corresponde a una ventana de los $k$ valores anteriores a $y_i$. En la siguiente celda podemos ver el arreglo en formato de *DataFrame*. Note que cada fila es la fila anterior corrida un movimiento hacia la izquierda."]},{"cell_type":"code","metadata":{"id":"n5ivNO4F8317"},"source":["# Observaciones de X en formato de DataFrame.\n","pd.DataFrame(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h1Jshdrg6SLx"},"source":["En $y_i$ está el elemento que iría justo después del último valor de la ventana $X_i$. Note que el elemento $y_i$ es el último valor de la fila $X_{i+1}$, pues en esa ventana pasa a ser el último elemento, usado para predecir el valor $y_{i+1}$."]},{"cell_type":"code","metadata":{"id":"hdiI4xYl85RF"},"source":["# Valores a predecir y en formato de Series.\n","pd.Series(y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jz8x3lWdhTar"},"source":["### **4.2.1. Partición de los datos de entrenamiento y pruebas**\n","---\n","\n","Como se mencionó previamente, para realizar la partición de entrenamiento y pruebas se debe tomar en cuenta la temporalidad de la serie. Para ello utilizaremos la función **`TimeSeriesSplit`** de *Scikit-Learn*."]},{"cell_type":"code","metadata":{"id":"eofp7bP76d83"},"source":["# Selección de los datos en series de tiempo\n","from sklearn.model_selection import TimeSeriesSplit\n","\n","# Definimos el número de splits para realizar cross-validation\n","tsp = TimeSeriesSplit(n_splits=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9usqQafUiEGT"},"source":["EL método **`TimeSeriesSplit`** toma como parámetro los arreglos **`X`** y **`y`** y genera los índices para entrenamiento y pruebas de una validación cruzada de _**forward chaining**_ igual a la cantidad de divisiones definidas en el argumento **`n_splits`**."]},{"cell_type":"code","metadata":{"id":"3NeDvmPT9n2J"},"source":["for i, (train_index, test_index) in enumerate(tsp.split(X_train, y_train)):\n","\n","  print(f'-------------------- Pliegue {i + 1} --------------------')\n","  print(\"\\tPartición de entrenamiento\")\n","  print(f'\\t\\tTamaño de la partición: {train_index.shape}')\n","  print(f'\\t\\tRango de valores: {train_index[0]}-{train_index[-1]}\\n')\n","\n","  print(\"\\tPartición de validación\")\n","  print(f'\\t\\tTamaño de la partición: {test_index.shape}')\n","  print(f'\\t\\tRango de valores: {test_index[0]}-{test_index[-1]}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mig7k5vd6_kp","cellView":"form"},"source":["#@markdown **Visualización:** demostración de la ubicación de los índices de la partición de series de tiempo con **`TimeSeriesSplit`**.\n","\n","\n","n_splits = 3 #@param {type:\"slider\", min:3, max:7, step:1}\n","\n","# La partición nos devuelve los indices de train y test.\n","tsp = TimeSeriesSplit(n_splits=n_splits)\n","\n","i = 0\n","fig = plt.figure(figsize = (12,6), dpi = 110)\n","plt.set_cmap('Paired')\n","\n","tsp_indexes = [(train_index, test_index) for (train_index, test_index) in tsp.split(X_train, y_train)]\n","\n","for train_index, test_index in tsp_indexes:\n","  plt.plot(train_index,\n","           np.full(len(train_index), 1-i*0.001),\n","           lw = 8,\n","           ls= '-.',\n","           label = f'Entrenamiento (k = {i + 1})')\n","\n","  plt.plot(test_index,\n","           np.full(len(test_index), 1-i*0.001),\n","           lw = 8,\n","           ls= '-',\n","           label = f'Validación (k = {i + 1})')\n","  i+=1\n","fig.get_axes()[0].get_yaxis().set_visible(False)\n","plt.legend(ncol=1, title = 'Índices por partición', );"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62-hs1CWLAtO"},"source":["Visualizamos los datos de entrenamiento y validación de esta última división:"]},{"cell_type":"code","metadata":{"id":"IOAvhjuKKbjk"},"source":["# Datos de prueba y entrenamiento con Matplotlib\n","train_index, test_index = tsp_indexes[-1]\n","\n","fig = plt.figure(dpi = 120, figsize = (8, 3))\n","plt.plot(mintemp[train_index].index, mintemp[train_index].values, label = \"Entrenamiento (y)\")\n","plt.plot(mintemp[test_index].index, mintemp[test_index].values, label = \"Prueba (y)\")\n","\n","plt.title('Datos de entrenamiento y pruebas (y)')\n","fig.autofmt_xdate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m52QmQ3vJ8Q6"},"source":["## **4.3. Regresión de series de tiempo con perceptrón multicapa**\n","---\n","Ahora realizamos la regresión con una red neuronal multicapa, para predecir el valor de la serie. En esta ocasión utilizaremos **`MPLRegressor`**. Sus parámetros son equivalentes a los aceptados por **`MLPClassifier`**, a diferencia que el regresor permite retornar los valores continuos generados por la función de predicción."]},{"cell_type":"code","metadata":{"id":"EQmRet0wPX2B"},"source":["from sklearn.neural_network import MLPRegressor\n","\n","model = MLPRegressor(solver = 'lbfgs',\n","                   activation = 'relu',\n","                   hidden_layer_sizes=(120, 60, 30),\n","                   max_iter=200,\n","                   n_iter_no_change=50,\n","                   validation_fraction=0.2,\n","                   random_state=1234)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HR57UUEWPmyL"},"source":["# Entrenamos el modelo.\n","model.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lZCxyV7JP4w9"},"source":["# Métricas de rendimiento\n","# Error absoluto, cuadrado, y cuadrado logarítmico.\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n","\n","y_pred = model.predict(X_test)\n","\n","print(f\"Test Mean Squared Error: \\t{mean_squared_error(y_test, y_pred):.4f}\")\n","print(f\"Test Mean Absolute Error: \\t{mean_absolute_error(y_test, y_pred):.4f}\")\n","print(f\"Test Mean squared log error: \\t{mean_squared_log_error(y_test, y_pred):.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YwfrHnYvP-j0"},"source":["x = data_test.index[k:]\n","\n","plt.figure(figsize=(10,3), dpi = 105)\n","plt.plot(x, y_test, ls = \"--\", label=\"Valor verdadero (pruebas)\")\n","plt.plot(x, y_pred, ls = '-', label=\"Valor predicho (pruebas)\")\n","plt.title(\"Predicción vs valores verdaderos (pruebas)\")\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JS9BoirUnbb5"},"source":["### **4.3.1. Validación cruzada con series de tiempo**\n","---\n","Ahora vamos a explorar los hiperparámetros de la red para identificar sus valores más apropiados. Para hacer esto, utilizaremos todas las particiones generadas por **`TimeSeriesSplit`** y exploraremos manualmente las combinaciones de hiperparámetros de **`MLPRegressor`**.\n","\n","En este ejemplo exploraremos el tamaño de la capa oculta (**`hidden_layer_sizes`**) y la función de activación (**`activation`**)."]},{"cell_type":"code","metadata":{"id":"Gk_rZPdnpjVT"},"source":["params = {\n","      'hidden_layer_sizes' : [(10,), (20,), (40,), (80,) ], # Algunas arquitecturas propuestas.\n","      'activation' : ['logistic', 'tanh', 'relu']           # Funciones de activación.\n"," }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GDuTgaxSk9u0"},"source":["El objeto generado por **`TimeSeriesSplit`** puede ser usado para generar las particiones de validación cruzada con el método **`GridSearchCV`**, pasándolo con el argumento **`cv`**.\n","\n","> **Nota**: La búsqueda explora $12$ configuraciones distintas en cada uno de los $5$ pliegues generados  con **`TimeSeriesSplit`**. Como consecuencia la función puede tardar unos minutos en ejecutarse por completo."]},{"cell_type":"code","metadata":{"id":"YLMVWz1gT9YV"},"source":["#Grid Search para el modelo MLPRegressor\n","from sklearn.model_selection import GridSearchCV\n","\n","tsp = TimeSeriesSplit(n_splits = 5)\n","\n","gsearch = GridSearchCV(estimator = MLPRegressor(solver = 'lbfgs', #Modelo  a explorar.\n","                                                random_state=1234,\n","                                                max_iter= 2000,\n","                                                n_iter_no_change=50,\n","                                                validation_fraction=0.2),\n","                        cv = tsp,\n","                        param_grid = params,\n","                        verbose = 3)\n","\n","gsearch.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1GRfUTPmPCc"},"source":["Finalmente, podemos explorar el objeto generado en busca de la mejor configuración identificada, como se realizó en el material anterior."]},{"cell_type":"code","metadata":{"id":"s4w7Z5VLUkjg"},"source":["# Los mejores 10 modelos con respecto a su mean_test_score.\n","pd.DataFrame(gsearch.cv_results_).nlargest(10, 'mean_test_score')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L121oYqJCI2G"},"source":["Finalmente, para la evaluación del modelo en la tarea de predecir instancias futuras, podemos retroalimentar los datos predichos en nuevas ventanas que se usen para predecir datos totalmente generados por el modelo.\n","\n","A continuación, vamos a realizar este proceso desde la primera ventana del conjunto de evaluación, y comparar los resultados con los valores obtenidos al predecir a partir de las ventanas de evaluación y con los datos reales.\n","\n"," Las líneas generadas en la visualización tienen el siguiente significado:\n","  * **Valores de entrenamiento y pruebas**: La primera ventana de tiempo\n","      (<font color=\"blue\"><b>en azul</b></font>) corresponde a los datos que fueron usados para entrenar y validar el desempeño del modelo. A partir de su último valor se realizan las predicciones correspondientes.\n","  * **Valores reales**: Esta línea (<font color=\"red\"><b>en rojo</b></font>) corresponde a los valores reales de la ventana de tiempo final en el conjunto de datos original. Se visualiza para realizar una comparación gráfica con los valores predichos por el modelo.\n","  * **Valores predichos a partir de datos reales**: Esta línea (<font color=\"green\"><b>en verde</b></font>) corresponde a los valores predichos por el modelo a partir de la ventana previa de valores reales, aunque su final no coincida con el valor predicho con la ventana inmediatamente anterior.\n","  * **Valores predichos a partir de datos predichos**: Esta línea (<font color=\"BlueViolet\"><b>en azul</b></font>) corresponde a los valores predichos por el modelo a partir de la ventana previa de valores construida a partir de predicciones continuas. Al inicio se realiza una predicción con los valores reales del final de la primera ventana de tiempo y se concatena el valor predicho al final de la nueva ventana usada para predecir. Gracias a esta configuración se podría realizar teóricamente una lista de predicciones sin límite."]},{"cell_type":"code","metadata":{"id":"BbSUK0W0CpD2","cellView":"form"},"source":["#@markdown **Visualización:** Visualización de los resultados de la regresión a partir de datos reales y predichos\n","#@markdown > **Nota**: La función es generada con la librería de visualización interactiva de datos [*Plotly*](https://plotly.com/python/). Use la rueda del ratón para hacer *zoom* y haga clic y arrastre el puntero para desplazarse en los posibles valores.\n","# Últimos valores de entrenamiento a usar para la predicción.\n","X_last = X_test[:1]\n","\n","# Listas con los datos en y, empezando desde el primer valor de pruebas.\n","y_last = []\n","y_forward = []\n","\n","for i in range(len(X_test)):\n","  # Valores predichos a partir de datos reales (X_test)\n","  y_pred_forward = gsearch.predict(X_test[i: i + 1])\n","  y_forward.append(y_pred_forward[0])\n","\n","  # Valores predichos a partir de datos predichos y retroalimentados.\n","  y_pred_last = gsearch.predict(X_last)  # Se predice el valor siguiente a partir de datos predichos previamente.\n","  y_last.append(y_pred_last[0])          # Guardamos el valor predicho.\n","\n","  # Creación de la nueva ventana añadiendo la última predicción.\n","  X_last = np.roll(X_last, -1)           # Desplazamos todos los valores hacia la izquierda con np.roll\n","  X_last[0,-1] = y_pred_last             # Guardamos el valor predicho en la última posición del arreglo.\n","\n","#Gráficamos las 2 predicciones distintas en comparación con los valores reales.\n","\n","test_date_index = data_test.index[k:]\n","plot_prediction(gsearch.best_params_,\n","                (y_test, y_forward, y_last),\n","                 test_date_index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TykDw62o89RJ"},"source":["Podemos utilizar métricas para evaluar el rendimiento obtenido con los dos métodos. El segundo método, aun usando datos predichos únicamente, produce un resultado bastante bueno con relación a la poca información real de la que parte para su construcción."]},{"cell_type":"code","metadata":{"id":"t-MAcRw78d5B"},"source":["# Datos predichos a partir de datos predichos.\n","\n","print(f\"Test Mean Squared Error: \\t{mean_squared_error(y_test, y_last):.4f}\")\n","print(f\"Test Mean Absolute Error: \\t{mean_absolute_error(y_test, y_last):.4f}\")\n","print(f\"Test Mean squared log error: \\t{mean_squared_log_error(y_test, y_last):.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxqTu2Gx81fO"},"source":["# Datos predichos a partir de datos reales.\n","\n","print(f\"Test Mean Squared Error: \\t{mean_squared_error(y_test, y_forward):.4f}\")\n","print(f\"Test Mean Absolute Error: \\t{mean_absolute_error(y_test, y_forward):.4f}\")\n","print(f\"Test Mean squared log error: \\t{mean_squared_log_error(y_test, y_forward):.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4r5hSQAz6d-g"},"source":["# **Recursos adicionales**\n","---\n","Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *Scikit-learn* en la creación y entrenamiento de redes neuronales multicapa y el análisis y modelado de problemas de series de tiempo, además de material de apoyo teórico para reforzar estos conceptos:\n","\n","* [Time Series Machine Learning Regression Framework](https://towardsdatascience.com/time-series-machine-learning-regression-framework-9ea33929009a)\n","* [How (not) to use Machine Learning for time series forecasting: Avoiding the pitfalls](https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424)\n","* [Analytics Vidhya - Time Series Forecasting using Python](https://courses.analyticsvidhya.com/courses/creating-time-series-forecast-using-python/)\n","* [3Blue1Brown - Neural Networks (Lista de reproducción de *YouTube*)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n","* [Fernando Sancho Caparrini - Redes Neuronales: una visión superficial.](http://www.cs.us.es/~fsancho/?e=72)\n","* [Knut Hinkelmann - Neural Networks](http://didattica.cs.unicam.it/lib/exe/fetch.php?media=didattica:magistrale:kebi:ay_1718:ke-11_neural_networks.pdf)\n","* [MIT Press book - Deep learning book](https://www.deeplearningbook.org/)\n","* [course.fast.ai](https://course.fast.ai/)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O6dwABE_Zg44"},"source":["# **Créditos**\n","---\n","\n","* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n","* **Asistentes docentes:**\n","  * Miguel Angel Ortiz Marín\n","  * Alberto Nicolai Romero Martínez\n","\n","**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"]}]}