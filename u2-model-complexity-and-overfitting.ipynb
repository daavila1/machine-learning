{"cells":[{"cell_type":"markdown","metadata":{"id":"yTRoytbIps_y"},"source":["![](https://drive.google.com/uc?export=view&id=1NiRkCapP04t7XxA7fbG7ZWie2PA1L_0M)\n"]},{"cell_type":"markdown","metadata":{"id":"dqKR8J6k_PRh"},"source":["# **Complejidad y sobreajuste**\n","---\n","\n","En este _notebook_ exploraremos la diferencia entre parámetros e hiperparámetros de un modelo de aprendizaje computacional, además de conceptos como la capacidad o complejidad, y las consecuencias del subajuste y sobreajuste.\n","\n","Para esto, observaremos cómo se comporta la complejidad del modelo de clasificación no lineal  *k-vecinos más cercanos* (K-nearest neighbors en inglés).\n"]},{"cell_type":"markdown","metadata":{"id":"i0sRGgMB2FUF"},"source":["# **1. Dependencias**\n","---\n","Importamos las librerías necesarias y definimos algunas funciones básicas de visualización que vamos a usar en algunos ejemplos.\n"]},{"cell_type":"markdown","metadata":{"id":"FKGZyc4shdTy"},"source":["### **1.1. Dependencias**\n","---\n","Para la construcción de modelos y ejecución de procedimientos metodológicos de aprendizaje automático, utilizaremos la librería **Scikit-learn** (**`sklearn`**) y varias de sus funciones y conjuntos de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXB7rHzqZJq0"},"outputs":[],"source":["# Actualizamos scikit-learn a la última versión\n","!pip install -U scikit-learn\n","\n","# Importamos scikit-learn\n","import sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlOlDOmbsGII"},"outputs":[],"source":["# Librerías básicas de análisis y visualización de datos.\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nmx-RGqF8Hls"},"outputs":[],"source":["# Configuraciones para las librerías y módulos usados\n","\n","# Ignoramos las advertencias o warnings.\n","import warnings\n","warnings.simplefilter(action='ignore')\n","\n","# Configuramos el formato por defecto de la\n","# librería de visualización Matplotlib.\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'"]},{"cell_type":"markdown","metadata":{"id":"dxNzX3sfq3gZ"},"source":["Este material se realizó con las siguientes versiones:\n","*  *Python*: 3.7.10\n","*  *Scikit-learn*: 0.24.1\n","*  *NumPy*:  1.19.5\n","*  *Pandas*:  1.1.5\n","*  *Matplotlib*:  3.2.2\n","*  *Seaborn*:  0.11.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUMP_2CPqwRY"},"outputs":[],"source":["# Versión de Python y las demás librerías.\n","!python --version\n","print('Scikit-learn', sklearn.__version__)\n","print('NumPy', np.__version__)\n","print('Pandas', pd.__version__)\n","print('Matplotlib', mpl.__version__)\n","print('Seaborn', sns.__version__)"]},{"cell_type":"markdown","metadata":{"id":"XIJTEeKxhvm2"},"source":["### **1.2. Funciones de utilidad y visualización**\n","---\n","\n","Para ilustrar los ejemplos discutidos en este material utilizaremos algunas funciones que permiten visualizar de manera general los datos y conceptos discutidos en las secciones.\n","\n","> **Nota**: *Matplotlib* y *Seaborn* se encuentran por fuera del alcance de este módulo. No es necesario que entienda estas funciones en detalle para sacar partido del resto del contenido puesto a su disposición. Usted decide si leer o no estas funciones en profundidad. Si decide omitir esta sección, continúe directamente con la siguiente sección, en donde se discutirán los conjuntos de datos que vamos a utilizar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFDXpdM-ps_1"},"outputs":[],"source":["# Función para visualizar un conjunto de datos de dos variables en un plano 2D\n","def plot_data(X, y, model = None, ax = None, title=None):\n","\n","    if ax is None:\n","      _, ax = plt.subplots(dpi = 110)\n","\n","    if model is not None:\n","      pred_fun = gen_pred_fun(model)\n","      plot_decision_region(X, pred_fun, ax)\n","\n","    y_unique = np.unique(y)\n","    df = pd.DataFrame({'x1': X[:,0], 'x2': X[:,1], 'Clases': y})\n","    sns.set_theme()\n","    sns.scatterplot(data = df, x = 'x1', y = 'x2',\n","                    hue = 'Clases',style = 'Clases', ax = ax, palette = 'Set1').set_title(title)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZZQ_8SFDWcb"},"outputs":[],"source":["# Función para visualizar la superficie de decisión de un clasificador\n","def plot_decision_region(X, pred_fun, ax=None):\n","    min_x, max_x = np.min(X[:, 0]), np.max(X[:, 0])\n","    min_y, max_y = np.min(X[:, 1]), np.max(X[:, 1])\n","\n","    min_x = min_x - (max_x - min_x) * 0.05\n","    max_x = max_x + (max_x - min_x) * 0.05\n","    min_y = min_y - (max_y - min_y) * 0.05\n","    max_y = max_y + (max_y - min_y) * 0.05\n","\n","    x_vals = np.linspace(min_x, max_x, 100)\n","    y_vals = np.linspace(min_y, max_y, 100)\n","\n","    XX, YY = np.meshgrid(x_vals, y_vals)\n","    grid_r, grid_c = XX.shape\n","\n","    ZZ = np.zeros((grid_r, grid_c))\n","\n","    for i in range(grid_r):\n","        for j in range(grid_c):\n","            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n","\n","    ax.contourf(XX, YY, ZZ, 100, cmap = plt.cm.coolwarm_r, vmin= -1, vmax=2, alpha = 0.75)\n","    ax.set_xlabel(\"x\")\n","    ax.set_ylabel(\"y\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9D8XlcuDaEt"},"outputs":[],"source":["# Función para visualizar la curva de aprendizaje a partir\n","# del error de entrenamiento y de generalización.\n","def plot_learning_curve(train_error, generalization_error):\n","\n","  balance_point = np.array(generalization_error).argmin() + 1\n","  plt.figure(figsize = (8, 5), dpi = 105)\n","\n","  plt.plot(range(1, k_values + 1), train_error, label=\"Entrenamiento\")\n","  plt.plot(range(1, k_values + 1), generalization_error, label=\"Validación\")\n","  plt.xticks(range(0, k_values + 1, 5))\n","  plt.xlabel(\"k-vecinos\")\n","  plt.ylabel(\"Error\")\n","  y_min, y_max = plt.gca().get_ylim()\n","  plt.vlines(balance_point, y_min, y_max, colors = ['red'], linestyles = ['dashdot'])\n","  plt.ylim([y_min, y_max])\n","  plt.text(balance_point + 1, 0.165, 'Punto de balance')\n","  plt.legend();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSfViWX6DcEY"},"outputs":[],"source":["#Función para generar la función de predicción de un clasificador entrenado previamente.\n","def gen_pred_fun(clf):\n","    def pred_fun(x1, x2):\n","        x = np.array([[x1, x2]])\n","        return clf.predict(x)[0]\n","    return pred_fun"]},{"cell_type":"markdown","metadata":{"id":"WobaSntoptAG"},"source":["# **2. Definición del conjunto de datos**\n","---\n","\n","En este material vamos a trabajar con un conjunto de datos artificial. El conjunto es creado usando la función **`make_moons`** de _Scikit-Learn_. Esta función permite introducir algo de ruido sobre las muestras creadas con el argumento **`noise`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWoSEkkeptAJ"},"outputs":[],"source":["from sklearn import datasets\n","\n","X, y = datasets.make_moons(n_samples=1000, noise=0.4, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"maqpy27NptAS"},"outputs":[],"source":["print('X ~ n_muestras x n_características:', X.shape)\n","print('y ~ n_muestras:', y.shape)\n","\n","print('\\nPrimeras 5 muestras:\\n', X[:5, :])\n","print('\\nPrimeras 5 etiquetas:', y[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fz8fktlya1Rl"},"outputs":[],"source":["plot_data(X, y)"]},{"cell_type":"markdown","metadata":{"id":"VNI8F1dc6Lpp"},"source":["A continuación, vamos a dividir el conjunto en $70\\%$ para entrenamiento y $30\\%$ para prueba. Utilizaremos el parámetro **`stratify`** para estratificar en submuestras balanceadas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pm083RBp6Eip"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size=0.3,\n","                                                    random_state=1234,\n","                                                    stratify=y)"]},{"cell_type":"markdown","metadata":{"id":"9gOkLj4_lIxo"},"source":["Vamos a verificar el número de muestras de ambas particiones y la distribución de clases de cada una."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MH4c-gJptCc"},"outputs":[],"source":["print(f'Número de muestras en entrenamiento: {X_train.shape[0]}')\n","print(f'Número de muestras en prueba: {X_test.shape[0]}')\n","print(f'Número de características: {X_train.shape[1]}')\n","\n","print(f'Distribución de clases en entrenamiento: {np.bincount(y_train)}')\n","print(f'Distribución de clases en prueba: {np.bincount(y_test)}')"]},{"cell_type":"markdown","metadata":{"id":"tXc5XJQ2CYzP"},"source":["# **3. Parámetros e Hiperparámetros**\n","---\n","Los **parámetros** o pesos de un modelo se refieren a los valores que caracterizan un modelo. Por ejemplo, en una regresión lineal los parámetros del modelo corresponden a los coeficientes por los cuales se multiplican las variables de entrada. Los parámetros son aprendidos por el algoritmo de aprendizaje a partir de los datos.\n","\n","Por otra parte, los **hiperparámetros** son todos los parámetros que no se aprenden y que controlan el aprendizaje y el comportamiento del modelo. Estos son especificados de forma manual por el programador en la concepción del modelo.\n","\n","Para entender la diferencia entre parámetros e hiperparámetros vamos a ver un ejemplo con uno de los modelos de clasificación más simples: la regresión logística.\n","\n","El modelo de regresión logística busca clasificar los datos de forma binaria en dos categorías ($0$ y $1$). Para ello, usa la función logística o sigmoidal:\n","\n","$$\n","\\hat{y} = \\frac{1}{1+e^{-\\mathbf{w}\\cdot\\mathbf{x}+w_0}}\n","$$\n","\n","Donde $\\hat{y}$ es la *predicción*, $\\mathbf{w}$ y $w_0$ son los *parámetros* y $\\mathbf{x}$ es una *observación* o un vector de características que representa cada ejemplo.\n","\n","Ahora vamos a definir un modelo de regresión logística en _Scikit-Learn_:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y8u038yoc2lN"},"outputs":[],"source":["# Importamos el modelo de sklearn.\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0Fc1ZOackoj"},"outputs":[],"source":["# Definimos el modelo.\n","model_1 = LogisticRegression()"]},{"cell_type":"markdown","metadata":{"id":"iggMNirOc9AF"},"source":["Hasta este punto ya tenemos definido el modelo, podríamos pasar a entrenarlo y posteriormente obtener predicciones sobre datos nuevos. No obstante, podemos definir otro modelo de regresión logística con algunas variaciones:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yM3nDCw7dPI5"},"outputs":[],"source":["# Definimos el segundo modelo\n","model_2 = LogisticRegression(fit_intercept=False)"]},{"cell_type":"markdown","metadata":{"id":"Uj2yq0zVdeI2"},"source":["Aunque el modelo **`model_2`** es un modelo de regresión logística, su comportamiento va a ser diferente al tener una variación en el hiperparámetro **`fit_intercept`**. Este especifica si el modelo va a tener en cuenta el intercepto $w_0$. Este segundo modelo se describiría por medio de la siguiente ecuación:\n","\n","$$\n","\\hat{y} = \\frac{1}{1+e^{-{w}\\cdot\\mathbf{x}}}\n","$$\n","\n","Este hiperparámetro afecta la forma del modelo, ya que tiene un parámetro menos.\n","\n","Veamos la diferencia entre el comportamiento de los dos modelos definidos en el conjunto de datos artificial *blobs*:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBxo1cIraYKf"},"outputs":[],"source":["X_blobs, y_blobs = datasets.make_blobs(n_samples = 200, centers = 2,  random_state= 246)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qj2Ogv5Pe8ys"},"outputs":[],"source":["# Entrenamos el modelo 1.\n","\n","model_1.fit(X_blobs, y_blobs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jj4bFkQffYqj"},"outputs":[],"source":["# Entrenamos el modelo 2.\n","\n","model_2.fit(X_blobs, y_blobs)"]},{"cell_type":"markdown","metadata":{"id":"C55NECzkfeCy"},"source":["Podemos ver los parámetros de los dos modelos. Estos pueden ser accedidos con los atributos **`coef_`** (vector de pesos del modelo $w$)  e **`intercept_`** (intercepto $w_0$)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCcR9RNLfiiV"},"outputs":[],"source":["# Vector w de pesos e intercepto w_0 del modelo 1.\n","print(f\"Pesos w: {model_1.coef_}\")\n","print(f\"Intercepto w_0: {model_1.intercept_}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isiIRjcUf51C"},"outputs":[],"source":["# Vector w de pesos e intercepto w_0 del modelo 2.\n","print(f\"Pesos w: {model_2.coef_}\")\n","print(f\"Intercepto w_0: {model_2.intercept_}\")"]},{"cell_type":"markdown","metadata":{"id":"2u51HKRkfwq0"},"source":["Como podemos ver, el segundo modelo tiene $w_0=0$ y esto afecta los valores del vector de pesos ${w}$. Así mismo, afecta todo el aprendizaje y los resultados obtenidos.\n","\n","A partir de la siguiente visualización podemos ver que la línea que separa las regiones de decisión del modelo pasa por el punto $(0, 0)$ cuando no se considera el intercepto en el entrenamiento del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhXEDEwIehyQ"},"outputs":[],"source":["fig, axes = plt.subplots(ncols = 2, dpi = 110, figsize = (10, 4))\n","\n","plot_data(X_blobs, y_blobs, model_1, ax = axes[0],\n","          title = f'Regresión CON intercepto ($w_0$ = {model_1.intercept_[0]:.2f})')\n","plot_data(X_blobs, y_blobs, model_2, ax = axes[1],\n","          title = f'Regresión SIN intercepto ($w_0$ = {model_2.intercept_[0]:.2f})')"]},{"cell_type":"markdown","metadata":{"id":"taNR6WDYgFWz"},"source":["\n","En general, en _Scikit-Learn_ los hiperparámetros se encuentran entre los argumentos requeridos para la definición del modelo. Veamos los argumentos de la regresión logística:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESgoX5ewgSlp"},"outputs":[],"source":["model_1.get_params()"]},{"cell_type":"markdown","metadata":{"id":"umFyElXsgkKc"},"source":["Encontramos algunos hiperparámetros como:\n","\n","* **`fit_intercept`**: especifica si el modelo utiliza el intercepto $w_0$.\n","* **`class_weight`** permite ponderar cada clase de acuerdo a un peso determinado.\n","* **`penalty`**: función de pérdida usada para la regularización del modelo. Es una restricción que se agrega sobre la función de pérdida que permite optimizar el modelo de regresión logística.\n","* **`tol`**: tolerancia mínima en la función de pérdida para detener el entrenamiento.\n","* **`solver`**: algoritmo de optimización que se utilizará para el entrenamiento.\n","\n","Finalmente, veamos el efecto de variar el parametro **`class_weight`** con diferentes valores en la regresión logística:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pnHIA2sh1Ld"},"outputs":[],"source":["# Definimos una serie de valores para el peso de la clase 0.\n","weights = np.linspace(0, 1, 5)\n","weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pW95hSmJh_2O"},"outputs":[],"source":["# Definimos una figura con 5 ejes\n","fig, ax = plt.subplots(nrows = 5, figsize=(6, 20), dpi = 110)\n","\n","# Iteramos para cada peso a explorar\n","for i, weight in enumerate(weights):\n","    # Definimos un modelo para el valor de 'class_weight' actual.\n","      # El parámetro 'class_weight' es recibido en\n","      # forma de diccionario con el peso dado por\n","      # cada clase en 'y'.\n","    model = LogisticRegression(class_weight= {0: weight, 1: 1 - weight})\n","\n","    # Entrenamos el modelo\n","    model.fit(X_train, y_train)\n","    # Mostramos la región de decisión y los puntos con sus etiquetas.\n","    plot_data(X_train, y_train, model = model, ax=ax[i], title=f\"Pesos por clase: [Clase 0: {weight}; Clase 1: {1 - weight}]\")\n","\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"vGjxArv6knFw"},"source":["> **¿Observa alguna diferencia?**\n","\n","Conforme los pesos varían en el rango $[0, 1]$ la región de decisión tiende a predecir una mayor cantidad de datos para la clase con mayor peso."]},{"cell_type":"markdown","metadata":{"id":"XOeRabKcC1-Q"},"source":["# **4. Capacidad de un modelo**\n","---\n","La capacidad o complejidad de un modelo es su habilidad de ajustarse a una amplia variedad de funciones.\n","\n","Una forma de controlar la capacidad de un algoritmo de aprendizaje es elegir su espacio de hipótesis, el conjunto de funciones que puede seleccionar como la solución.\n","\n","\n","Por ejemplo, en un modelo de regresión polinomial la capacidad se puede controlar especificando el máximo grado $d$ del polinomio que se puede aprender. A mayor grado $d$ más grande el espacio de hipótesis y por lo tanto mayor capacidad.\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1li2VAfipUxUoIcJ_7W_KJ51QGrnZioNx\" width=400>\n","\n","En el lado izquierdo de la gráfica, ambos errores son altos, esta es la zona que corresponde al **subajuste**. A medida que aumentamos la capacidad, el error de entrenamiento se reduce, pero la brecha de generalización aumenta.\n","\n","Eventualmente, el tamaño de la brecha supera la disminución del error de entrenamiento, y se entra a la zona de sobreajuste, donde la capacidad es muy alta, por encima de la capacidad óptima.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PctyePy6b9Ya"},"source":["# **5. Subajuste, Sobreajuste y ajuste apropiado.**\n","---\n","Un algoritmo de aprendizaje automático busca cumplir los siguientes objetivos:\n","\n","- Hacer que el error de entrenamiento sea bajo.\n","- Hacer que la brecha entre el error de entrenamiento y el error de prueba sea pequeña.\n","\n","Dependiendo del desempeño del algoritmo en estas dos habilidades se habla de que el modelo resultante tiene **subajuste**, **sobreajuste** o **ajuste apropiado**.\n"]},{"cell_type":"markdown","metadata":{"id":"WIPTbTj4gCYj"},"source":["## **6.1 Sobreajuste**\n","---\n","<img src=\"https://drive.google.com/uc?export=view&id=1yLVxXHJfQfDOdsr7moiqumtFvp9U1K1L\" width=300>\n","\n","El sobreajuste (*overfitting* en inglés) ocurre cuando la brecha entre el error de entrenamiento y el error de prueba es muy grande. En estos casos el error de entrenamiento es bajo, pero el error de generalización es alto. Este resultado indica que el modelo se sobreajusta a los detalles más granulares de los datos de entrenamiento.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ezYWd60X_OpU"},"source":["Para ejemplificar este concepto, utilizaremos el algoritmo K-vecinos más cercanos (*KNN*). Usamos la partición de entrenamiento y prueba creada y analizaremos un modelo _KNN_ entrenado con $k = 1$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPZjL14Z9nfa"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier(n_neighbors=1)\n","knn.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSi4n9_K2xMY"},"outputs":[],"source":["plot_data(X_train, y_train, model = knn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1A8p0EnGptBn"},"outputs":[],"source":["print(\"Error en entrenamiento:\", 1 - knn.score(X_train, y_train))"]},{"cell_type":"markdown","metadata":{"id":"z-WWw0ImptB2"},"source":["> **¿Tiene sentido que el error sea del $0\\%$?**\n","\n","Revisemos el desempeño en la partición de prueba:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AmDcb5WwptB4"},"outputs":[],"source":["plot_data(X_test, y_test, model = knn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSTkhSf2ptCE"},"outputs":[],"source":["print('Error en prueba:', 1 - knn.score(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"rzPuZGjZptCL"},"source":["Podemos observar que cuando el número de vecinos es $1$, el modelo se ajusta demasiado al ruido de los datos de entrada y por lo tanto sufre de **sobreajuste**."]},{"cell_type":"markdown","metadata":{"id":"pZ1wGQnEf7jY"},"source":["## **6.2 Subajuste**\n","---\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1xdKPb1Oz22HghkmnQPgX8DOqllZYB2lG\" width=300>\n","\n","El subajuste (*underfitting* en inglés) ocurre cuando el modelo no logra conseguir un error de entrenamiento (ni de generalización) suficientemente bajo.\n","\n","Este resultado ocurre porque el modelo no tiene la capacidad suficiente para capturar la estructura de los datos y el problema.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LfXiPvswptCs"},"source":["Usaremos la partición creada y analizaremos un modelo _KNN_ entrenado con $k = 400$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQRcEMFqptCv"},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors=400)\n","knn.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jP6dr1VWptC_"},"outputs":[],"source":["plot_data(X_train, y_train, model = knn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6X9AwXzptDM"},"outputs":[],"source":["print('Error en entrenamiento:', 1-knn.score(X_train, y_train))"]},{"cell_type":"markdown","metadata":{"id":"4CAbN_b7ptDa"},"source":["Observamos que el error en entrenamiento es del $19\\%$. El modelo entrenado es ahora demasiado **simple** y no se puede ajustar a la estructura de los datos.\n","\n","Ahora medimos el error de generalización del modelo entrenado y visualizamos la clasificación de los datos de prueba."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upPVMjFXptDb"},"outputs":[],"source":["plot_data(X_test, y_test, model = knn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kg6oyuhpptDg"},"outputs":[],"source":["print('Error de generalización:', 1 - knn.score(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"kiyJZyJgptDk"},"source":["Podemos observar que cuando aumentamos el número de vecinos, nuestro modelo sufre de **subajuste**. La superficie de decisión se suaviza, pero no logra captar los detalles de los datos. Tanto el error de entrenamiento como el error de generalización se acercan a $19\\%$.\n","\n","**¿Cómo estimar un buen número de $k$-vecinos más cercanos de manera que el modelo no sobreajuste ni subajuste los datos?**"]},{"cell_type":"markdown","metadata":{"id":"NTXrQxMNf-dz"},"source":["### **6.3 Ajuste Apropiado**\n","---\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1GE36PB3mBa9_76v0-jYdFFmHkm7Cng7G\" width=300>\n","\n","El ajuste apropiado ocurre cuando tanto el error de entrenamiento y el de generalización son bajos. En este caso el modelo logra comportarse de manera similar tanto en el conjunto de entrenamiento como en el conjunto de prueba con un desempeño es satisfactorio.\n","\n","En la siguiente subsección veremos un ejemplo de cómo encontrar el valor de $k$ para encontrar la complejidad óptima."]},{"cell_type":"markdown","metadata":{"id":"dNcWQnj7ptDl"},"source":["### **6.3.1. Determinación de la complejidad óptima para _KNN_**\n","---\n","\n","Un modelo de aprendizaje de máquina puede ser tan complejo como para recordar las particularidades y el ruido del conjunto de entrenamiento (**sobreajuste**), así como puede ser demasiado flexible para no modelar la variabilidad de los datos (**subajuste**). El modelo debe garantizar un compromiso entre el sobreajuste y el subajuste, lo cual se logra evaluando la complejidad del modelo. Una forma de evaluar la complejidad es analizar el error de entrenamiento y generalización para diferentes modelos que varían en su complejidad. En el caso de **`KNearestNeighbor`**, la complejidad está determinada por el número de vecinos $k$. **Entre menor sea el número de vecinos, más complejo es el modelo.**\n","\n","A continuación, exploramos un conjunto de valores $k$, con el objetivo de encontrar aquél modelo con el mejor compromiso entre error de entrenamiento y error de generalización."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLzARLqiptDr"},"outputs":[],"source":["k_values = 50"]},{"cell_type":"markdown","metadata":{"id":"bl9yKEr8ptEA"},"source":["Evaluamos el error de entrenamiento y generalización para diferentes valores de complejidad del modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hnGbr7KptEC"},"outputs":[],"source":["train_error = []\n","generalization_error = []\n","\n","for nn in range(1, k_values + 1):\n","    knn = KNeighborsClassifier(n_neighbors=nn)\n","    knn.fit(X_train, y_train)\n","    train_error.append(1 - knn.score(X_train, y_train))\n","    generalization_error.append(1 - knn.score(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"7j2Npay7ptEF"},"source":["Visualizamos ambas curvas de aprendizaje."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5IgnrcGptEG"},"outputs":[],"source":["plot_learning_curve(train_error, generalization_error)"]},{"cell_type":"markdown","metadata":{"id":"QZ6Okf0OuUD9"},"source":["Se observa que el error de entrenamiento es más alto para modelos más simples (valor de $k$ alto) y tiende a cero para modelos más complejos (valor bajo de $k$). Además, el error de validación es alto en ambos extremos, y tiene su punto de balance mínimo en $k=13$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FC1iKjU9dO5b"},"outputs":[],"source":["print(\"Error de generalización con k = 13:\", generalization_error[12])"]},{"cell_type":"markdown","metadata":{"id":"e8zPzleKptEN"},"source":["\n","\n","Tenga en cuenta que a comparación de la gráfica en la **sección 4**, está gráfica está invertida, pues, KNN tiene mayor complejidad con menor número de vecinos a considerar.\n","\n","A continuación, se muestra la frontera de decisión para el clasificador con número de vecinos $k=13$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIyhTQ7sDFzc"},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors=13)\n","knn.fit(X_train, y_train)\n","\n","plot_data(X_test, y_test, knn)"]},{"cell_type":"markdown","metadata":{"id":"ohztdJICWzK_"},"source":["# **Recursos adicionales**\n","---\n","Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *Scikit-learn* en la evaluación de la complejidad de sus modelos, además de material de apoyo teórico para reforzar estos conceptos:\n","\n","- [Scikit-learn - Underfitting vs Overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)\n","- [Machine Learning Mastery - Overfitting and Underfitting with machine learning algorithms](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/)\n","- [Deep Learning Book - Chapter 5 - Machine Learning Basics](https://www.deeplearningbook.org/contents/ml.html)\n","- [Elite Data Science - Overfitting in Machine Learning](https://elitedatascience.com/overfitting-in-machine-learning)"]},{"cell_type":"markdown","metadata":{"id":"-9TWW0YTWyML"},"source":["# **Créditos**\n","---\n","\n","* **Profesor:** [Fabio Augusto González](https://dis.unal.edu.co/~fgonza/)\n","* **Asistentes docentes:**\n","  * Miguel Angel Ortiz Marín\n","  * Alberto Nicolai Romero Martínez\n","\n","**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"]}],"metadata":{"colab":{"collapsed_sections":["dqKR8J6k_PRh"],"toc_visible":true,"provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}