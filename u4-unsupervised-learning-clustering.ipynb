{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fb9pUStUq6xf"},"source":["<img src = \"https://drive.google.com/uc?export=view&id=102yRp1NqZJ12212QaersRTNL5_ZxieKX\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"]},{"cell_type":"markdown","metadata":{"id":"cSxJU721MNoF"},"source":["# **Aprendizaje no supervisado: agrupamiento**\n","---\n","\n","Los métodos discutidos hasta ahora dependen de datos etiquetados para generar sus predicciones. El **aprendizaje no supervisado** es una tarea en donde se busca aprender propiedades o patrones de un conjunto de datos sin un objetivo sobre el cuál validar si la tarea se realizó de la manera adecuada. Estos grupos de objetos se deben crear de tal forma en que los objetos del mismo grupo sean similares entre sí y sean diferentes a los objetos de otros grupos.\n","\n","En este material se discutirá el agrupamiento o *clustering*, una tarea no supervisada en donde se busca distinguir y agrupar objetos físicos o abstractos en clases de objetos **similares**. Algunos ejemplos de tareas o aplicaciones de *clustering* son:\n","\n","- Distinguir taxonomías en biología con agrupaciones por similitud biológica o incluso genética.\n","- Identificar páginas web similares para estructurar resultados de búsquedas\n","- Segmentación de clientes o usuarios por un criterio de similitud definido.\n","\n","\n","\n","El *clustering* es una tarea **no supervisada**, pues no sabemos _a priori_ cómo clasificar nuestros objetos, y **no completamente definida**, pues se plantean las preguntas:\n","\n","- ¿Cómo cuantificamos el ***desempeño*** de un resultado de *clustering*?\n","- ¿Qué definición de ***similitud*** establecemos?\n","  "]},{"cell_type":"markdown","metadata":{"id":"i0sRGgMB2FUF"},"source":["# **1. Dependencias**\n","---\n","Importamos las librerías necesarias y definimos algunas funciones básicas de visualización que vamos a usar en algunos ejemplos.\n"]},{"cell_type":"markdown","metadata":{"id":"qJgGczNUDVUN"},"source":["### **1.1. Dependencias**\n","---\n","Para la construcción de modelos y ejecución de procedimientos metodológicos de aprendizaje automático, utilizaremos la librería _Scikit-learn_ (**`sklearn`**) y varias de sus funciones y conjuntos de datos."]},{"cell_type":"code","source":["!pip install --upgrade matplotlib seaborn"],"metadata":{"id":"o4P6XPQoc-F1"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1A1bWvdAsW_B"},"source":["# Actualizamos scikit-learn a la última versión\n","!pip install -U scikit-learn\n","\n","# Importamos scikit-learn\n","import sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h0jic_vwJv9c"},"source":["Importamos además algunas librerías básicas y configuraciones de *Python*."]},{"cell_type":"code","metadata":{"id":"H5lk0elTiFy_"},"source":["# Librerías básicas NumPy, Pandas, Matplotlib y Seaborn.\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import seaborn as sns\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nmx-RGqF8Hls"},"source":["# Configuraciones para las librerías y módulos usados.\n","\n","# Ignoramos las advertencias o warnings.\n","import warnings\n","warnings.simplefilter(action='ignore')\n","\n","# Configuramos el formato por defecto de la\n","# librería de visualización Matplotlib.\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","mpl.rcParams['figure.dpi'] = 105\n","mpl.rcParams['figure.figsize'] = (9, 7)\n","sns.set_theme()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmFrETF-Osjj"},"source":["### **1.2. Funciones de utilidad y visualización**\n","---\n","\n","Para ilustrar los ejemplos discutidos en este material utilizaremos algunas funciones que permiten visualizar de manera general los datos, junto a las funciones de predicción obtenidas con cada modelo.\n","\n","> **Nota**: *Matplotlib* y *Seaborn* se encuentran por fuera del alcance de este módulo. No es necesario que entienda estas funciones en detalle para sacar partido del resto del contenido puesto a su disposición. Usted decide si leer o no estas funciones en profundidad. Si decide omitir esta sección, continúe directamente con la siguiente sección, en donde se discutirán los conjuntos de datos que vamos a utilizar."]},{"cell_type":"code","metadata":{"id":"c5-HM-xXIRxb"},"source":["# Visualizar el resultado del agrupamiento con el algoritmo K-means para 8 valores de k.\n","\n","from google.colab import widgets\n","\n","def experiment_number_of_clusters(X, clustering, show_metric=None,\n","                                  plot_data=True, plot_centers=True, plot_boundaries=False):\n","\n","    tb = widgets.TabBar([f'k = {k}'for k in range(2,10)])\n","    for i, n_clusters in enumerate(range(2,10)):\n","        with tb.output_to(i, select= (i < 1)):\n","          clustering.n_clusters = n_clusters\n","          y = clustering.fit_predict(X)\n","\n","          cm = 'tab10'\n","          fig, ax = plt.subplots(figsize=(8, 6))\n","          plot_cluster_predictions(clustering, X, n_clusters, cm,\n","                                  plot_data, plot_centers, show_metric, ax = ax)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dn0e_wcxhUi2"},"source":["# Visualizar el resultado del agrupamiento con el algoritmo AgglomerativeClustering  para 8 valores de k.\n","\n","from google.colab import widgets\n","\n","def experiment_hyerarchical(X, show_metric=None,\n","                                  plot_data=True, plot_centers=True):\n","\n","    tb = widgets.TabBar([f'KN = {k}'for k in [1, 2, 3, 90]])\n","    for i, kn in enumerate([1, 2, 3, 90]):\n","        with tb.output_to(i, select= (i < 1)):\n","          knn_graph = kneighbors_graph(X, kn, include_self=False)\n","\n","          cm = 'tab10'\n","          fig, ax = plt.subplots(figsize=(8, 6))\n","          plot_cluster_predictions(AgglomerativeClustering(connectivity=knn_graph, linkage=\"average\"), X,\n","                              n_clusters=2, show_metric='silueta', ax = ax)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQp3ULXQIQAC"},"source":["# Gráfica individual del resultado de un agrupamiento.\n","from sklearn.metrics import silhouette_score\n","\n","def plot_cluster_predictions(clustering, X, n_clusters = None, cmap = 'tab10',\n","                             plot_data=True, plot_centers=True, show_metric=None,\n","                             title_str=\"\", ax = None):\n","\n","    assert not hasattr(clustering, \"n_clusters\") or \\\n","           (hasattr(clustering, \"n_clusters\") and n_clusters is not None), \"must specify `n_clusters` for \"+str(clustering)\n","\n","    if n_clusters is not None:\n","        clustering.n_clusters = n_clusters\n","\n","    y = clustering.fit_predict(X)\n","    # remove elements tagged as noise (cluster nb<0)\n","    X = X[y>=0]\n","    y = y[y>=0]\n","\n","    if n_clusters is None:\n","        n_clusters = len(np.unique(y))\n","\n","    if ax is None:\n","        ax = plt.gca()\n","\n","    if plot_data:\n","        sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, palette=cmap,\n","                            legend=False, alpha=.5, ax=ax, s=40)\n","\n","    if plot_centers and hasattr(clustering, \"cluster_centers_\"):\n","        sns.scatterplot(x=clustering.cluster_centers_[:,0],\n","                    y=clustering.cluster_centers_[:,1], hue = np.unique(y), s=180,  lw=3,\n","                    palette=cmap,\n","                    edgecolor=\"black\", legend = False, ax = ax)\n","\n","    if show_metric is not None:\n","        if show_metric == 'inercia' and hasattr(clustering, 'inertia_'):\n","          inertia = clustering.inertia_\n","          ax.set_title(\"Inercia = {:.0f}\".format(inertia)+ title_str, fontdict=dict(family = 'serif', size = 20))\n","        elif show_metric == 'silueta':\n","          sc = silhouette_score(X, y) if len(np.unique(y)) > 1 else 0\n","          ax.set_title(\"Coeficiente de silueta = {:.3f}\".format(sc)+ title_str, fontdict=dict(family = 'serif', size = 20))\n","    else:\n","        ax.set_title(\"k={}\".format(n_clusters) +title_str, fontdict=dict(family = 'serif', size = 20))\n","\n","    plt.axis(\"off\")\n","\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbUE0VoGMZo4"},"source":["# Gracicar la curva de aprendizaje de determinada métrica de agrupamiento.\n","\n","def plot_metric(K, scores, metric_name):\n","  plt.figure(dpi=110, figsize=(9, 5))\n","  plt.plot(K, scores, 'bx-')\n","  plt.xticks(K); plt.xlabel('$k$', fontdict=dict(family = 'serif', size = 14));  plt.ylabel(metric_name, fontdict=dict(family = 'serif', size = 14));\n","  plt.title(f'K vs {metric_name}', fontdict=dict(family = 'serif', size = 18))\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RURwOVpHIb2P"},"source":["# **2. Conjuntos de datos**\n","---\n","\n","Para los ejemplos desarrollados en el transcurso de material, se usarán datos de  *Scikit-Learn* de carácter real (usando *Loaders*) y sintético (usando *Generators*).\n","\n","Usaremos el *dataset* *Iris* para mostrar un ejemplo de evaluación externa, el *dataset* [Titanic](https://www.kaggle.com/c/titanic) para mostrar un ejemplo de aplicación y finalmente usaremos un conjunto de datos artificial que cargaremos desde una URL remota."]},{"cell_type":"markdown","metadata":{"id":"Bylg7mvYMB_o"},"source":["Cargamos *Iris* usando el módulo **`sklearn.datasets`**."]},{"cell_type":"code","metadata":{"id":"aLE4pNZ_MGtg"},"source":["from sklearn.datasets import load_iris\n","iris = load_iris()\n","\n","print(iris.DESCR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WAVA2PHfMikG"},"source":["Cargamos el *dataset* *Titanic* desde una Google drive remoto con *gdown*:"]},{"cell_type":"code","metadata":{"id":"ujjsuC-SMnHB"},"source":["# Id remoto del conjunto de datos Titanic.\n","!gdown --id 19ciOuzzyxN-Ht03lBwHAqEyrsmWBUhDK\n","titanic_df = pd.read_csv('titanic.csv')\n","\n","titanic_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VqqaWrY2OgqG"},"source":["Retomaremos los conjuntos de datos de medias lunas y de *blobs* de *Scikit-Learn*:"]},{"cell_type":"code","metadata":{"id":"vbA6uf_qNL0O"},"source":["from sklearn.datasets import make_blobs, make_moons\n","\n","X_blobs, y_blobs = make_blobs(centers = 2, random_state= 321)\n","X_moons, y_moons = make_moons(noise = 0.1, random_state= 123)\n","\n","fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (10, 4))\n","\n","sns.scatterplot(x = X_blobs[:, 0], y = X_blobs[:, 1], hue = y_blobs, ax = ax1);\n","sns.scatterplot(x = X_moons[:, 0], y = X_moons[:, 1], hue = y_moons, ax = ax2);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xJ5eb1dGtccC"},"source":["Cargamos el conjunto de datos artificial usando *Pandas*."]},{"cell_type":"code","metadata":{"id":"sLBSEHMspmdB"},"source":["url = 'https://gist.githubusercontent.com/fagonzalezo/d4c3992ba89f7598a75adc5290531451/raw/de2edd17e526a96ff9e063c9014f7e0c4a06e922/cluster1.csv'\n","cluster_df = pd.read_csv(url)\n","X_cluster = cluster_df.values\n","\n","X_cluster.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JL8bk_FgbKsO"},"source":["# **3. Métodos basados en centroides - `KMeans`**\n","---\n","> **¿Qué grupos identifica en la siguiente gráfica y cómo se puede automatizar el proceso?**\n","\n","Los humanos poseen la capacidad de inferir rápidamente grupos gracias a su intuición y poderoso sistema visual. Sin embargo, para conjuntos de datos más complejos se tienen que plantear técnicas para que un computador pueda resolver este tipo de problemas de manera automática."]},{"cell_type":"code","metadata":{"id":"6Y7HJ3MXbKr4"},"source":["url = 'https://gist.githubusercontent.com/fagonzalezo/d4c3992ba89f7598a75adc5290531451/raw/de2edd17e526a96ff9e063c9014f7e0c4a06e922/cluster1.csv'\n","cluster_df = pd.read_csv(url)\n","X_cluster = cluster_df.values\n","\n","plt.scatter(X_cluster[:,0],\n","            X_cluster[:,1]);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RbBzUIU264ne"},"source":["El **algoritmo *k-means*** (o *k-medias*), es un método de agrupamiento que supone que los grupos (*clusters*) están representadas por un prototipo o elemento representativo, que corresponde al centroide del conjunto de datos. Es un algoritmo iterativo que en cada iteración asigna los elementos al centroide más cercano y recalcula los centroides de acuerdo con los nuevos elementos asignados a cada grupo."]},{"cell_type":"markdown","metadata":{"id":"4i1KLWRObKsE"},"source":["La idea general del algoritmo se puede ver en forma de *pseudo-código*:\n","```\n","Entrada:\n","    X: Datos a agrupar.\n","    k: Número de clusters deseados.\n","    \n","Algoritmo:\n","    1. Se seleccionan k centroides aleatoriamente.\n","    2. Se repite hasta que los k centroides no cambien:\n","    3.    Se establecen k clusters asignando cada dato al centroide más cercano.\n","    4.    Se recalcula el centroide de cada cluster como el promedio (mean) de los datos.\n","```"]},{"cell_type":"markdown","metadata":{"id":"yv8upixoN95p"},"source":["En los siguientes videos podrá ver de manera gráfica el concepto del algoritmo aplicado:"]},{"cell_type":"code","metadata":{"id":"jh6JoELTzKS6","cellView":"form"},"source":["#@markdown **Animación: Algoritmo *K-means***\n","\n","from IPython.display import HTML\n","\n","HTML('<iframe style=\"width:768px; height: 432px;\" src=\"https://drive.google.com/file/d/1YwiKTNqoHNtovepfS8aGZyF25M0KMMCN/preview\"></iframe>')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svwEiJchbKsG","cellView":"form"},"source":["#@markdown **Video: Ejemplo de agrupamiento con *K-means***\n","\n","from IPython.display import HTML\n","HTML('<iframe width=\"758\" height=\"432\" src=\"https://www.youtube.com/embed/BVFG7fd1H30\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8hxmNVpOkv1"},"source":["Podemos usar el método de *Scikit-Learn* **`sklearn.cluster.KMeans`** para ejecutar este algoritmo en nuestros datos. El siguiente código aplica el algoritmo *k-means* al conjunto de datos artificial. Puesto que es un modelo no supervisado, la función **`fit`** solo recibe como argumento los datos de entrada, no las etiquetas. La función **`predict`** asigna *clusters* a los ejemplos, y se usa tanto en los datos de entrenamiento como en ejemplos nuevos."]},{"cell_type":"code","metadata":{"id":"lHPYZno3bKsR"},"source":["# Métodos de agrupamiento - Algoritmo K-means\n","from sklearn.cluster import KMeans\n","\n","# Número de clusters que se desea generar.\n","n = 2\n","\n","km = KMeans(n_clusters = n)\n","km.fit(X_cluster)\n","\n","y = km.predict(X_cluster)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ayI-JL-pSUoj"},"source":["Usamos **`pandas`** para contar el número de elementos en cada cluster:"]},{"cell_type":"code","metadata":{"id":"LfZdXMWUbKsX"},"source":["pd.Series(y).value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kxQblS38SdTW"},"source":["Las coordenadas de los centroides se pueden obtener con el atributo **`cluster_centers_`**:"]},{"cell_type":"code","metadata":{"id":"EG5yq8UAbKsj"},"source":["km.cluster_centers_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6eTJvMDISqdM"},"source":["El siguiente código dibuja los datos agrupados junto con los centroides:"]},{"cell_type":"code","metadata":{"id":"UuD-lZC3YqQv"},"source":["plt.figure(dpi = 110)\n","sns.scatterplot(x = X_cluster[:,0], y = X_cluster[:,1], hue = y)\n","plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1],\n","            marker=\"x\", lw=3, s=200, color = 'k')\n","\n","plt.legend(title = 'Clusters'); plt.xlabel(\"Eje x\"); plt.ylabel(\"Eje y\");"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SPGvaKWMdUgV"},"source":["Podemos ver los parámetros usados por el modelo con **`.get_params()`**."]},{"cell_type":"code","metadata":{"id":"f77P3ufDbKs6"},"source":["km.get_params()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JX4CWCBZbKtT"},"source":["La función **`experiment_number_of_clusters`** (definida al principio del notebook) muestra resultados con diferente número de *clusters*:"]},{"cell_type":"code","metadata":{"id":"pLnsXqoebKts"},"source":["experiment_number_of_clusters(X_cluster, KMeans())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckcwLoosbKty"},"source":["Ahora veamos el resultado al aplicar el algoritmo en otros conjuntos de datos sintéticos como **`make_blobs`**.\n","Cambie **`cluster_std`** y **`centers`** en **`make_blobs`** para generar *datasets* con distintas distribuciones.\n","\n","**¿Cuál es el número de clusters _natural_ que usarías? ¿por qué es _natural_?**"]},{"cell_type":"code","metadata":{"id":"4glhkqM9bKt0"},"source":["# Conjunto de datos blobs.\n","from sklearn.datasets import make_blobs\n","\n","X,_ = make_blobs(500, cluster_std=1.5, centers=3)\n","\n","experiment_number_of_clusters(X, KMeans())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zdeMOewPbKt-"},"source":["## **3.1. Selección del número de *clusters***\n","---\n","\n","Si bien para un humano es intuitivo, para conjuntos de datos más grandes, con más dimensiones y para hacerlo de manera automática necesitamos usar otros criterios. Para esto necesitamos usar una medida objetiva de la calidad de un *clustering*. Estas medidas se encuentran definidas en el paquete [**`sklearn.metrics.cluster`**](http://scikit-learn.org/stable/modules/classes.html#clustering-metrics). Algunas medidas son supervisadas y otras no-supervisadas:\n","*  **Medidas supervisadas**: Utilizan las etiquetas reales de los ejemplos para analizar la correspondencia entre *clusters* y clases.\n","* **Medidas no-supervisadas**: Calculan medidas basadas en las distancias intra-cluster y/o inter-cluster.\n","\n","En este material se discutirán las medidas no-supervisadas, partiendo del hecho en que en este tipo de tareas no siempre es posible contar con la etiqueta real de los datos."]},{"cell_type":"markdown","metadata":{"id":"olMQ5mrafaVB"},"source":["#### **3.1.1. Inercia o distancia intra-cluster**\n","---\n","\n","La distancia **intra-cluster** mide qué tan compacto es cada *cluster* y se define como:\n","\n","$$\\sum_{i=0}^{n}\\min_{\\mu_j \\in C}(||x_i - \\mu_j||^2)$$\n","\n","*k-means* minimiza esta medida, lo cual la hace una buena candidata para evaluar la calidad de un *cluster*. Para esto ejecutamos *k-means* con diferentes valores de $k$ y graficamos el valor de la inercia. En esta gráfica buscamos un valor de $k$ tan pequeño como sea posible y que tenga un valor de la métrica bajo. A este tipo de gráfica se le conoce usualmente como **gráfica de codo**:"]},{"cell_type":"code","metadata":{"id":"S8fVslz3mH07","cellView":"form"},"source":["#@markdown **Video: Método del codo**\n","\n","from IPython.display import HTML\n","\n","HTML('<iframe style=\"width:768px; height: 432px;\" src=\"https://drive.google.com/file/d/1cRPD6BX26wEWf0yTeYcTKsV5o5f6RRUQ/preview\"></iframe>')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gu9PKOwYQAjy"},"source":["Para ilustrar este concepto, vamos a generar un modelo de agrupamiento para cada valor de $k$ entre $2$ y $15$. Al final de la generación, obtenemos el valor de la métrica de inercia con el atributo **`intertia_`**."]},{"cell_type":"code","metadata":{"id":"1P0-z9ywm5xf"},"source":["X,_ = make_blobs(500, cluster_std=1.5, centers=6, random_state=10)\n","\n","sum_of_squared_distances = []\n","K = range(2,15)\n","for k in K:\n","    km = KMeans(n_clusters=k)\n","    km = km.fit(X)\n","    sum_of_squared_distances.append(km.inertia_)\n","\n","plot_metric(K, sum_of_squared_distances, 'Inercia')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QyaH83Krp_ks"},"source":["experiment_number_of_clusters(X, KMeans(), show_metric='inercia')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nzh6uLXEXcUE"},"source":["Ahora aplicamos la misma estrategia para el conjunto de datos artificial:"]},{"cell_type":"code","metadata":{"id":"6cnk986kq6G-"},"source":["sum_of_squared_distances = []\n","K = range(2,15)\n","for k in K:\n","    km = KMeans(n_clusters=k)\n","    km = km.fit(X_cluster)\n","    sum_of_squared_distances.append(km.inertia_)\n","\n","plot_metric(K, sum_of_squared_distances, 'Inercia')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_jRkFYfBbKuB"},"source":["experiment_number_of_clusters(X_cluster, KMeans(), show_metric='inercia')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZgthnBxvbLvk"},"source":["La gráfica de codo nos sugiere un valor de $k$ de 5 o 6. La razón es que hay un *cluster* mucho más grande que el otro. Esto evidencia algunos de los problemas que tiene la inercia o suma de distancia *intra-cluster*:\n","*  La inercia supone que los *clusters* son convexos e isotrópicos, lo que no siempre es así. Responde mal a los grupos alargados, o múltiples con formas irregulares.\n","* La inercia supone que los *clusters* son de tamaños similares, pues penaliza mucho más fuertemente *clusters* grandes.\n","* La inercia no es una métrica normalizada: solo sabemos que los valores más bajos son mejores y que el cero es el óptimo.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MTwVTSu5rD98"},"source":["#### **3.1.2. Coeficiente de silueta**\n","---\n","\n","El coeficiente de silueta combina la distancia media *intra-cluster* ($a$) y la distancia media al grupo más cercano ($b$) para cada muestra ($s_i$):\n","$$ s_i = \\frac{b - a}{\\max(a,b)}$$\n","\n","Es una medida que está entre $-1$ y $1$ para cada muestra. Un valor cercano a $1$ indica que la distancia inter-cluster es mucho más grande que la distancia intra-cluster. También indica que la muestra que estamos evaluando está en la frontera entre dos _clusters_.\n","\n","> **Nota**: Tenga en cuenta que el coeficiente de silueta solo tiene sentido cuando $2<=k<=n$ con $k$ siendo el número de clusters y $n$ el tamaño de la muestra.\n","\n","Para calcular el coeficiente de silueta del proceso de agrupamiento *sklearn* utiliza la media de cada valor de silueta $s_i$"]},{"cell_type":"code","metadata":{"id":"AkhNAfX12pYc"},"source":["# Métricas de rendimiento\n","from sklearn.metrics import silhouette_score\n","\n","X,_ = make_blobs(500, cluster_std=1.5, centers=6, random_state=10)\n","silhouette_scores = []\n","\n","K = range(2,15)\n","for k in K:\n","    km = KMeans(n_clusters=k)\n","    km = km.fit(X)\n","    y = km.predict(X)\n","    silhouette_scores.append(silhouette_score(X, y))\n","\n","plot_metric(K, silhouette_scores, 'Coeficiente de silueta')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MjW4SpOd3cCm"},"source":["En contraste con el diagrama de inercia donde buscamos el codo de la gráfica, aquí buscamos el valor máximo. Que en este caso se obtiene en $k = 5$. Para el segundo conjunto de datos tenemos:"]},{"cell_type":"code","metadata":{"id":"Otn6Sp6Z3wFA"},"source":["X = X_cluster\n","silhouette_scores = []\n","K = range(2,15)\n","\n","for k in K:\n","    km = KMeans(n_clusters=k)\n","    km = km.fit(X)\n","    y = km.predict(X)\n","    silhouette_scores.append(silhouette_score(X, y))\n","\n","plot_metric(K, silhouette_scores, 'Coeficiente de silueta')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OTCDuGByj-Iy"},"source":["En este caso el coeficiente de silueta máximo se alcanza en $k = 2$, que se ajusta más a lo esperado intuitivamente."]},{"cell_type":"markdown","metadata":{"id":"UbuFMHhtvCGo"},"source":["#### **3.1.3. Evaluación externa**\n","---\n","\n","En la evaluación externa se usan datos adicionales que no estaban disponibles durante el entrenamiento al algoritmo de agrupamiento. Por ejemplo, las categorías reales de los ejemplos. Este tipo de evaluación también se conoce como evaluación supervisada.\n","\n","En este caso usaremos *Iris* y evaluaremos el desempeño de _K-means_ sobre _Iris_ para varios valores de $k$ con varias métricas externas.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NpPm00pb0DXl"},"source":["# Partición en pruebas y entrenamiento.\n","from sklearn.model_selection import train_test_split\n","\n","iris = load_iris()\n","X_iris, y_iris = iris.data, iris.target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5PjeXTK1P-3"},"source":["Definimos la función **`plot_scores`** para graficar una métrica supervisada para varios valores de $k$."]},{"cell_type":"code","metadata":{"id":"a9rLUpeS1RDi"},"source":["def plot_extern_metric(X, y, metric, metric_name):\n","  scores = []\n","  for i in range(2,20):\n","    model = KMeans(n_clusters=i, random_state=32)\n","    model.fit(X)\n","    y_pred = model.predict(X)\n","    scores.append(metric(y, y_pred))\n","\n","  plot_metric(range(2, 20), scores, metric_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cA4fERudyfkK"},"source":["##### **3.1.3.1. Homogeneidad**\n","---\n","\n","Para calcular la homogeneidad del proceso de agrupamiento, cada grupo es asociado con la clase mayoritaria; luego, La métrica se evalúa contando el número de ejemplos clasificados correctamente y dividiendo por N _(Manning, Raghavan & Schütze, 2008)_.\n","\n","En este caso está acotada entre $0$ y $1$. Un valor cercano a $1$ nos indicará que las muestras de un *cluster* dado pertenecen en su mayoría a una sola clase.\n","\n","*Scikit-learn* implementa el método **`homogeneity_score`** en el paquete **`metrics`**.\n","\n","Después de importar la métrica, la usamos con la función **`plot_scores`**.\n"]},{"cell_type":"code","metadata":{"id":"2FmEKPQrvpHa"},"source":["from sklearn.metrics import homogeneity_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QadE1PXV6Qqx"},"source":["plot_extern_metric(X_iris, y_iris, homogeneity_score, 'Homogeneidad')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SCWbGCEC6sqr"},"source":["Podemos ver que se tendría que aplicar un análisis como el método del codo para determinar el número óptimo de clusters. En este caso se puede observar que luego de $8$ clusters la medida de homogeneidad llega a un punto de codo invertido. En este caso valores de $k$ entre $7$ y $8$ serían correctos.\n","\n","Debemos tener en cuenta que la homogeneidad no es una medida simétrica, y si cambiamos **`y_true`** con **`y_pred`**, la función dará el puntaje de\n","[completitud de los *clusters*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score)."]},{"cell_type":"markdown","metadata":{"id":"Kd6n_b1gzje9"},"source":["##### **3.1.3.2. Información mutua**\n","---\n","\n","La información mutua es una medida de la similitud entre dos etiquetas de los mismos datos. Es una métrica simétrica, si se cambian las posiciones de **`y_true`** y **`y_pred`** la métrica retorna el mismo valor. La información mutua tiene una importante interpretación en la teoría de la información. En términos de teoría de la información, esta medida nos da qué tanta información ganamos de una variable no observada al observar una variable relacionada.\n","\n","*Scikit-Learn* implementa **`mutual_info_score`** en el paquete **`metrics`**.\n","\n","Después de importar la métrica la usamos con la función **`plot_scores`**.\n"]},{"cell_type":"code","metadata":{"id":"sd5SoX_w0xsR"},"source":["from sklearn.metrics import mutual_info_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"prerHQapQh7_"},"source":["plot_extern_metric(X_iris, y_iris,\n","            mutual_info_score, 'Información mutua')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PQk1VRZ_62pp"},"source":["Podemos ver que se tendría que aplicar un análisis como el método del codo para determinar el número óptimo de clusters. En este caso podemos observar que el valor de cambio es $7$. En este caso la medida nos dice que al tener $7$ clusters, obtenemos casí el máximo información posible."]},{"cell_type":"markdown","metadata":{"id":"DilkLIoa2ZKi"},"source":["##### **3.1.3.3. Índice de Rand**\n","---\n","El **índice de *Rand*** computa una medida de similitud entre dos agrupamientos al considerar todas las parejas de ejemplos, contando el número de ejemplos que pertenecen al mismo grupo y los que no en el agrupamiento real y en el predicho.\n","\n","*Scikit-learn* implementa **`adjusted_rand_score`** en el paquete **`metrics`**. Esta implementación es una versión corregida del índice de _Rand_ que tiene en cuenta el \"*chance*\", es decir la aleatoriedad de los agrupamientos. Agrupamientos aleatorios tienen un índice de _Rand_ ajustado cercanos a $0$, con $1$ siendo un agrupamiento perfecto.\n","\n","Después de importar la métrica la usamos con la función **`plot_scores`**."]},{"cell_type":"code","metadata":{"id":"tJ4pfRA91J_m"},"source":["from sklearn.metrics import adjusted_rand_score\n","\n","plot_extern_metric(X_iris, y_iris,\n","            adjusted_rand_score, 'Índice de Rand ajustado')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pYhs-D-575yG"},"source":["Podemos ver que el índice de *Rand* es una métrica que buscamos máximizar, en este caso escogeríamos $k=3$."]},{"cell_type":"markdown","metadata":{"id":"NRy56Glu2UdV"},"source":["##### **3.1.3.4. Matriz de Contingencia**\n","---\n","\n","Una matriz de contingencia es una matriz similar a la matriz de confusión que muestra la relación entre las etiquetas asignadas para cada grupo y las etiquetas reales.\n","\n","*Scikit-learn* implementa **`contigency_matrix`** en el paquete **`metrics.cluster`**.\n","\n","Definimos la función **`show_contigency_matrix`** para entrenar un modelo **`KMeans`**, calcular la matriz de contigencia y retornarla como un objeto **`DataFrame`** de *Pandas*, lo que facilita su visualización."]},{"cell_type":"code","metadata":{"id":"fwpR73op2qWd"},"source":["from sklearn.metrics.cluster import contingency_matrix\n","\n","def show_contigency_matrix(X, y, n_clusters, classes):\n","  # Fijamos la semilla aleatoria para obtener resultados reproducibles.\n","  model = KMeans(n_clusters, random_state=32)\n","  model.fit(X)\n","  y_pred = model.predict(X)\n","  mat = contingency_matrix(y, y_pred)\n","  columns = ['Cluster ' + str(i) for i in range(n_clusters)]\n","\n","  # Se retorna cómo un DataFrame de Pandas para mejorar la visualización.\n","  return pd.DataFrame(mat, columns=columns, index=classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R6KRwT2b_axy"},"source":["Como hemos visto (y también de manera intuitiva), un valor de $k$ bueno es 3 o 4.\n","\n","Ejecute las siguientes celdas para ver la matriz de contingencia para $k=3$ y $k=4$."]},{"cell_type":"code","metadata":{"id":"k1zIkG0W_ZqE"},"source":["show_contigency_matrix(X_iris, y_iris, 3, iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_hSl8qt6_4xf"},"source":["Podemos ver que el grupo $0$ corresponde a la especie _setosa_ (clase $0$), el grupo $1$ corresponde mayormente a la especie _virginica_ (clase $2$), y el grupo $2$ corresponde a la especie _versicolor_ principalmente (clase _1_).\n","\n","El orden de los grupos y las clases no corresponden, esto tiene sentido, pues **`KMeans`** no tuvo acceso a las etiquetas durante el entrenamiento."]},{"cell_type":"code","metadata":{"id":"Vhzxgm1o5FV_"},"source":["show_contigency_matrix(X_iris, y_iris, 4, iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SwDWKNq9_xhD"},"source":["Si lo intentamos con un total de $4$ grupos, podemos ver que el grupo $0$ y el grupo $3$ corresponden a _versicolor_ (clase $1$), el grupo $1$ corresponde mayormente a la especie _setosa_ y el grupo $2$ corresponde principalmente a la especie _virginica_."]},{"cell_type":"markdown","metadata":{"id":"o-RS3bQBbKvV"},"source":["# **4. Métodos jerárquicos basados en conectividad - `AgglomerativeClustering`**\n","---\n","Para los dos *dataset* anteriores los resultados obtenidos son apropiados, aunque requieren de un buen uso de las métricas para obtener el número $k$ de *clusters* que se deben generar. Ahora, apliquemos el algoritmo en el *dataset* sintético de medias lunas con la función **`make_moons`**.\n","\n"]},{"cell_type":"code","metadata":{"id":"nNm3FDFWbKul"},"source":["from sklearn.datasets import make_moons\n","X,_ = make_moons(500, noise=.1)\n","\n","plot_cluster_predictions(KMeans(), X, n_clusters=2, cmap='seismic', show_metric='silueta')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBSB59YT4hrP"},"source":["Los grupos en este *dataset* no son convexos, por lo que *k-means* no es el mejor acercamiento al problema. Cuando los *clusters* no son globulares, otros métodos pueden producir mejores resultados."]},{"cell_type":"markdown","metadata":{"id":"XgwR6Z3nM3eR"},"source":["Los métodos de agrupamiento **basados en conectividad** utilizan relaciones de vecindad entre los elementos para encontrar grupos. Estos métodos requieren construir una matriz de conectividad de los puntos. La función **`kneighbors_graph`** del paquete **`neighbors`** construye una matriz basada en los $k$ vecinos más cercanos de cada punto."]},{"cell_type":"code","metadata":{"id":"Y7HNssUQbKvV"},"source":["X, _ = make_moons(500, noise=.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLgk8v8Aa93C"},"source":["Con la siguiente celda puede visualizar los K vecinos más cercanos de un punto seleccionado al azar."]},{"cell_type":"code","metadata":{"id":"zsRILWy3bKva"},"source":["from sklearn.neighbors import kneighbors_graph\n","\n","# Obtenemos el grafo de k- vecinos más cercanos por punto.\n","knn_graph = kneighbors_graph(X, 20, include_self=False)\n","\n","# Obtenemos los n (20) vecinos más cercanos de un punto al azar\n","i = np.random.randint(len(X))\n","nn = X[knn_graph[i].toarray()[0].astype(bool)]\n","\n","# Graficamos (en azul) 20 puntos más cercanos.\n","plt.scatter(nn[:,0], nn[:,1], color=\"darkblue\", alpha=1)\n","\n","# Graficamos el resto de punto con menos opacidad.\n","plt.scatter(X[:,0], X[:,1], color=\"blue\", alpha=.2)\n","\n","# Graficamos (en rojo) el punto sobre el cual se evalúa la cercanía.\n","plt.scatter(X[i,0], X[i,1], s=150, color=\"red\")\n","\n","plt.xlim(np.min(X[:,0])-.1, np.max(X[:,0])+.1); plt.ylim(np.min(X[:,1])-.1, np.max(X[:,1])+.1);\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eeoGI88TbKvg"},"source":["Usamos esta matriz de conectividad para suministrar información de estructura al algoritmo. En este caso vamos a usar el algoritmo de *clustering* aglomerativo **`AgglomerativeClustering`**. Este recibe como argumento el grafo de conectividad (**`connectivity`**) y el criterio de enlazamiento entre grupos (**`linkage`**)."]},{"cell_type":"code","metadata":{"id":"LkBz9SEqbKvi"},"source":["from sklearn.cluster import AgglomerativeClustering\n","\n","X,_ = make_moons(500, noise=.05)\n","knn_graph = kneighbors_graph(X, 20, include_self=False)\n","\n","# Declaramos el modelo\n","ac = AgglomerativeClustering(connectivity=knn_graph, linkage=\"average\")\n","\n","plot_cluster_predictions(ac, X, n_clusters=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PCSwF1kIaWQF"},"source":["Cómo podemos ver, el método jerárquico se desempeña mucho mejor con las media lunas. El algoritmo **`AgglomerativeClustering`** realiza un agrupamiento jerárquico de la siguiente manera:\n","\n","- Cada ejemplo empieza en su propio grupo, y los grupos son fusionados iterativamente.\n","\n","- Los dos grupos que son fusionados en cada iteración dependen del criterio de enlazamiento, el cuál es definido por el parámetro **`linkage`**.\n","\n","En este caso usamos el criterio de enlazamiento promedio (**`linkage = \"average\"`**). Este criterio minimiza el promedio de la distancia entre todos los ejemplos de cada par de grupos.\n","\n","A continuación, podemos ver cómo los grupos encontrados por el algoritmo varía dependiendo del tamaño de la vecindad."]},{"cell_type":"code","metadata":{"id":"SAOoDMMkjCh9"},"source":["experiment_hyerarchical(X, show_metric='silueta')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZHMk5D22ZhOs"},"source":["# **5. Ejemplo de aplicación: `Titanic`**\n","---\n","\n","El 15 de abril de 1912, durante su viaje inaugural, el ampliamente considerado \"insumergible\" RMS Titanic se hundió después de chocar con un iceberg. Desafortunadamente, no había suficientes botes salvavidas para todos a bordo, resultando en la muerte de 1502 de 2224 pasajeros y tripulación.\n","\n","Aunque había un elemento de suerte en la supervivencia, parece que algunos grupos de personas tenían más probabilidades de sobrevivir que otros.\n","\n","Para finalizar este notebook se mostrará un ejemplo con el conjunto de datos [Titanic](https://www.kaggle.com/c/titanic), disponible en _Kaggle_.\n","\n","Utilizando _Scikit-learn_ veremos un ejemplo del análisis de grupos y la supervivencia de estos. Este ejemplo incluye:\n","\n","- Preprocesamiento (**`OneHotEncoder`**, **`StandardScaler`** y **`ColumnTransformer`**) .\n","- Agrupamiento con **`KMeans`**.\n","- Evaluación del desempeño externa e interna.\n","- Interpretación de los centroides."]},{"cell_type":"markdown","metadata":{"id":"I65pi2b7j9JA"},"source":["## **5.1. Cargar el conjunto de datos**\n","---\n","\n","Usando un *Id* público de google drive para cargar el conjunto de datos:"]},{"cell_type":"code","metadata":{"id":"QMTh4Dm9BAkT"},"source":["# Id remota del conjunto de datos Titanic.\n","!gdown --id 19ciOuzzyxN-Ht03lBwHAqEyrsmWBUhDK\n","titanic_df_raw  = pd.read_csv('titanic.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pK1yBPyYDxhM"},"source":["\n","El conjunto de Titanic cuenta con las siguientes características:\n","\n","| Variable | Definición\t| Valores |\n","| --- | --- | --- |\n","| survival | \tSupervivencia  | \t0 = No, 1 = Sí |\n","| pclass \t| Clase del tiquete | \t1 = 1ra, 2 = 2da, 3 = 3ra\n","| sex \t| Sexo \t| |\n","| Age |\tEdad en años \t| |\n","| sibsp |\t# de hermanos / cónyuge abordo del Titanic \t| |\n","| parch |\t# de padres / hijos abordo del Titanic \t| |\n","| ticket |\tNúmero del ticket | |\n","| fare \t| Costo del ticket | |\n","| cabin |\tNúmero de la cabina \t| |\n","| embarked |\tPuerto de embarque |\tC = Cherbourg, Q = Queenstown, S = Southampton |"]},{"cell_type":"markdown","metadata":{"id":"U2OBC3EZktaw"},"source":["Veamos datos básicos del conjunto de datos con ayuda de **`info`**:"]},{"cell_type":"code","metadata":{"id":"eEjljzxKks68"},"source":["titanic_df_raw.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fgAJWA40WkQL"},"source":["No utilizaremos todas las características de *Titanic*, y nos limitaremos al subconjunto de características:\n","```python\n","['Embarked', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Survived', 'Age']\n","```\n","\n","Excluimos la característica **`Cabin`** por simplicidad, pues esta cuenta con muchos valores faltantes."]},{"cell_type":"code","metadata":{"id":"IaNmQsOTCzAP"},"source":["features = ['Embarked', 'Sex', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Survived', 'Age']\n","titanic_df = titanic_df_raw[features].dropna(axis=0)\n","\n","# Visualizamos nuevamente la información del conjunto de datos resultante:\n","titanic_df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-US0eVEXozsp"},"source":["Como podemos ver, **`Embarked`** y **`Sex`** son variables categóricas y el resto son numéricas. Esta información es necesaria para entender el ejemplo.\n","\n","Antes de proceder con el preprocesamiento, convertimos los datos a la forma **`X, y`**.\n","\n","Tenga en cuenta que en muchos casos no se cuenta con etiquetas en los ejercicios de agrupamiento. Es decir, no se cuenta con un **`X`** y con un **`y`**.  Sin embargo, en este ejemplo usaremos la variable **`'Survived'`** para evaluar el desempeño de los agrupamientos de manera externa.\n","\n","Por esta razón no usaremos la variable **`Survived`** durante el entrenamiento, pero si en la evaluación."]},{"cell_type":"code","metadata":{"id":"RwSf6SBJD-pk"},"source":["X_titanic = titanic_df.drop(['Survived'], axis=1)\n","y_titanic = titanic_df.Survived\n","\n","print(f'El shape de X_titanic es: {X_titanic.shape}')\n","print(f'El shape de y_titanic es: {y_titanic.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FljIWX-Pp2sH"},"source":["Observe que está vez no hemos convertido el *DataFrame* a un arreglo de *Numpy*, esto nos facilitará el preprocesamiento más adelante.\n","\n","La principal ventaja de esto es que nos permite usar los nombres de las características. De igual manera, cómo veremos, no tendremos que preocuparnos por concatenar los datos transformados (unos categóricos y otros numéricos)."]},{"cell_type":"markdown","metadata":{"id":"iNed2Yd9nBHq"},"source":["## **5.2. Preprocesamiento**\n","---\n","\n","Para este ejemplo usaremos dos transformaciones conocidas: **`OneHotEncoder`** (para las características categóricas) y **`StandardScaler`** (para las características numéricas).\n","\n","Con el fin de simplificar el código usaremos **`ColumnTransformer`**. El objeto **`ColumnTransformer`** es una utilidad que permite aplicar distintas transformaciones a distintas columnas de un *DataFrame* de *Pandas*.\n","\n","Primero, importamos las clases que necesitamos:\n"]},{"cell_type":"code","metadata":{"id":"3GJITwWioI4z"},"source":["from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6_iMS4ZpLwh"},"source":["Definimos dos listas, una con los nombres de las características categóricas y otra con las características numéricas."]},{"cell_type":"code","metadata":{"id":"HPcpK3_mpJxH"},"source":["categoric = ['Embarked', 'Sex']\n","numeric = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hw9QOWyfqQgj"},"source":["Definimos nuestro **`ColumnTransformer`**:\n","\n","Podemos ver que recibe una lista de tuplas, cada tupla define una transformación a un conjunto de características (columnas).\n","\n","Las tuplas tienen la forma:\n","\n","```\n","('nombre', Transformación(), [característica_1, característica_2, ...])\n","```\n","\n","Donde el primer valor asigna el nombre de la transformación (lo usaremos más adelante), el segundo valor de la tupla define el tipo de transformación con un objeto de **`sklearn`** y el tercer valor corresponde a una lista con los nombres de las columnas a transformar.\n","\n","En nuestro caso, definimos dos transformaciones:\n","\n","- **`onehot`**: _One Hot Encoding_ para las características categóricas.\n","- **`scaler`**: Estandarización para las características numéricas.\n","\n","La intuición detrás de estandarizar las variables numéricas para **`KMeans`** proviene de que **`KMeans`** por defecto utiliza una métrica de distancia euclidiana, la cual es sensible a las unidades de las características. Es decir, una característica con alta varianza podría influir más en los resultados del agrupamiento. Con la estandarización nos aseguramos de que cada característica influye a la distancia de una manera similar.\n","\n","Cómo regla general, debería probar el desempeño de un agrupamiento sin preprocesamiento y compararlo con el desempeño de un agrupamiento con preprocesamiento."]},{"cell_type":"code","metadata":{"id":"eajhmfXLLnbh"},"source":["tf = ColumnTransformer([('onehot', OneHotEncoder(), categoric),\n","                        ('scaler', StandardScaler(), numeric)])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"msaHgDKFri-6"},"source":["Finalmente, aplicamos las transformaciones a el conjunto de datos:"]},{"cell_type":"code","metadata":{"id":"hrjPA1RoDLAR"},"source":["X_preprocessed = tf.fit_transform(X_titanic)\n","\n","print(f'El shape de X_titanic es: {X_titanic.shape}')\n","print(f'El shape de X_preprocessed es: {X_preprocessed.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9G66UEZJr2hm"},"source":["Podemos ver que pasamos de $7$ características a $10$. Esto se debe a que la característica **`Embarked`** cuenta con $3$ valores únicos y **`Sex`** con dos, es decir pasamos de $1$ característica para **`Embarked`** a $3$ (suma $2$) y de $1$ característica para **`Sex`** a $2$ (suma $1$).\n","\n","Podemos verificarlo con la función **`get_feature_names()`** de **`onehot`** (nuestro **`OneHotEncoder`**). Para acceder a **`onehot`** usamos el atributo **`named_transformers_`** de **`tf`** (nuestro **`ColumnTransformer`**):"]},{"cell_type":"code","metadata":{"id":"vZb56JLqFBVs"},"source":["onehot_categories = tf.named_transformers_['onehot'].get_feature_names_out()\n","\n","onehot_categories"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KOEknvVsssZs"},"source":["De esta manera, podemos interpretar un ejemplo del conjunto de datos transformado:\n","\n"]},{"cell_type":"code","metadata":{"id":"AWCdu48IEV35"},"source":["X_preprocessed[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBhBE5IAtxSY"},"source":["Los primeros $3$ valores corresponden a las $3$ variables del _One Hot Encoding_ de **`Embarked`** y las siguientes $2$ corresponden a el _One Hot Encoding_ de **`Sex`**.\n","\n","Las siguientes $5$ variables corresponden a la estandarización de las variables numéricas (en el orden de la lista **`numeric`**)."]},{"cell_type":"code","metadata":{"id":"hQHmR6t_t0Ax"},"source":["# Datos originales\n","titanic_df.loc[:5, numeric]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WHt8SlLq7qUV"},"source":["tf.named_transformers_['scaler']\n","# Datos originales\n","X_preprocessed[:5, 5:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2-K3JxZmDrO"},"source":["## **5.3. Evaluación del desempeño**\n","---\n","Procedemos a realizar la evaluación del desempeño interna y después la evaluación del desempeño externa."]},{"cell_type":"markdown","metadata":{"id":"Qug3LgrtmKSY"},"source":["### **5.3.1. Evaluación del desempeño interna (no supervisada)**\n","---\n","Con la siguiente celda podemos ver la curva de inercia y coeficiente de silueta:"]},{"cell_type":"code","metadata":{"id":"ALyg2RSoZrby"},"source":["inertia = []\n","silhouette = []\n","K = range(2, 15)\n","for i in K:\n","  # Declaramos y ejecutamos el algoritmo K-means.\n","  model = KMeans(n_clusters=i)\n","  model.fit(X_preprocessed)\n","\n","  # Predecimos las etiquetas de X_preprocessed.\n","  y = model.predict(X_preprocessed)\n","\n","  # Almacenamos la métrica de inercia y el coeficiente de silueta.\n","  inertia.append(model.inertia_)\n","  silhouette.append(silhouette_score(X_preprocessed, y))\n","\n","\n","plot_metric(K, inertia, 'Inercia')\n","plot_metric(K, silhouette, 'Coeficiente de silueta')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ZgzJO8uuS16"},"source":["A partir de la evaluación del desempeño interno, podríamos concluir que un buen número para $k$ es 3, el valor que maximiza el coeficiente de silueta."]},{"cell_type":"markdown","metadata":{"id":"HOerpADTmNLq"},"source":["### **5.3.2. Evaluación del desempeño externa (supervisada)**\n","---\n","Graficamos la homogeneidad:"]},{"cell_type":"code","metadata":{"id":"-whI7380P-ZL"},"source":["plot_extern_metric(X_preprocessed, y_titanic, homogeneity_score, 'Homogeneidad')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXMEdi1TvELL"},"source":["Graficamos la información mutua:"]},{"cell_type":"code","metadata":{"id":"adMAOTflQsCC"},"source":["plot_extern_metric(X_preprocessed, y_titanic, mutual_info_score, 'Información mutua')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-97xDDCvHoo"},"source":["Graficamos el índice de *Rand*:"]},{"cell_type":"code","metadata":{"id":"b7wTdRysQgQt"},"source":["plot_extern_metric(X_preprocessed, y_titanic, adjusted_rand_score, 'Índice de Rand')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOr5Vda8ufNI"},"source":["A diferencia de la evaluación del desempeño interna, la externa nos sugiere usar un valor de $k$ más grande.\n","\n","En este caso podríamos concluir que un buen valor para $k$ es $6$, el valor que maximiza el índice ajustado de _Rand_. Recuerde que el índice de _Rand_ es una medida de similitud entre los dos agrupamientos.\n","\n","Cabe aclarar que, la selección de $k$ depende del objetivo de análisis, si este tiene que ver con la supervivencia es mejor quedarse con $k=6$ sugerido por los métodos de evaluación externa."]},{"cell_type":"markdown","metadata":{"id":"qyYYbBtTlsSn"},"source":["## **5.4. Interpretación de los centroides**\n","---\n","\n","Para la interpretación de los centroides obtenidos en el proceso vamos a examinar los valores de los centroides encontrados por **`KMeans`** para conocer el prototipo de cada grupo. Si tomáramos el atributo **`cluster_centers`** sin más obtendríamos datos numéricos estandarizados, los cuales serían díficiles de interpretar.\n","\n","Para esto, definimos las funciones **`show_survival_ratios`**, que imprime la proporción de personas que sobrevivieron de cada grupo encontrado por **`KMeans`** y la función **`show_centroids`** que aplica la transformación inversa a la estandarización (**`scaler.inverse_transform`**) a las características numéricas de cada centroide, recolecta cada centroide en una lista y los retorna cómo un _DataFrame_ con las columnas correspondientes para facilitar la lectura.\n","\n","No se aplica una transformación inversa al _One Hot Encoding_, pues no estaría bien definido si los valores son distintos de $0$ y $1$. Los valores de un centroide del _One Hot Encoding_ se pueden interpretar como porcentajes de presencia de cada valor en un grupo.\n","\n","En cada función se redondean los valores a $5$ decimales para facilitar la lectura. Lea las implementaciónes con detenimiento:"]},{"cell_type":"code","metadata":{"id":"dpMPblHjV8ns"},"source":["def show_survival_ratios(X, y, k):\n","  # Se entrena KMeans con k grupos y random_state fijo para obtener resultados reproducibles.\n","  model = KMeans(n_clusters=k, random_state=32)\n","  model.fit(X_preprocessed)\n","\n","  # Obtenemos las etiquetas de grupo del modelo.\n","  y_pred = model.predict(X)\n","\n","  for i in range(k):\n","    # Ejemplos que pertenecen al i-esimo grupo.\n","    ids_group = y_pred == i\n","\n","    # Etiquetas reales de los ejemplos del grupo.\n","    labels_group = y[ids_group]\n","\n","    # Calculamos la proporción como la media, pues consiste en valores con 0 y 1.\n","    survival_ratio = np.round(np.mean(labels_group), 5)\n","    print(f'Proporción de supervivencia grupo {i}: {survival_ratio}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSSDziA3FELr"},"source":["def show_centroids(X, k, tf):\n","  # Se entrena KMeans con k grupos y random_state fijo para obtener resultados reproducibles.\n","  model = KMeans(n_clusters=k, random_state=32)\n","  model.fit(X_preprocessed)\n","\n","  # Guardamos scaler para usar la transformación inversa después.\n","  scaler = tf.named_transformers_['scaler']\n","\n","  # Inicializamos una lista de los centroides vacía.\n","  centroids = []\n","\n","  # Iteramos por cada centroide (con estandarización)\n","\n","  for centroid in model.cluster_centers_:\n","    # Creamos una copia del centroide, en otro caso podríamos sobrescribir los valores obtenidos en el entrenamiento.\n","    centroid_copy = centroid.copy()\n","    # Se aplica la transformación inversa a las características numéricas.\n","    centroid_copy[5:] = scaler.inverse_transform([centroid_copy[5:]])\n","    # Redondeamos y almacenamos el centroide.\n","    centroids.append(np.round(centroid_copy, 5))\n","\n","  # Definimos una lista con los nombres de las columnas correspondientes.\n","  columns = ['C', 'Q', 'S', 'female', 'male', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Age']\n","\n","  # retornamos un DataFrame\n","  return pd.DataFrame(centroids, columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8vQ5y2IH3vor"},"source":["Debido a los resultados de la evaluación del desempeño externa e interna, que indican que $3$ y $6$ son valores apropiados para $k$, mostramos los centroides para estas dos configuraciones:"]},{"cell_type":"markdown","metadata":{"id":"6gte1--hmRPV"},"source":["Visualizamos la matriz de contingencia junto con las funciones que se acaban de definir para $k=3$:"]},{"cell_type":"code","metadata":{"id":"kYJ9iDpZRYVb"},"source":["show_contigency_matrix(X_preprocessed, y_titanic, 3, ['Survived: False', 'Survived: True'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kWP1a8kTWJk"},"source":["show_survival_ratios(X_preprocessed, y_titanic, 3)\n","show_centroids(X_preprocessed, 3, tf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rGUwGzVX3_8e"},"source":["Podemos darnos cuenta de que los centroides muestran el valor medio de cada característica para las personas a el grupo.\n","\n","En el caso de las variables categóricas, los valores del centroide corresponden a las proporciones de personas con cada uno de los valores posibles."]},{"cell_type":"markdown","metadata":{"id":"S8rjZPRl4_jJ"},"source":["Una observación que se puede realizar es sobre el grupo $1$, este tiene la menor proporción de supervivencia ($0.27059$) y podemos observar que la proporción de puerto de embarcamiento (**`Embarked`**) para el valor **`S`** (Southampton) corresponde al $0.84471$.\n","\n","Es decir, una gran proporción de personas que embarcaron en *Southampton* no sobrevivieron."]},{"cell_type":"markdown","metadata":{"id":"FzNat_8olnPx"},"source":["Al igual que con $3$ grupos, visualizamos la matriz de contingencia junto con las funciones para $k=6$:"]},{"cell_type":"code","metadata":{"id":"mPeNOVRARdlI"},"source":["show_contigency_matrix(X_preprocessed, y_titanic, 6, ['Survived: False', 'Survived: True'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXDrc956VpW6"},"source":["show_survival_ratios(X_preprocessed, y_titanic, 6)\n","show_centroids(X_preprocessed, 6, tf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SoAOHnFg5phR"},"source":["Podemos observar, por ejemplo, el grupo $0$. Es el grupo con mayor proporción de supervivencia ($0.78125$). La mayoría de las personas de este grupo son mujeres, todos corresponden a pasajeros de primera clase y el valor promedio que pagaron por su tickete es el más elevado ($222.03463$) de todos los grupos."]},{"cell_type":"markdown","metadata":{"id":"4r5hSQAz6d-g"},"source":["# **Recursos adicionales**\n","---\n","Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *Scikit-learn* en el desarrollo y evaluación de modelos de aprendizaje no supervisado como el agrupamiento, además de material de apoyo teórico para reforzar estos conceptos:\n","\n","- [Clustering - Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html)\n","- [Hierarchial Clustering - Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)\n","- [Column Transformer for heterogeneous data - Scikit-learn ](https://scikit-learn.org/stable/modules/compose.html#column-transformer)\n","- [Data Mining Cluster Analysis: Basic Concepts and Algorithms - Introduction to Data Mining by Tan, Steinbach, Karpatne, Kumar](https://www-users.cs.umn.edu/~kumar001/dmbook/slides/chap7_basic_cluster_analysis.pdf)\n","- [Cluster Analysis in Data Mining](https://es.coursera.org/learn/cluster-analysis)\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"elcS3QaTyxU9"},"source":["## **Referencias**\n","---\n","- Manning, C., Raghavan, D. & Schütze, H. (2008). Introduction to Information Retrieval [Introducción a la recuperación de información]."]},{"cell_type":"markdown","metadata":{"id":"O6dwABE_Zg44"},"source":["# **Créditos**\n","---\n","\n","* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n","* **Asistentes docentes:**\n","  * Miguel Angel Ortiz Marín\n","  * Alberto Nicolai Romero Martínez\n","\n","**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"]}]}