{"cells":[{"cell_type":"markdown","metadata":{"id":"cSxJU721MNoF"},"source":["# **Métodos de clasificación no lineal**\n","---\n","\n","\n","En este notebook se discutirán los métodos de clasificación no lineal, y en particular, se presentará la implementación de modelos basados en árboles de decisión y de máquinas de vectores de soporte (SVM). El material se desarrollará con la ayuda de la librería de aprendizaje automático *Scikit-Learn* y de otras librerías comunes como *NumPy*, *Pandas* y *Matplotlib*.\n","\n","Finalmente, se discutirá la necesidad de identificar lo hiperparámetros más adecuados para un modelo de aprendizaje automático, y se discutirán técnicas para estimarlo de forma robusta, como la validación cruzada de $k$ pliegues y  *grid search*."]},{"cell_type":"markdown","metadata":{"id":"i0sRGgMB2FUF"},"source":["# **1. Dependencias**\n","---\n","Importamos las librerías necesarias y definimos algunas funciones básicas de visualización que vamos a usar en algunos ejemplos.\n"]},{"cell_type":"markdown","metadata":{"id":"qJgGczNUDVUN"},"source":["### **1.1. Dependencias**\n","---\n","Para la construcción de modelos y ejecución de procedimientos metodológicos de aprendizaje automático, utilizaremos la librería *Scikit-learn* (**`sklearn`**) y varias de sus funciones y conjuntos de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1A1bWvdAsW_B"},"outputs":[],"source":["# Actualizamos scikit-learn a la última versión\n","# !pip install -U scikit-learn\n","\n","# Importamos scikit-learn\n","import sklearn"]},{"cell_type":"markdown","metadata":{"id":"h0jic_vwJv9c"},"source":["Importamos además algunas librerías básicas y configuraciones de *Python*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEf3ydjznNhj"},"outputs":[],"source":["#Librerías básicas NumPy y Pandas.\n","import numpy as np\n","import pandas as pd\n","\n","#Matplotlib y Seaborn - Librerías de visualización.\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Visualización de grafos con graphviz.\n","import graphviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nmx-RGqF8Hls"},"outputs":[],"source":["# Configuraciones para las librerías y módulos usados.\n","\n","# Ignoramos las advertencias o warnings.\n","import warnings\n","warnings.simplefilter(action='ignore')\n","\n","# Configuramos el formato por defecto de la\n","# librería de visualización Matplotlib.\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","mpl.rcParams['figure.dpi'] = 105\n","mpl.rcParams['figure.figsize'] = (9, 7)"]},{"cell_type":"markdown","metadata":{"id":"dxNzX3sfq3gZ"},"source":["Este material se realizó con las siguientes versiones:\n","*  *Python*: 3.7.10\n","*  *Scikit-learn*: 0.24.1\n","*  *NumPy*:  1.19.5\n","*  *Pandas*:  1.1.5\n","*  *Matplotlib*:  3.2.2\n","*  *Seaborn*:  0.11.1\n","*  *Graphviz*: 0.10.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUMP_2CPqwRY"},"outputs":[],"source":["# Versión de Python y las demás librerías.\n","!python --version\n","print('Scikit-learn', sklearn.__version__)\n","print('NumPy', np.__version__)\n","print('Pandas', pd.__version__)\n","print('Matplotlib', mpl.__version__)\n","print('Seaborn', sns.__version__)\n","print('Graphviz', graphviz.__version__)"]},{"cell_type":"markdown","metadata":{"id":"nmFrETF-Osjj"},"source":["### **1.2. Funciones de utilidad y visualización**\n","---\n","\n","Para ilustrar los ejemplos discutidos en este material utilizaremos algunas funciones que permiten visualizar de manera general los datos, junto a las funciones de predicción obtenidas con cada modelo.\n","\n","> **Nota**: *Matplotlib* y *Seaborn* se encuentran por fuera del alcance de este módulo. No es necesario que entienda estas funciones en detalle para sacar partido del resto del contenido puesto a su disposición. Usted decide si leer o no estas funciones en profundidad. Si decide omitir esta sección, continúe directamente con la siguiente sección, en donde se discutirán los conjuntos de datos que vamos a utilizar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFDXpdM-ps_1"},"outputs":[],"source":["# Función para visualizar un conjunto de datos de dos variables en un plano 2D.\n","def plot_data(X, y, model = None, ax = None, title=None):\n","\n","    if ax is None:\n","      _, ax = plt.subplots(dpi = 110)\n","\n","    if model is not None:\n","      pred_fun = gen_pred_fun(model)\n","      plot_decision_region(X, pred_fun, ax)\n","\n","    y_unique = np.unique(y)\n","    df = pd.DataFrame({'x1': X[:,0], 'x2': X[:,1], 'Clases': y})\n","    sns.set_theme()\n","    sns.scatterplot(data = df, x = 'x1', y = 'x2',\n","                    hue = 'Clases',style = 'Clases', ax = ax, palette = 'Set1').set_title(title)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZZQ_8SFDWcb"},"outputs":[],"source":["# Función para visualizar la superficie de decisión de un clasificador.\n","def plot_decision_region(X, pred_fun, ax=None):\n","    min_x, max_x = np.min(X[:, 0]), np.max(X[:, 0])\n","    min_y, max_y = np.min(X[:, 1]), np.max(X[:, 1])\n","\n","    min_x = min_x - (max_x - min_x) * 0.05\n","    max_x = max_x + (max_x - min_x) * 0.05\n","    min_y = min_y - (max_y - min_y) * 0.05\n","    max_y = max_y + (max_y - min_y) * 0.05\n","\n","    x_vals = np.linspace(min_x, max_x, 100)\n","    y_vals = np.linspace(min_y, max_y, 100)\n","\n","    XX, YY = np.meshgrid(x_vals, y_vals)\n","    grid_r, grid_c = XX.shape\n","\n","    ZZ = np.zeros((grid_r, grid_c))\n","\n","    for i in range(grid_r):\n","        for j in range(grid_c):\n","            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n","\n","    cs = ax.contourf(XX, YY, ZZ, 100, cmap = plt.cm.Pastel1, vmin = 0, vmax = np.max(ZZ)* 9. / (np.max(ZZ) + 1), alpha = 0.75)\n","    ax.get_figure().colorbar(cs, ax=ax, )\n","    ax.set_xlabel(\"x\")\n","    ax.set_ylabel(\"y\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9D8XlcuDaEt"},"outputs":[],"source":["# Función para visualizar la curva de aprendizaje a partir\n","# del error de entrenamiento y de generalización.\n","def plot_learning_curve(train_error, generalization_error):\n","  n = len(train_error)\n","  if len(train_error) != len(generalization_error):\n","    print(\"Las secuencias de error de entrenamiento y generalización deben tener el mismo tamaño.\")\n","    return\n","\n","  balance_point = np.array(generalization_error).argmin() + 1\n","  plt.figure(figsize = (8, 5), dpi = 105)\n","\n","  plt.plot(range(1, n + 1), train_error, label=\"Entrenamiento\")\n","  plt.plot(range(1, n + 1), generalization_error, label=\"Generalización\")\n","  plt.xticks(range(0, n + 1, 2))\n","  plt.xlabel(\"Profundidad máxima\")\n","  plt.ylabel(\"Error\")\n","  y_min, y_max = plt.gca().get_ylim()\n","  plt.vlines(balance_point, y_min, y_max, colors = ['red'], linestyles = ['dashdot'])\n","  plt.ylim([y_min, y_max])\n","  plt.text(balance_point + 1, 0.165, 'Punto de balance')\n","  plt.legend();"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fSfViWX6DcEY"},"outputs":[],"source":["#Función para generar la función de predicción de un clasificador entrenado previamente.\n","def gen_pred_fun(clf):\n","    def pred_fun(x1, x2):\n","        x = np.array([[x1, x2]])\n","        return clf.predict(x)[0]\n","    return pred_fun"]},{"cell_type":"markdown","metadata":{"id":"RURwOVpHIb2P"},"source":["# **2. Conjuntos de datos**\n","---\n","\n","Para los ejemplos desarrollados en el transcurso de material, se usarán datos de  *Scikit-Learn* de carácter real (usando *Loaders*) y sintético (usando *Generators*)."]},{"cell_type":"markdown","metadata":{"id":"D0LuNr1jTrE-"},"source":["#### **2.1. Conjunto de datos *Iris***\n","---\n","\n","En este material retomaremos el conjunto de datos *Iris* para ilustrar algunos ejemplos. Para esto, usaremos la función **`load_iris`** de *Scikit-Learn*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1E4zU826S9mD"},"outputs":[],"source":["# Loader del dataset iris.\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris()\n","\n","X = iris.data\n","y = iris.target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwCxXcaMTRhS"},"outputs":[],"source":["# Información general del conjunto.\n","\n","print(f'X ~ {X.shape[0]} muestras x {X.shape[1]} características.')\n","print(f'y ~ {y.shape[0]} muestras.')\n","print('\\nPrimeras 5 muestras:\\n', X[:5, :])\n","print('\\nPrimeras 5 etiquetas:\\n', y[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bq-HxHnvTRhV"},"outputs":[],"source":["# Graficamos en un área 2d.\n","plot_data(X, y)"]},{"cell_type":"markdown","metadata":{"id":"bITZMX0DRvFt"},"source":["#### **2.2. Conjuntos de datos sintéticos**\n","---\n","Además de *Iris*, vamos a trabajar con dos conjuntos de datos artificiales. Estos son:\n","\n","  * **`make_circles`**: Este conjunto de datos artificial genera dos variables que representan dos círculos, uno mayor y otro menor contenido en su interior. *Scikit-Learn* permite a su vez introducir algo de ruido sobre las muestras creadas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFxnv30KRvFx"},"outputs":[],"source":["# Conjunto de datos sintético circles.\n","from sklearn.datasets import make_circles\n","\n","X, y = make_circles(n_samples=600,\n","                    noise=0.1,\n","                    random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ughx7e2lRvF4"},"outputs":[],"source":["# Información general del conjunto.\n","\n","print(f'X ~ {X.shape[0]} muestras x {X.shape[1]} características.')\n","print(f'y ~ {y.shape[0]} muestras.')\n","print('\\nPrimeras 5 muestras:\\n', X[:5, :])\n","print('\\nPrimeras 5 etiquetas:\\n', y[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3VglYMLRvGB"},"outputs":[],"source":["# Graficamos en un área 2d.\n","plot_data(X, y)"]},{"cell_type":"markdown","metadata":{"id":"CCxn6F3wOSRn"},"source":["  * **`make_moons`**: Este conjunto de datos artificial genera dos variables asociadas a dos clases que representan dos medias lunas. *Scikit-Learn* permite a su vez introducir algo de ruido sobre las muestras creadas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWoSEkkeptAJ"},"outputs":[],"source":["#Conjunto de datos sintético moons.\n","from sklearn.datasets import make_moons\n","\n","X, y = make_moons(n_samples=600, #Número de observaciones o muestras.\n","                  noise=0.15,     #Cantidad de ruido aleatorio introducido.\n","                  random_state=0 #Semilla aleatoria para garantizar la replicabilidad.\n","                  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51ZONnKoUcGx"},"outputs":[],"source":["#Información general del conjunto.\n","\n","print(f'X ~ {X.shape[0]} muestras x {X.shape[1]} características.')\n","print(f'y ~ {y.shape[0]} muestras.')\n","print('\\nPrimeras 5 muestras:\\n', X[:5, :])\n","print('\\nPrimeras 5 etiquetas:\\n', y[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSRmYSFoptAh"},"outputs":[],"source":["#Graficamos en un área 2d.\n","plot_data(X, y)"]},{"cell_type":"markdown","metadata":{"id":"KJecNHkCptAo"},"source":["Estos conjuntos de datos producen un resultado interesante cuando se utilizando los métodos y modelos discutidos hasta ahora. Si aplicamos un modelo de **clasificación lineal** como una regresión logística, observamos que es difícil establecer una separación apropiada:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LweSH5Zf9Kf7"},"outputs":[],"source":["# Clasificador basado en regresión logística.\n","from sklearn.linear_model import LogisticRegression\n","\n","lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs');\n","lr_model.fit(X, y)\n","\n","plot_data(X, y, lr_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fmkNdrRHJnu"},"outputs":[],"source":["print(\"Score:\", lr_model.score(X, y))"]},{"cell_type":"markdown","metadata":{"id":"4mP4Iq5baDNz"},"source":["Existen problemas en los que generar una clasificación lineal no produce un resultado apropiado, sin importar el tamaño del conjunto o tiempo invertido en el entrenamiento. Por lo tanto, surge la necesidad de usar un modelo que permita realizar una **clasificación no lineal**."]},{"cell_type":"markdown","metadata":{"id":"Si_g8YaEptEP"},"source":["# **3. Árboles de Decisión**\n","---\n","\n","El primer algoritmo de clasificación no lineal que discutiremos es el basado en **árboles de decisión**. Los árboles de decisión son muy intuitivos, pues codifican una serie de elecciones \"**si esto**\" y \"**si no, entonces**\", de forma muy similar a como una persona tomaría una decisión, o un programa simple usando las estructuras **`if`** y **`else`**. La gran ventaja de esta técnica es que estas elecciones se pueden aprender de forma automática a partir de los datos y existen maneras de identificar de manera automática las mejores condiciones y ramificaciones del árbol generado.\n","\n","Por ejemplo, considere el siguiente árbol de decisión. Este árbol de decisión describe una serie de elecciones que buscan determinar si espero (**V**) o no (**F**) por una mesa en un restaurante.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1XrQiEx-PRqJDjSaoXvhh2a_YxxNlRUy0\">\n","\n","\n","Con base al anterior árbol de decisión, puedo tomar la decisión de esperar o no, usando unas reglas de clasificación sencillas con preguntas como:\n","* ¿Cuántos clientes hay en el restaurante?\n","* ¿Cuánto tiempo tengo que esperar?\n","* ¿Tengo alguna alternativa de restaurante?\n","* ¿Tengo hambre en este momento?\n","* ¿Es viernes o sábado?\n","* ¿Tengo reservación?\n","\n","Como puede apreciar, estos árboles pueden tener una interpretación muy intuitiva. Para tomar una decisión, o más bien realizar una clasificación de la situación, evaluaríamos esta condición en la observación sobre la que queremos tomar una decisión y avanzamos a la siguiente condición o estado final. Así, se realizarían preguntas como:\n","\n","* **Si `Clientes == \"Lleno\"` Y `EsperaEstimada == \"10-30\"` Y `Hambre == \"No\"` Entonces `Esperar=\"SÍ\"`**.\n","* **Si `Clientes == \"Algunos\"` Entonces `Esperar=\"SI\"`**.\n","* **Si `Clientes == \"Lleno\"` Y `EsperaEstimada == \">60\"` Entonces `Esperar=\"NO\"`**."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"S8fVslz3mH07"},"outputs":[],"source":["#@markdown **Video: Ejemplo de predicción con árboles de decisión**\n","#@markdown ***\n","\n","from IPython.display import HTML\n","\n","HTML('<iframe style=\"width:768px; height: 432px;\" src=\"https://drive.google.com/file/d/1vbCDEIBnrSbEfsIMtirHj8J-mOzSNCoP/preview\"></iframe>')"]},{"cell_type":"markdown","metadata":{"id":"PtsHcuRCptEV"},"source":["## **3.1. Ventajas y desventajas**\n","---\n","\n","**Ventajas**\n","\n","* Los datos de entrada requieren muy poco preprocesamiento. Los árboles de decisión pueden trabajar con variables de diferente tipo (continuas y categóricas) y son invariantes al escalamiento de las características.\n","* Los modelos son fáciles de interpretar y los árboles pueden ser visualizados.\n","* El costo computacional del uso del árbol para predecir la categoría de un ejemplo es mínimo comparado con otras técnicas (se realiza en tiempo logarítmico).\n","\n","**Desventajas**\n","\n","* Puede ser tan complejo, que se memoriza el conjunto de datos, por lo tanto, no generaliza tan bien (**sobreajuste**).\n","* Son muy sensibles al desbalance de clases (**sesgo**)."]},{"cell_type":"markdown","metadata":{"id":"DaMizhtIptEe"},"source":["## **3.2. Implementación en *Scikit-Learn***\n","---\n","\n","La implementación de *Scikit-Learn* se consigue con la clase **`DecisionTreeClassifier`** del módulo **`sklearn.tree`**:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9_5juCHptEf"},"outputs":[],"source":["# Importamos el constructor del clasificador por árboles de decisión.\n","from sklearn.tree import DecisionTreeClassifier\n","\n","classifier = DecisionTreeClassifier()"]},{"cell_type":"markdown","metadata":{"id":"HUYAy9l8SM_X"},"source":["Cargamos de nuevo nuestros conjuntos de datos _Iris_ y _moons_."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ManoqRdcSHVe"},"outputs":[],"source":["#Conjunto de datos iris\n","iris = load_iris()\n","\n","X_iris = iris.data[:,[0, 2]] # Usamos solo dos variables (longitud del sépalo y del pétalo)\n","y_iris = iris.target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLT7ZJFVsjGN"},"outputs":[],"source":["#Conjunto de datos de medias lunas\n","X_moons, y_moons = make_moons(n_samples=600, # Número de observaciones o muestras.\n","                              noise=0.3,     # Cantidad de ruido aleatorio introducido.\n","                              random_state=0 # Semilla aleatoria para garantizar la replicabilidad.\n","                              )"]},{"cell_type":"markdown","metadata":{"id":"a5pzTxWXptEi"},"source":["Algunos de los parámetros más importantes del clasificador **`DecisionTreeClassifier`** son:\n","* **`max_depth`**: profundidad máxima del árbol.\n","* **`criterion`**: medida para determinar la calidad del particionamiento generado por un atributo. Soporta el coeficiente de *Gini* y entropía.\n","* **`min_samples_split`**: controla el número mínimo de muestras que debe haber en un nodo luego de una partición.\n","* **`min_samples_leaf`**: controla el número mínimo de muestras que debe haber en un nodo hoja."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmWPqp_VptEj"},"outputs":[],"source":["classifier.get_params()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_4ornMhaptEp"},"outputs":[],"source":["# Entrenamos el modelo con el conjunto de datos moons.\n","\n","moons_DT_classifier =  DecisionTreeClassifier()\n","moons_DT_classifier = moons_DT_classifier.fit(X_moons, y_moons)"]},{"cell_type":"markdown","metadata":{"id":"qGHh5y1XptEt"},"source":["Visualizamos la superficie de decisión del clasificador"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irG4rvBeHSlD"},"outputs":[],"source":["plot_data(X_moons, y_moons, moons_DT_classifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEiYphhDptE-"},"outputs":[],"source":["print(f'Error: {1 - moons_DT_classifier.score(X_moons, y_moons)}')"]},{"cell_type":"markdown","metadata":{"id":"MMFU4196t1yt"},"source":["Y ahora podemos realizar el mismo proceso con el *dataset* *Iris*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a4ArmfLt2Fc"},"outputs":[],"source":["#Entrenamos el modelo con el conjunto de datos moons\n","\n","iris_DT_classifier =  DecisionTreeClassifier()\n","iris_DT_classifier = iris_DT_classifier.fit(X_iris, y_iris)"]},{"cell_type":"markdown","metadata":{"id":"7oV4wj4Jt2Ff"},"source":["Visualizamos la superficie de decisión del clasificador."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pkx_UFXnHcxM"},"outputs":[],"source":["plot_data(X_iris, y_iris, iris_DT_classifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJmOUFKZvzXi"},"outputs":[],"source":["print(f'Error: {1 - iris_DT_classifier.score(X_iris, y_iris)}')"]},{"cell_type":"markdown","metadata":{"id":"z5HdMBwgVsgI"},"source":["Ambos conjuntos de datos tienen un error con valor $0$, que apunta a un posible **sobreajuste**."]},{"cell_type":"markdown","metadata":{"id":"ps5k8wNeptFC"},"source":["## **3.3. Visualización de árboles de decisión**\n","---\n","\n","El árbol de decisión aprendido puede ser visualizado usando la librería de visualización de grafos **`graphviz`**.\n","\n","> **Nota:** En sistemas operativos basados en *Linux* como *Ubuntu* se recomienda instalarlo usando estas líneas:\n","  ```\n","  sudo apt-get install graphviz\n","  pip install graphviz\n","  pip install pydot\n","  ```\n","\n","A continuación, vamos a usar el conjunto de datos *Iris* completo, usando las cuatro características, y su árbol de decisión, pero esta vez utilizaremos las 4 variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJnk39yGptFC"},"outputs":[],"source":["# Declaramos los datos de entrada.\n","X_iris = iris.data\n","y_iris = iris.target\n","\n","# Declaramos y entrenamos el clasificador.\n","iris_DT_classifier = DecisionTreeClassifier(random_state=2)\n","iris_DT_classifier = iris_DT_classifier.fit(X_iris, y_iris)"]},{"cell_type":"markdown","metadata":{"id":"Th13_z22ptFH"},"source":["Usamos **`graphviz`** para visualizar el árbol generado. El método **`graphviz`** soporta como parámetros los nombres de las clases y de las características a graficar. Además, con el método **`sklearn.tree.export_graphviz`** podemos generar la entrada de este método y así visualizar los modelos que entrenemos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fOZgfrL_ptFI"},"outputs":[],"source":["# Función de utilidad para la visualización de archivos SVG en notebooks.\n","from IPython.display import SVG\n","\n","# Importamos la función de generación del archivo de descripción del árbol.\n","from sklearn.tree import export_graphviz\n","\n","graphviz_data = export_graphviz(iris_DT_classifier, # Árbol de decisión entrenado.\n","                                out_file=None,      # Se usa 'None' para generar un string con el resultado.\n","                                feature_names=iris.feature_names,  # Nombre de las características.\n","                                class_names=iris.target_names,     # Nombre de las clases.\n","                                 # Configuración de estilo.\n","                                filled=True, rounded=True, special_characters=True)\n","\n","# Generamos el grafo de graphviz para la visualización.\n","graph = graphviz.Source(graphviz_data)\n","\n","# Exportamos en formato svg y visualizamos con IPython.\n","SVG(graph.pipe(format='svg'))"]},{"cell_type":"markdown","metadata":{"id":"ryDFpUIzw-BX"},"source":["Podemos ver como resultó el modelo construido y las reglas que se definieron en la construcción del árbol. Una cosa a tener en cuenta es la diferenciación inmediata de las flores de la clase **`setosa`** (en naranja) con la primera regla del árbol, en la que para todas las flores cuyo grosor de pétalo es menor que $0.8 (cm)$ se clasifican en esta especie.\n","\n","Tras esto, nos podemos imaginar que el grosor de pétalo es especialmente importante para distinguir las flores *setosa*. ¿Hay alguna forma de identificar la importancia de cada variable?"]},{"cell_type":"markdown","metadata":{"id":"iq85AHVlptFS"},"source":["## **3.4. Importancia de las variables**\n","---\n","\n","Una de las ventajas de usar árboles de decisión, es que nos permite determinar la importancia de cada característica, con base al índice de impureza usado. *Scikit-Learn* nos permite acceder a la importancia de cada característica llamando el atributo **`feature_importances_`** del clasificador. Esta importancia cuantifica qué tanto aporta cada característica a mejorar el desempeño del árbol."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c6CKLAgptFT"},"outputs":[],"source":["# Valores entre 0 y 1 del aporte al desempeño de cada característica.\n","iris_DT_classifier.feature_importances_"]},{"cell_type":"markdown","metadata":{"id":"4ZvMSR0UNRXj"},"source":["El atributo **`feature_importances_`** contiene un arreglo de *Numpy* del tamaño igual al número de características. Por ejemplo, la importancia de la característica $0$ (**`sepal length (cm)`**) es de $1.3\\%$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXdImqbOptFX"},"outputs":[],"source":["# Nombres de las características a partir del bunch.\n","iris.feature_names"]},{"cell_type":"markdown","metadata":{"id":"jw8XUX1c0JXF"},"source":["Entonces, podríamos decir que, para el modelo construido, las variables aportan a la decisión de la siguiente forma:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcWSeyC20Yd8"},"outputs":[],"source":["sns.barplot(x = iris.feature_names,  # Nombre de las características.\n","            y = iris_DT_classifier.feature_importances_ ); # Importancia de cada característica."]},{"cell_type":"markdown","metadata":{"id":"EpO9e6PUptFd"},"source":["## **3.5. Evaluación de la complejidad usando `DecisionTreeClassifier`**\n","---\n","\n","Para evaluar la complejidad, vamos a estimar este valor tomando como referencia la profundidad del árbol."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O20n0IsEptFe"},"outputs":[],"source":["# Función de partición en subconjuntos de entrenamiento y pruebas.\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris,\n","                                                    test_size=0.3,     # Proporción de datos usados para el grupo de evaluación.\n","                                                    random_state=1234, # Semilla aleatoria para la replicabilidad.\n","                                                    stratify=y_iris)   # Estratificar con respecto a la etiqueta."]},{"cell_type":"markdown","metadata":{"id":"g_r_2dv2ptFi"},"source":["Vamos a explorar los siguientes valores de profundidad máxima:\n","* $[1, 2, 3, \\dots, 20]$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LoijGLgYptFj"},"outputs":[],"source":["# Números enteros de 1 a 20 como posibles valores del hiperparámetro de profundidad.\n","max_depth_values = np.arange(1, 21, 1)\n","\n","# Arreglos vacíos para almacenar el error de entrenamiento y el de generalización.\n","train_error = np.empty(len(max_depth_values))\n","generalization_error = np.empty(len(max_depth_values))\n","\n","\n","for depth in max_depth_values:\n","    # Entrenamos un árbol de decisión para cada valor de profundidad.\n","    decision_tree = DecisionTreeClassifier(max_depth=depth)\n","    decision_tree.fit(X_train, y_train)\n","\n","    # Almacenamos el error de entrenamiento y de generalización por cada árbol.\n","    train_error[depth - 1] = (1 - decision_tree.score(X_train, y_train))\n","    generalization_error[depth - 1] = (1 - decision_tree.score(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"kLJP1n98ptFl"},"source":["Visualizamos la curva de error de entrenamiento contra error de generalización:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YbYzgGMOVPg"},"outputs":[],"source":["plot_learning_curve(train_error, generalization_error)"]},{"cell_type":"markdown","metadata":{"id":"-cnkgxwi2gtm"},"source":["En este caso, el balance entre ambos errores se alcanza muy rápido, con profundidad de $2$ nodos."]},{"cell_type":"markdown","metadata":{"id":"H-WoP70a4mWt"},"source":["# **4. Máquinas de vectores de soporte (*SVM*)**\n","---\n","Las máquinas de vectores de soporte son un modelo de aprendizaje supervisado en el cual se busca representar a los ejemplos en un nuevo espacio, de tal forma que a aquellos ejemplos de diferentes categorías sea posible, en principio, separarlos linealmente en este nuevo espacio. Considere el siguiente ejemplo, usando el conjunto de datos generados con el *Generator* **`make_circles`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJsr26kJ4mWw"},"outputs":[],"source":["X, y = make_circles(n_samples=1000, factor=.3, noise=.08 , random_state= 0)"]},{"cell_type":"markdown","metadata":{"id":"VOZ22ssG4mW5"},"source":["Se trata de un conjunto de datos que no es linealmente separable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWJMsccZ4mW8"},"outputs":[],"source":["plot_data(X, y)"]},{"cell_type":"markdown","metadata":{"id":"UJWd3J764mXN"},"source":["> **¿Se pueden separar las clases con una función lineal?**\n","\n","Si intentamos utilizar un modelo de clasificación lineal, podemos notar que el resultado no es apropiado. De hecho, este es un ejemplo de problema en el que es **imposible** distinguir directamente los datos con un clasificador lineal."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CtVFgZxD9u6H"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Declaramos y entrenamos un modelo de regresión logística.\n","lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs');\n","lr_model.fit(X, y)\n","\n","# Graficamos la región de decisión.\n","plot_data(X, y, lr_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gjgl-3kH7vWE"},"outputs":[],"source":["# Imprimimos el score del modelo.\n","print(\"Score:\", lr_model.score(X, y))"]},{"cell_type":"markdown","metadata":{"id":"AVNuTUoC4mXO"},"source":["Un modelo *SVM* crea, implícitamente, un espacio de representación de mayor dimensionalidad en el cual sí podemos separar de forma clara nuestros datos. Esto se ilustra en la siguiente figura:\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1NuYvzWfEb_nOZ9pWbsycdQWiHhad5_BI\">"]},{"cell_type":"markdown","metadata":{"id":"y96W22zGoFhV"},"source":["Para el ejemplo de los dos círculos, podemos llevar los datos a un nuevo espacio más apropiado. Para esto, usaremos un espacio donde las características corresponden al cuadrado de las características originales:\n","\n","$$\\begin{equation}\n","\\begin{split}\n","\\phi:& \\mathbb{R}^2  & \\longrightarrow & \\mathbb{R}^2 \\\\\n","  & (x,y) & \\longmapsto & (x^2,y^2)\n","\\end{split}\n","\\end{equation}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrnFHcC2noU8"},"outputs":[],"source":["X_square = X * X\n","\n","plot_data(X_square, y)"]},{"cell_type":"markdown","metadata":{"id":"i5Nf--3GrDi9"},"source":["En este nuevo espacio de representación **SÍ** es posible separar los datos con un discriminante lineal."]},{"cell_type":"markdown","metadata":{"id":"N0j9YLhU4mXR"},"source":["### **4.1. Kernel trick**\n","---\n","\n","SVM usa una función conocida como *Kernel*. Intuitivamente, esta función $k$ define qué tan parecidas son dos instancias del conjunto de datos. Formalmente, la función $k$ calcula el producto punto en el espacio de características donde se representarán los datos. Dependiendo del *kernel*, este espacio de características es de mayor dimensionalidad, y facilita la definición de un \"*hiperplano*\" que separe los ejemplos de ambas características. La dimensión de este *hiperplano* varía de acuerdo al número de características. Si se tienen 2, el *hiperplano* es una recta. Si se tienen 3 el *hiperplano* es un plano en un espacio de 3 dimensiones.\n","\n","Existen varias opciones para las funciones de *kernel*. Primero, vamos a cargar nuevamente los dos conjuntos de datos (*iris* y *moons*) sobre los cuales vamos a comparar la superficie de decisión generada por cada tipo de *kernel*. Empezaremos de una vez con la división en grupos de entrenamiento y evaluación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ii0cvDyH4mXV"},"outputs":[],"source":["# Dataset de flores iris\n","iris = load_iris()\n","\n","X_iris = iris.data[:,[0, 2]]\n","y_iris = iris.target\n","X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris,\n","                                                                        y_iris,\n","                                                                        test_size=0.3,\n","                                                                        random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P197Nde4-xwJ"},"outputs":[],"source":["# Dataset sintético de lunas\n","X_moons, y_moons = make_moons(n_samples=600, noise=0.3, random_state=0)\n","X_train_moons, X_test_moons, y_train_moons, y_test_moons = train_test_split(X_moons,\n","                                                                            y_moons,\n","                                                                            test_size=0.3,\n","                                                                            random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x72Fwx5z4mXc"},"outputs":[],"source":["fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (10, 4))\n","plot_data(X_iris, y_iris, ax = ax1, title = 'Conjunto de datos Iris')\n","plot_data(X_moons, y_moons, ax = ax2, title = 'Conjunto de datos Moons')"]},{"cell_type":"markdown","metadata":{"id":"DsXKMf-Y4mXw"},"source":["#### **4.1.1. Kernel Lineal**\n","---\n","\n","En un *kernel* lineal, la función $k$ está definida como:\n","$$\n","k(x,y) = \\langle x, y\\rangle = xy^T\n","$$\n","\n","Esta implementación puede ser consultada a través de **`sklearn.svm.LinearSVC`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNwNoxWQ4mXz"},"outputs":[],"source":["# Modelo de máquina de vector de soporte con kernel lineal.\n","from sklearn.svm import LinearSVC\n","\n","# Declaramos el modelo SVC lineal para ambos conjuntos de datos.\n","linear_iris = LinearSVC(max_iter=5000)\n","linear_moons = LinearSVC(max_iter=5000)\n","\n","# Entrenamos cada modelo con sus datos de entrada respectivos.\n","linear_iris.fit(X_train_iris, y_train_iris)\n","linear_moons.fit(X_train_moons, y_train_moons);"]},{"cell_type":"markdown","metadata":{"id":"3tevZ6Yw4mX9"},"source":["Ahora visualizamos los datos de ambos:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GBoQbimq4mYA"},"outputs":[],"source":["plot_data(X_test_iris, y_test_iris, linear_iris)"]},{"cell_type":"markdown","metadata":{"id":"pk_E8pCo4mYJ"},"source":["El error en el conjunto de entrenamiento y prueba es el siguiente:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XoOvluwv4mYL"},"outputs":[],"source":["print(f\"Error en entrenamiento:\\t{1-linear_iris.score(X_train_iris, y_train_iris):.4f}\")\n","print(f\"Error en prueba:\\t{1-linear_iris.score(X_test_iris, y_test_iris):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"E5JpH4A94mYV"},"source":["Ahora hacemos los mismo para el conjunto de datos generado artificialmente:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19r59ffV4mYX"},"outputs":[],"source":["plot_data(X_moons, y_moons, linear_moons)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lj2USego4mYg"},"outputs":[],"source":["print(f\"Error en entrenamiento:\\t{1-linear_moons.score(X_train_moons, y_train_moons):.4f}\")\n","print(f\"Error en prueba:\\t{1-linear_moons.score(X_test_moons, y_test_moons):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"qcbbV8odANff"},"source":["Hasta el momento, los resultados son muy similares a los que obtendríamos con otro método de clasificación lineal."]},{"cell_type":"markdown","metadata":{"id":"1zsaCnGa4maD"},"source":["#### **4.1.2. Kernel Gaussiano**\n","---\n","\n","Otro kernel muy importante es el **_kernel_ gaussiano**. Este está definido por la siguiente función:\n","$$\n","K(x, x') = \\exp\\left(-\\frac{\\|x-x'\\|^2}{2\\sigma^2}\\right)\n","$$\n","la cual se puede simplificar como\n","$$\n","K(x, x') = \\exp(-\\gamma \\|x-x'\\|^2)\n","$$\n","$$\n","\\gamma \\ = \\frac{1}{2\\sigma^2}\n","$$\n","En la literatura este método también se encuentra como *kernel* usando una función de base radial (**RBF** por del ingles *Radial basis function*).\n","\n","Para implementar un clasificador de vectores de soporte con un *kernel* gaussiano podemos utilizar el constructor de clasificadores basados en máquinas de soporte general **`sklearn.SVC`**. Esta es una versión general de este tipo de clasificador, que acepta distintos argumentos para definir el método deseado.\n","\n","En el siguiente ejemplo probamos con un valor pequeño del argumento $\\gamma$ (**`gamma`**):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFc0e-HH4maD"},"outputs":[],"source":["#Clasificador de vectores de soporte general.\n","from sklearn.svm import SVC\n","\n","rbf_svm = SVC(kernel='rbf',   # Kernel de tipo RBF\n","              gamma = 0.001)  # Valor del argumento gamma\n","\n","rbf_svm.fit(X_train_moons, y_train_moons);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxGx0He-4maG"},"outputs":[],"source":["plot_data(X_test_moons, y_test_moons, rbf_svm)"]},{"cell_type":"markdown","metadata":{"id":"Jh-WoG4c4maK"},"source":["Reportamos el error de entrenamiento y prueba:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1a1BQFr4maQ"},"outputs":[],"source":["print(f\"Error en entrenamiento:\\t {1-rbf_svm.score(X_train_moons, y_train_moons):.4f}\")\n","print(f\"Error en prueba:\\t {1-rbf_svm.score(X_test_moons, y_test_moons):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"J3He4jvS4maS"},"source":["El resultado no es mucho mejor al obtenido previamente. Usemos ahora un $\\gamma$ más grande."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXV-WVoP4maV"},"outputs":[],"source":["# Creamos y entrenamos el modelo.\n","rbf_svm = SVC(kernel='rbf',\n","              gamma = 1000)\n","rbf_svm.fit(X_train_moons, y_train_moons)\n","\n","# Graficamos los resultados.\n","plot_data(X_test_moons, y_test_moons, rbf_svm)"]},{"cell_type":"markdown","metadata":{"id":"cTdfd2NT4mao"},"source":["Ahora reportamos el error de entrenamiento y prueba:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hN9OWsrg4mar"},"outputs":[],"source":["print(f\"Error en entrenamiento:\\t{1-rbf_svm.score(X_train_moons, y_train_moons):.4f}\")\n","print(f\"Error en prueba:\\t{1-rbf_svm.score(X_test_moons, y_test_moons):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"bbNDjoaF4maw"},"source":["La forma ha mejorado, pero ahora tenemos franjas de la clase $0$ ocupando el espacio que debería corresponder a la clase $1$, es decir, el modelo está **sobreajustado**. Probemos ahora con un valor de $\\gamma$ intermedio:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"raTWjAl_4may"},"outputs":[],"source":["# Creamos y entrenamos el modelo.\n","rbf_svm = SVC(kernel='rbf',\n","              gamma = 0.7)\n","rbf_svm.fit(X_train_moons, y_train_moons)\n","\n","# Graficamos los resultados.\n","plot_data(X_test_moons, y_test_moons, rbf_svm)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkcTzLg-4ma4"},"outputs":[],"source":["print(f\"Error en entrenamiento:\\t{1-rbf_svm.score(X_train_moons, y_train_moons):.4f}\")\n","print(f\"Error en prueba:\\t{1-rbf_svm.score(X_test_moons, y_test_moons):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"ULwfwNmH4ma7"},"source":["Probamos el mismo *kernel* sobre el conjunto de datos *Iris*:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZY0ewQp4ma9"},"outputs":[],"source":["rbf_svm = SVC(kernel='rbf', gamma = 0.7)\n","rbf_svm.fit(X_train_iris, y_train_iris)\n","\n","plot_data(X_test_iris, y_test_iris, rbf_svm)"]},{"cell_type":"markdown","metadata":{"id":"ZoZJ1WLi4mbB"},"source":["Finalmente reportamos el error en entrenamiento y prueba:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AqwCfefp4mbC"},"outputs":[],"source":["print(f\"Error en entrenamiento:\\t{1-rbf_svm.score(X_train_iris, y_train_iris):.4f}\")\n","print(f\"Error en prueba:\\t{1-rbf_svm.score(X_test_iris, y_test_iris):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"bxQp0Wfx4mbF"},"source":["# **5. Estimación de los hiperparámetros del modelo**\n","---\n","\n","Hasta el momento nos hemos concentrado en evaluar nuestros modelos en una partición de prueba. Sin embargo, es común introducir sobreajuste a través de la modificación manual de los hiperparámetros de un modelo conforme vamos reportando el error de generalización sobre el conjunto de prueba.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1brLudEu094L7H3-cFqnrIRZnDrFIfrNW\">\n","\n","En la anterior imagen, introducimos una nueva partición, adicional a la de prueba y entrenamiento, conocida como partición de \"**validación**\". Esta partición es resultado de tomar la partición de entrenamiento y volver a dividirla (en entrenamiento y validación) de tal forma que cualquier configuración de parámetros que se use para entrenar un modelo, pueda ser reportada en **validación**. Una vez estemos seguros de que tenemos el modelo con el mejor desempeño en **validación**, volvemos a unir ambas particiones, entrenamos un modelo sobre la partición original de entrenamiento y reportamos **una sola vez** en el conjunto de prueba."]},{"cell_type":"markdown","metadata":{"id":"Wj4ecIP54mbI"},"source":["## **5.1. Validación cruzada de  $k$ pliegues**\n","---\n","\n","A pesar de que se introdujo una nueva partición para validar los parámetros de un modelo, se sigue usando una partición reducida para entrenar el conjunto de datos. La **validación cruzada** nos permite usar una mayor parte de los datos para construír el modelo y generar un estimador más robusto y con mayor capacidad de generalización. En validación cruzada, los datos son particionados varias veces en entrenamiento y validación de forma repetida. Finalmente, el desempeño del clasificador es agregado sobre las diferentes particiones de validación para obtener un estimador más robusto.\n","\n","La validación cruzada se hace comúnmente de la siguiente manera:\n","1. Se divide el conjunto de entrenamiento en $k$ pliegues o particiones (usualmente 3, 5 o 10). Estas particiones deben ser del mismo tamaño.\n","2. En cada iteración, uno de los pliegues es usado como la partición de validación, mientras el resto es usado como la partición de entrenamiento.\n","3. Se reporta y guarda el desempeño sobre esa partición de validación.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=12nCvyPDNOgHuxpToJrlR-m71nt3SOrKo\">"]},{"cell_type":"markdown","metadata":{"id":"Z9zTjnsV4mby"},"source":["### **5.1.1. Validación cruzada usando *Scikit-Learn***\n","---\n","\n","*Scikit-Learn* provee una implementación muy eficiente para realizar **validación cruzada** usando métodos del módulo **`sklearn.model_selection`**. El método **`sklearn.model_selection.cross_val_score`** recibe un estimador y un conjunto de datos, luego hace el particionamiento y entrena un modelo sobre cada partición de validación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVG0O_O04mbz"},"outputs":[],"source":["X_iris = iris.data\n","y_iris = iris.target\n","\n","classifier_iris  = LinearSVC()"]},{"cell_type":"markdown","metadata":{"id":"OeoxnT4P4mb1"},"source":["El parámetro **`cv`** en **`cross_val_score`** controla el número de pliegues a usar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_pig3JR4mb2"},"outputs":[],"source":["# Desempeño por validación cruzada.\n","from sklearn.model_selection import cross_val_score\n","\n","scores = cross_val_score(classifier_iris,\n","                         X_iris,\n","                         y_iris,\n","                         cv = 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBXZVTt2_V3i"},"outputs":[],"source":["print(f'Accuracy por cada pliegue:\\n{list(scores)}')\n","print(f'Accuracy promedio sobre los 5 pliegues: {np.mean(scores)}')"]},{"cell_type":"markdown","metadata":{"id":"pKpJSO3i4mb5"},"source":["**`cross_val_score`** realiza por defecto una partición estratificada usando **`sklearn.model_selection.StratifiedKFold`**. Esta estrategia consiste en hacer un particionamiento de tal forma que cada partición tenga la misma distribución de etiquetas $y$.\n","\n","En caso de que se quiera hacer una partición diferente, se puede especificar como argumento **`cv`** otro modelo de validación cruzada. Por ejemplo, si no queremos hacer partición estratificada podemos usar el constructor **`sklearn.model_selection.KFold`**.\n","\n","\n","Una vez declarado un objeto de tipo **`KFold`**, podemos usar el método **`split`** para iterar por los índices de las particiones $X$ y $y$ para cada pliegue autogenerado.\n","\n","A continuación, agregaremos el conteo de clases por cada pliegue y obtendremos el *score* obtenido mediante el método **`cross_val_score`**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOEzcWxL4mb-"},"outputs":[],"source":["# Validación cruzada de K-pliegues.\n","from sklearn.model_selection import KFold, StratifiedKFold\n","n_folds = 5   # Definimos un total de 5 pliegues.\n","\n","cv_no_stra = KFold(n_splits= n_folds)\n","\n","X = iris.data\n","y = iris.target\n","\n","pd.DataFrame(# Conteo de valores por clase. Por los índices de cada pliegue generado.\n","              [np.bincount(y[y_index], minlength = 3)\n","              for X_index, y_index  in cv_no_stra.split(X, y)]\n","              # Renombramos los índices (pliegues) y columnas (clases).\n","              ).rename(index = lambda x: f'Pliegue {x}',\n","                        columns = lambda x: f'Clase {x}'\n","              # Creamos una columna para almacenar el accuracy obtenido en cada pliegue.\n","              ).assign(accuracy = cross_val_score(classifier_iris, X_iris, y_iris, cv=cv_no_stra))"]},{"cell_type":"markdown","metadata":{"id":"t-iqgqFr4mcG"},"source":["## **5.2. Validación cruzada con *Grid Search***\n","---\n","\n","Los modelos *SVM* que usan *RBF* comúnmente requieren el ajuste de los parámetros **`gamma`** (coeficiente $\\gamma$ del *kernel*) y **`C`** (parámetro de regularización.\n","\n","Ambos parámetros controlan la complejidad del modelo. Estos parámetros pueden ser explorados usando un retículo (grid) de valores y evaluando su desempeño usando validación cruzada de $k$ pliegues. A continuación, creamos una partición entrenamiento y prueba sobre el conjunto de datos *Iris*.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"M6FM-TnJjPAv"},"outputs":[],"source":["#@markdown **Video: Experimento con *Grid Search***\n","from IPython.display import HTML\n","\n","HTML('<iframe style=\"width:768px; height: 432px;\" src=\"https://drive.google.com/file/d/15LLpIS-OdeijeMCNmW0NSa56uhp3FQAj/preview\"></iframe>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"90tMB4Sj4mcG"},"outputs":[],"source":["# Partición estratíficada del conjunto de datos Iris.\n","X_train, X_test, y_train, y_test = train_test_split(X_iris,\n","                                                    y_iris,\n","                                                    test_size=0.3,\n","                                                    random_state=1,\n","                                                    stratify=y_iris)"]},{"cell_type":"markdown","metadata":{"id":"wTDnNHTp4mcS"},"source":["Definimos los siguientes valores para $C$ y $\\textit{gamma}$. Vamos a explorar estos valores en el siguiente rango de potencias de 2:\n","\n","> $2^{-5}, 2^{-4}, \\dots , 2^{6}, 2^{7} $"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6XXD8U54mcU"},"outputs":[],"source":["# Los hiperparámetros deben estar en forma de diccionario.\n","param_grid = {'C':     [2**i for i in range(-5, 7, 1)],\n","              'gamma': [2**i for i in range(-5, 7, 1)]}\n","\n","param_grid"]},{"cell_type":"markdown","metadata":{"id":"7KBcxPY64mcc"},"source":["Valores de $C$:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-hARTcE4mcd"},"outputs":[],"source":["print(param_grid['C'])"]},{"cell_type":"markdown","metadata":{"id":"2-6Z8Go94mci"},"source":["Valores de $\\textit{gamma}$:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6UY5V-F4mci"},"outputs":[],"source":["print(param_grid['gamma'])"]},{"cell_type":"markdown","metadata":{"id":"olCCRaVw4mdM"},"source":["Podemos realizar una validación cruzada con *grid search* en los hiperparámetros e identificar la configuración con el mejor *score* utilizando el método **`sklearn.model_selection.GridSearchCV`**. El objeto retornado por este método funciona como los demás modelos e implementa funciones como **`fit`**, **`score`** y **`predict`**.\n","\n","**`GridSearchCV`** recibe tres argumentos principales:\n","* **`estimator`**: modelo de *Scikit-Learn* a explorar. En este ejemplo usaremos  **`SVC(kernel='rbf')`**.\n","* **`param_grid`**: diccionario que contiene los parámetros que se van a explorar usando validación cruzada. La llave del diccionario es el nombre del parámetro y el valor es una lista con los valores que se quieren explorar.\n","* **`return_train_score`**: si se ingresa como argumento el valor **`True`**, los puntajes o *scores* de los modelos entrenados en cada combinación aparecerán en el objeto del atributo **`cv_results_`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmQBKukE4mdO"},"outputs":[],"source":["# Búsqueda en cuadrícula de hiperparámetros.\n","from sklearn.model_selection import GridSearchCV\n","\n","grid_clf = GridSearchCV(SVC(kernel='rbf'),\n","                   param_grid=param_grid,\n","                   verbose=1,\n","                   return_train_score=True\n","                   )\n","\n","grid_clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"I7aLornt4meF"},"source":["**`GridSearchCV`** nos ofrece una serie de atributos y métodos que nos permiten consultar:\n","* La lista de resultados por elemento en la malla de parámetros(**`cv_results_`**).\n","* La configuración con el mejor desempeño (**`best_params_`**).\n","* El *accuracy* promedio sobre todos los pliegues de la mejor configuración(**`best_score_`**)."]},{"cell_type":"markdown","metadata":{"id":"xWSfS_Hg4mdT"},"source":["Los valores promedio de *accuracy* para cada combinación de hiperparámetros se pueden extraer usando **`GridSearchCV.cv_results_`**. Para visualizarlo mejor convertimos ese diccionario a un *DataFrame* de *Pandas*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBpAikAwvNPM"},"outputs":[],"source":["cv_results = pd.DataFrame(grid_clf.cv_results_)\n","cv_results"]},{"cell_type":"markdown","metadata":{"id":"bN60mtVFvWvu"},"source":["Para encontrar las mejores configuraciones, podemos obtener la tabla de los $n$ mayores resultados con *pandas*.\n","> El método **`nlargest`** es un método de los objetos *DataFrame* de *pandas* que permite retornar las $n$ observaciones con mayor valor en la variable deseada. En este caso esa variable es el puntaje del modelo **`mean_test_score`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QVUsKIQTjiS8"},"outputs":[],"source":["# Método nlargest de pandas, con los 10 primeros valores por mean_test_score.\n","cv_results.nlargest(10, 'mean_test_score')"]},{"cell_type":"markdown","metadata":{"id":"Z35hiFLk4meH"},"source":["En este caso la configuración con $C = 1$ y $\\gamma = 1$ es la que aparece como mayor puntaje, empatada con otra configuración con $C = 2$ y $\\gamma = 0.25$. Esta información también se puede consultar usando **`.best_params_`** y **`.best_score_`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFElZaL-4meH"},"outputs":[],"source":["# Mejores parámetros identificados.\n","print(grid_clf.best_params_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxGMvKbr4meP"},"outputs":[],"source":["# Puntaje de la mejor combinación de parámetros.\n","print(grid_clf.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"bRIvxs8u4meW"},"source":["Una vez se haya entrenado el modelo usando validación cruzada, **`GridSearchCV`** escoge automáticamente la mejor configuración y vuelve a entrenar un modelo sobre todo el conjunto de datos de entrenamiento. Por lo tanto tras realizar el entrenamiento con **`fit`** se pueden hacer llamados a funciones como **`predict()`** y **`score()`** directamente desde el objeto de *grid search*.\n","\n","Para reportar sobre el conjunto de prueba basta con ejecutar:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFM0OPD_4meW"},"outputs":[],"source":["grid_clf.score(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"82rDvTJZ4mdp"},"source":["A continuación, vamos a explorar gráficamente los resultados obtenidos en todas las configuraciones. Primero observamos que el número de filas del *DataFrame*  **`cv_results`** corresponde al número de configuraciones de hiperparámetros que se están explorando:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H7_kTqMp4mdq"},"outputs":[],"source":["len(cv_results), len(param_grid['C']) * len(param_grid['gamma'])"]},{"cell_type":"markdown","metadata":{"id":"P1I3xvsv4mdu"},"source":["Usando la columna **`mean_test_score`**, extraemos los valores de precisión o *accuracy* promedio y los organizamos en una matriz donde las filas corresponden a los valores del parámetro **`C`** y las columnas a los valores del parámetro **`gamma`**.\n","\n","Para esto, usaremos el método **`pivot`** de *pandas* que genera una [tabla de pivote](https://en.wikipedia.org/wiki/Pivot_table)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQGNbpnv4mdw"},"outputs":[],"source":["scores_df = cv_results.pivot(index = 'param_C',\n","                             columns = 'param_gamma',\n","                             values = 'mean_test_score')\n","scores_df"]},{"cell_type":"markdown","metadata":{"id":"5LfRh9PB4meA"},"source":["A continuación, presentamos una forma de visualizar esta exploración sobre la malla de hiperparámetros en forma de mapa de calor con el método **`heatmap`** de *Seaborn*, una librería de visualización de datos estadísticos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee_mCKYl4md6"},"outputs":[],"source":["sns.heatmap(scores_df, cmap = 'inferno').set_title('Accuracy en validación');"]},{"cell_type":"markdown","metadata":{"id":"4r5hSQAz6d-g"},"source":["#**Recursos adicionales**\n","---\n","Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *Scikit-learn* en la creación y entrenamiento de modelos de clasificación de lineal, validación cruzada y búsqueda de hiperparámetros, además de material de apoyo teórico para reforzar estos conceptos:\n","\n","* [mlcourse.ai - Topic 3. Classification, Decision Trees and k Nearest Neighbors](https://mlcourse.ai/book/topic03/topic03_decision_trees_kNN.html)\n","* [Curso de aprendizaje automático para el INE- Support Vector Machines](http://albertotb.com/curso-ml-R/Rmd/07-svm/07-svm.html#1)\n","* [A Gentle Introduction to k-fold Cross-Validation](https://machinelearningmastery.com/k-fold-cross-validation/)\n","* [scikit-learn - 3.2.1. Exhaustive Grid Search](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O6dwABE_Zg44"},"source":["# **Créditos**\n","---\n","\n","* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n","* **Asistentes docentes:**\n","  * Miguel Angel Ortiz Marín\n","  * Alberto Nicolai Romero Martínez\n","\n","**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"]}],"metadata":{"colab":{"collapsed_sections":["PtsHcuRCptEV"],"private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
