{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-i_5GQXYoFo6"},"source":["![](https://drive.google.com/uc?export=view&id=1NiRkCapP04t7XxA7fbG7ZWie2PA1L_0M)"]},{"cell_type":"markdown","metadata":{"id":"QkGjEgUIoBIh"},"source":["# **Evaluación del desempeño de modelos de aprendizaje computacional**\n","---\n","En este *notebook* se discutirán los distintos métodos y métricas de evaluación del desempeño en modelos de clasificación (binaria y multiclase) y regresión. Además, se discutirá el algoritmo de K-vecinos más cercanos para clasificación y regresión en los conjuntos de datos *Iris* y *Boston*."]},{"cell_type":"markdown","metadata":{"id":"i0sRGgMB2FUF"},"source":["# **1. Dependencias**\n","---\n","Importamos las librerías necesarias y definimos algunas funciones básicas de visualización que vamos a usar en algunos ejemplos.\n"]},{"cell_type":"markdown","metadata":{"id":"qJgGczNUDVUN"},"source":["### **1.1. Dependencias**\n","---\n","Para la construcción de modelos y ejecución de procedimientos metodológicos de aprendizaje automático, utilizaremos la librería *Scikit-learn* (**`sklearn`**) y varias de sus funciones y conjuntos de datos."]},{"cell_type":"code","source":["!pip install --upgrade matplotlib mlxtend"],"metadata":{"id":"-gg2ewHNZrRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1A1bWvdAsW_B"},"source":["# Actualizamos scikit-learn a la última versión\n","!pip install -U scikit-learn\n","\n","# Importamos scikit-learn\n","import sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlOlDOmbsGII"},"source":["# Librerías básicas de análisis y visualización de datos.\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns   # Librería de visualización de datos estadísticos.\n","import mlxtend          # Librería de utilidades de aprendizaje computacional."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nmx-RGqF8Hls"},"source":["# Configuraciones para las librerías y módulos usados\n","\n","# Ignoramos las advertencias o warnings.\n","import warnings\n","warnings.simplefilter(action='ignore')\n","\n","# Configuramos el formato por defecto de la\n","# librería de visualización Matplotlib.\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxNzX3sfq3gZ"},"source":["Este material se realizó con las siguientes versiones:\n","*  *Python*: 3.7.10\n","*  *Scikit-learn*: 0.24.1\n","*  *NumPy*:  1.19.5\n","*  *Pandas*:  1.1.5\n","*  *Matplotlib*:  3.2.2\n","*  *Seaborn*:  0.11.1"]},{"cell_type":"code","metadata":{"id":"jUMP_2CPqwRY"},"source":["# Versión de Python y las demás librerías.\n","!python --version\n","print('Scikit-learn', sklearn.__version__)\n","print('NumPy', np.__version__)\n","print('Pandas', pd.__version__)\n","print('Matplotlib', mpl.__version__)\n","print('Seaborn', sns.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmFrETF-Osjj"},"source":["### **1.2. Funciones de utilidad y visualización**\n","---\n","\n","Para ilustrar los ejemplos discutidos en este material utilizaremos algunas funciones que permiten visualizar de manera general los datos y conceptos discutidos en las secciones.\n","\n","> **Nota**: *Matplotlib*, *Seaborn* y *mlxtend* se encuentran por fuera del alcance de este módulo. No es necesario que entienda estas funciones en detalle para sacar partido del resto del contenido puesto a su disposición. Usted decide si leer o no estas funciones en profundidad. Si decide omitir esta sección, continúe directamente con la siguiente sección, en donde se discutirán los conjuntos de datos que vamos a utilizar."]},{"cell_type":"code","metadata":{"id":"y2YdbsswCibw"},"source":["from mlxtend.plotting import plot_decision_regions\n","\n","# Función para visualizar la superficie de decisión de un clasificador.\n","def plot_decision_region(X, y, clf, classes, title = \"\"):\n","  fig, ax = plt.subplots(dpi = 120)\n","  plot_decision_regions(X, y, clf = clf, ax = ax)\n","  handles, _ = ax.get_legend_handles_labels()\n","  ax.legend(handles, classes)\n","  ax.set_title(title)\n","  fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiVBW_kBwTst"},"source":["def list_confusion_matrix(cm,classes):\n","  df = pd.DataFrame(data = cm,\n","                    index = pd.MultiIndex.from_product([['Valor real'], classes]),\n","                    columns = pd.MultiIndex.from_product([['Valor predicho'], classes]))\n","\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RURwOVpHIb2P"},"source":["# **2. Conjuntos de datos**\n","---\n","\n","Como se mencionó, utilizaremos el conjunto de datos *Iris* para los ejemplos de clasificación binaria y clasificación con varias clases y el conjunto de datos *Boston* para los ejemplos de regresión."]},{"cell_type":"markdown","metadata":{"id":"A3ChcqtvZBw7"},"source":["### **2.1. Conjunto de datos *Iris***\n","---\n","Para el problema de clasificación binaria solo consideraremos $2$ etiquetas y para clasificación con varias clases usaremos las $3$ etiquetas del conjunto de datos *Iris*.En está sección cargaremos el conjunto de datos y haremos una pequeña exploración de datos inicial.\n","\n","Cargamos *Iris* del paquete **`sklearn.datasets`**:\n"]},{"cell_type":"code","metadata":{"id":"HXxW1azdoFqw"},"source":["# Loader del conjunto de datos Iris.\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xZzc_NbioFq3"},"source":["Podemos observar que contiene este objeto que nos regresa *Scikit-learn* usando el atributo **`keys()`**:"]},{"cell_type":"code","metadata":{"id":"pbcDY2XjoFq5"},"source":["iris.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"92VGdynLZygM"},"source":["Con la llave **`DESCR`** podemos acceder a una descripción general del conjunto de datos:"]},{"cell_type":"code","metadata":{"id":"WjbLRWHMZ5I2"},"source":["print(iris.DESCR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k2t26UJooFrG"},"source":["Encontramos que el número de muestras y características de **`data`** es:"]},{"cell_type":"code","metadata":{"id":"jk86Ro9hoFrH"},"source":["n_samples, n_features = iris.data.shape\n","\n","print('Número de muestras:', n_samples)\n","print('Número de características:', n_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z2YcDi4EoFrQ"},"source":["Observamos que cada fila corresponde a un ejemplar de una especie de flor. Cada flor tiene asociado una serie de características, como el ancho y largo del sépalo, y el ancho y largo del pétalo.\n","\n","![](https://drive.google.com/uc?export=view&id=1TB-7jzOkgnA-EAnDFWJgIzyb0fbY89XH)"]},{"cell_type":"code","metadata":{"id":"ljf6Nq5coFrR"},"source":["for var, value in zip(iris.feature_names, iris.data[-1]):\n","  print(f\"Variable {var}: {value}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1SGFFny8oFrv"},"source":["Las especies que tratamos de predecir están almacenadas en el atributo **`target_names`**:"]},{"cell_type":"code","metadata":{"id":"3DGCLjH1oFr1"},"source":["print(iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rsv8GRdwoFr-"},"source":["La distribución de las etiquetas es uniforme en el conjunto de datos, es decir, existe el mismo número (50) de flores por especie en el conjunto de datos:"]},{"cell_type":"code","metadata":{"id":"dHO-2J6XafHC"},"source":["# Cargamos el dataset Iris en forma de DataFrame\n","# del repositorio de datos de Seaborn.\n","iris_df = sns.load_dataset('iris')\n","\n","# Graficamos la distribución de las etiquetas.\n","sns.catplot(x='species', kind='count', data=iris_df, height=4, aspect=1.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DzLhmffuoFsO"},"source":["Utilizando la función **`pairplot`** de *Seaborn* podemos visualizar todas las características de *Iris*.\n","\n","> **`pairplot`** nos permite visualizar sobre la diagonal la distribución de las clases respecto a cada característica en forma de histograma y por cada par de características con un diagrama de dispersión. Puede tardar un poco en generar la visualización."]},{"cell_type":"code","metadata":{"id":"yGD5SM94oFsO"},"source":["sns.pairplot(iris_df, hue='species');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJRS8d16oFsV"},"source":["Podemos observar que en general la clase setosa se encuentra bien separada de las clases versicolor y virginica."]},{"cell_type":"markdown","metadata":{"id":"2h8HJs_KYA96"},"source":["### **2.2 Conjunto de datos _Boston_**\n","---\n","\n","Cargamos el conjunto de datos *Boston* con *scikit-learn*:"]},{"cell_type":"code","metadata":{"id":"tks3bLEoYEAE"},"source":["# Loader del conjunto de datos Boston.\n","from sklearn.datasets import fetch_openml\n","\n","boston = fetch_openml(name='boston', as_frame=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aWTAzlr5YkzF"},"source":["Revisamos las llaves del diccionario:"]},{"cell_type":"code","metadata":{"id":"kNWTzII6YcVb"},"source":["print(boston.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uHw5m2uMYoBe"},"source":["*Boston* es un conjunto de datos que plantea un problema de **regresión** y no existe una distinción por clases de su variable objetivo.\n","\n","En un problema de regresión la etiqueta asociada a cada ejemplo corresponde a una **cantidad**. Por ejemplo, con el conjunto de datos *Boston* estamos buscando predecir el precio de casas a partir de algunas de sus características."]},{"cell_type":"code","metadata":{"id":"xak9401RYPuD"},"source":["# Características del dataset Boston.\n","print(boston['feature_names'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7sSWwHj1yPF7"},"source":["Para saber mejor a que se refieren las abreviaciones podemos revisar la descripción del conjunto de datos con el atributo **`DESCR`**:"]},{"cell_type":"code","metadata":{"id":"AUvZMIJmZEJb"},"source":["print(boston['DESCR'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8Yz7z31yek9"},"source":["Podemos ver que el conjunto de datos tiene características como índices de criminalidad, impuestos, número de cuartos, entre otros, de propiedades en zonas urbanas. La variable objetivo **`target`** corresponde a la variable **`MEDV`**, que representa la mediana del valor de las casas en una zona.\n","\n","Veamos los primeros $5$ ejemplos:"]},{"cell_type":"code","metadata":{"id":"rWMtkfate_FT"},"source":["boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n","boston_df.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Y-V-yz10dU4"},"source":["Nuestro objetivo es centrarnos en la evaluación del desempeño, por lo cual no realizaremos más exploración de los datos. Procederemos directamente con entrenar modelos y evaluar su desempeño."]},{"cell_type":"markdown","metadata":{"id":"BkVcLaK5ptAr"},"source":["# **3.  Algoritmo: K-vecinos más cercanos (KNN)**\n","---\n","\n","La clasificación basada en vecinos es un tipo de aprendizaje basado en ejemplos. El modelo almacena los ejemplos vistos durante entrenamiento y clasifica un elemento no visto usando una simple regla de votación por mayoría. Si se ubica un **punto** en el espacio de características, se le asigna como clase el valor de la clase que tenga la mayor cantidad de ejemplos en la vecindad del punto. Este ejemplo lo podemos ver ilustrado en la siguiente imagen:\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=10I5967XssKpLQLivqER1uwfEw9qIsARd\" width=500>\n","\n","Para ilustrar el concepto utilizaremos el conjunto de datos artificial de medias lunas *moons* de *Scikit-learn*:\n","\n"]},{"cell_type":"code","metadata":{"id":"8COZWYlhJcjY"},"source":["# Generamos un conjunto de datos artificial de dos clases en forma de medias lunas.\n","X_moons, y_moons = datasets.make_moons(n_samples=100, noise=0.3, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nrxjheNF0ay"},"source":["*Scikit-Learn* provee una implementación del algoritmo *KNN* conocida como **`KNeighborsClassifier`**. Esta tiene un parámetro **`n_neighbors`** (el valor $k$), un entero definido por el usuario que determina cuántos vecinos evalúa para determinar la clase de una instancia nunca antes vista. La elección de este parámetro es definida totalmente por la naturaleza de los datos.\n","\n","Vamos a declarar el clasificador y entrenarlo con los datos del conjunto de datos artificial:"]},{"cell_type":"code","metadata":{"id":"zbKZM2Pv924o"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier(n_neighbors= 1)\n","knn.fit(X_moons, y_moons)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k__M-QJ-GHZV"},"source":["En este caso definimos que $k$ solo tenga en cuenta $1$ vecino más cercano. Si visualizamos la región de decisión podremos observar unas franjas de color azul (clase **A**) en la zona predominantemente naranja (clase **B**), en las cuales el valor más cercano es un único valor de la clase **A** ubicado por aleatoriedad."]},{"cell_type":"code","metadata":{"id":"qqFMSmjfE86y"},"source":["plot_decision_region(X_moons, y_moons, knn,\n","                     classes = ['A', 'B'],\n","                     title = 'KNN como clasificador de medias lunas')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBsisrdLDguy"},"source":["Observaremos que dependiendo del valor de vecinos más cercanos $k$ que definamos, conseguimos diferentes funciones de ajuste, unas más suaves que otras.\n","\n","Vamos a evaluar el efecto del parámetro $k$ en la complejidad del modelo."]},{"cell_type":"markdown","metadata":{"id":"Bm2u828DoFsX"},"source":["#**4. Evaluación del desempeño - Clasificación Binaria**\n","---\n","\n","Ahora que conocemos el conjunto de datos *Iris*, queremos entrenar un modelo que sea capaz de clasificar de forma automática cualquier flor representada en un conjunto de datos (a partir del ancho del pétalo (cm), largo del sépalo (cm)', largo del pétalo (cm)' y ancho del pétalo (cm)).\n","\n","En **clasificación binaria** se busca identificar la pertenencia de un ejemplo a una clase específica, con un total de $2$ clases en la variable objetivo ($1$ si pertenece y $0$ si no pertenece).\n","Para realizar un modelo de este tipo con *Iris* vamos a filtrar aquellas flores que pertenezcan a las clases *versicolor* y *virginica*."]},{"cell_type":"code","metadata":{"id":"uPI9-5NzoFsf"},"source":["X = iris.data\n","y = iris.target\n","\n","# Filtramos la clase 1 y 2 que corresponden a versicolor y virginica.\n","X = X[(y == 1) | (y == 2)]\n","y = y[(y == 1) | (y == 2)]\n","\n","# Para que las clases queden entre 0 y 1\n","# le restamos 1 a todos los valores.\n","y = y - 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9HgJfl4wVLB"},"source":["X.shape, y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kT_-FrOLoFsp"},"source":["Inicialmente, entrenamos el modelo **`KNeighborsClassifier`** con todos los datos y verificamos los valores predichos."]},{"cell_type":"code","metadata":{"id":"fxdSlrlsoFsp"},"source":["# Módulo de Scikit-learn para modelos lineales.\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Declaramos y entrenamos el modelo.\n","classifier = KNeighborsClassifier()\n","classifier.fit(X, y)\n","predictions = classifier.predict(X)\n","\n","n = 30\n","print(f'Número de instancias a predecir: {n}')\n","print(f'Valores reales: {y[:n]}')\n","print(f'Valores predichos: {predictions[:n]}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-NqoylloFsx"},"source":["> **Pregunta**: ¿Cómo evaluamos el desempeño de nuestro clasificador?"]},{"cell_type":"markdown","metadata":{"id":"hijAXHDqptCO"},"source":["## **4.1. Error de entrenamiento y generalización**\n","---\n","\n","Un modelo de aprendizaje de máquina tiene como objetivo principal hacer predicciones de manera acertada sobre ejemplos nunca antes vistos por el modelo. Esto se conoce como **error de generalización**. Para poder medir el error de generalización, dividimos el conjunto de datos en dos particiones:\n","\n","* **Entrenamiento**: Se usa para entrenar el modelo.\n","* **Prueba**: Se usa para estimar el error de generalización.\n","\n","En la siguiente imagen encontramos una ilustración de cómo se hace un particionamiento en entrenamiento y prueba de manera gráfica:\n","\n","<center>\n","<img src=\"https://drive.google.com/uc?export=view&id=1wTnv5b52qkLDhgkBgHvA6zs_BEW9a44R\">\n","</center>\n","\n","Una de las prácticas recomendadas, es particionar los datos $70\\%$ para entrenamiento y $30\\%$ para prueba. Cuando el número de muestras es muy grande ($\\ge 70K$), podemos reducir el porcentaje de muestras para prueba, a $90-10\\%$. Sin embargo, deben hacerse unas aclaraciones sobre la generalización:\n","\n","* **El conjunto de prueba debe ser una muestra representativa del conjunto de datos.** El muestreo de ejemplos debe hacerse de forma independiente e idénticamente aleatoria de una distribución. Esto quiere decir, que el muestreo de un ejemplo no está influenciado por el muestreo de otro.\n","* **La distribución es estacionaria.** Es decir, no cambia a lo largo del conjunto de datos.\n","* **Los ejemplos son muestreados desde particiones de la misma distribución.** Es decir, no se deben crear nuevas características en la partición de prueba.\n","\n","Adicionalmente, debemos tener en cuenta que se conserve la distribución de las etiquetas de los datos tanto en entrenamiento como en prueba (estratificación). En un *notebook* posterior se va a estudiar en más detalle los efectos de hacer una partición estratificada.\n","\n","Como se discutió en materiales previos, *Scikit-Learn* permite particionar un conjunto de datos en entrenamiento y prueba de manera automática con una diversidad de funciones de selección de modelos.\n","\n","A continuación, vamos a dividir el conjunto en $70\\%$ para entrenamiento y $30\\%$ para prueba:"]},{"cell_type":"code","metadata":{"id":"tMx3JeizhTHv"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,\n","                                                    y,\n","                                                    test_size=0.3,\n","                                                    stratify=y,\n","                                                    random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZzxh2nxptCX"},"source":["El argumento **`stratify`** le indica a *Scikit-learn* que se desea estratificar los datos con respecto a **`y`**.\n","\n","Vamos a verificar el número de muestras de ambas particiones y la distribución de clases de cada una."]},{"cell_type":"code","metadata":{"id":"3MH4c-gJptCc"},"source":["print(f'Número de muestras en entrenamiento: {X_train.shape[0]}')\n","print(f'Número de muestras en prueba: {X_test.shape[0]}')\n","print(f'Número de características: {X_train.shape[1]}')\n","\n","# La función np.bincount permite realizar el conteo\n","# de ocurrencia de valores enteros en un arreglo.\n","\n","print(f'Distribución de clases en entrenamiento: {np.bincount(y_train)}')\n","print(f'Distribución de clases en prueba: {np.bincount(y_test)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rw_4pEFghsQ-"},"source":["Procedemos a entrenar un modelo de clasificación por *K-vecinos* sobre la partición de entrenamiento:\n","\n","> **Nota**: La partición de prueba está destinada a validar el desempeño del modelo y sus datos no deberían ser vistos por el clasificador."]},{"cell_type":"code","metadata":{"id":"hKnKiDlgh44L"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","classifier = KNeighborsClassifier(n_neighbors=5)\n","classifier.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y6zWMAepoFs0"},"source":["## **4.2. Exactitud o *accuracy***\n","---\n","Con el objetivo de conocer el desempeño de nuestro clasificador se suele medir cuantitativamente cuantas predicciones fueron correctas. Este número se conoce como **exactitud** o **_accuracy_** en inglés y es la métrica por defecto en muchos de los modelos de clasificación de *Scikit-learn*."]},{"cell_type":"code","metadata":{"id":"a4qEle8LoFs1"},"source":["prediction = classifier.predict(X_test)\n","\n","# Número de valores acertados de una predicción.\n","np.mean(prediction == y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JwBV4S-aoFs8"},"source":["*Scikit-learn* nos permite evaluar también el accuracy con la función **`.score`** de un clasificador:"]},{"cell_type":"code","metadata":{"id":"kQibULlfoFs-"},"source":["classifier.score(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-d6O1NRYC0y"},"source":["También se puede realizar de forma explícita mediante la función **`accuracy_score`** del módulo **`sklearn.metrics`**."]},{"cell_type":"code","metadata":{"id":"kP9v_QJNYITC"},"source":["from sklearn.metrics import accuracy_score\n","\n","y_pred = classifier.predict(X_test)\n","accuracy_score(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgZ3Aq5VoFtI"},"source":["## **4.3. Matriz de confusión**\n","---\n","\n","No obstante, es importante conocer qué clases clasifica mejor. Para poder visualizar esta información, usaremos la **matriz de confusión**, la cual es una clase especial de tabla de contingencia en la cual se comparan las clases reales contra las clases predichas por el clasificador.\n","\n","**Scikit-Learn** nos permite construir la matriz de confusión usando la función **`sklearn.metrics.confusion_matrix`**, que recibe como argumento dos listas o arreglos de *NumPy*:\n","* $y$: etiquetas reales del conjunto de datos.\n","* $\\hat{y}$: etiquetas predichas por el clasificador sobre el conjunto de datos."]},{"cell_type":"code","metadata":{"id":"Txq4uEjSoFtJ"},"source":["from sklearn.metrics import confusion_matrix\n","\n","y_pred = classifier.predict(X_test)\n","cnf_matrix = confusion_matrix(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrSe-cl-oFtM"},"source":["La función **`confusion_matrix`** regresa una matriz de tamaño [$\\textit{n_clases}$, $\\textit{n_clases}$], dónde $\\textit{n_clases}$ corresponde al número de clases únicas en el conjunto de datos. La matriz de confusión nos permite comparar el rendimiento de nuestro clasificador clase por clase."]},{"cell_type":"code","metadata":{"id":"EKQus70XoFtN"},"source":["cnf_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"st1x4sRdoFtR"},"source":["A continuación, vamos a usar la función definida al comienzo de este *notebook* para generar de una forma más visual la matriz de confusión."]},{"cell_type":"code","metadata":{"id":"x8xovL-vkGvy"},"source":["class_names = iris.target_names[1:]\n","list_confusion_matrix(cnf_matrix,class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gMnwv_5XoFtg"},"source":["> **¿Cómo interpretarla?**\n","\n","* Los valores en la diagonal indican los aciertos de nuestro clasificador. Por ejemplo, sabemos que de $15$ ejemplos de la clase *virginica*, supo clasificar $14$, mientras que de $15$ ejemplos de la clase *versicolor* se equivocó en $3$."]},{"cell_type":"markdown","metadata":{"id":"AOIOM993oFt0"},"source":["> **¿Qué pasa cuando el problema es desbalanceado?**\n","\n","Supongamos un clasificador $G$ con el siguiente desempeño sobre un conjunto de datos:\n","\n","* $\\text{Accuracy} = \\frac{99}{100} = 99\\%$  \n","* $\\text{Error} = \\frac{1}{100} = 1\\%$  \n","\n","> **¿Es un buen clasificador?**\n","\n","Para medir efectivamente si $G$ es un buen clasificador, presentamos la matriz de confusión producto de sus predicciones."]},{"cell_type":"code","metadata":{"id":"TuHTjgchiD0n"},"source":["# Clases de ejemplo.\n","class_names = ['C_+', 'C_-']\n","\n","# Valores reales y predichos de ejemplo.\n","y_pred_G = np.ones(100)\n","y_test_G = np.ones(100)\n","y_test_G[-1] = 0\n","\n","mat = confusion_matrix(y_test_G, y_pred_G)\n","list_confusion_matrix(mat, class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJoLSJPLymMh"},"source":["A pesar de que el modelo clasificó correctamente $99$ muestras de la clase negativa, falló en clasificar la única muestra positiva del conjunto de datos."]},{"cell_type":"markdown","metadata":{"id":"0k4wrkadoFt8"},"source":["## **4.4. Métricas de precisión, *Recall* y F1**\n","---\n","\n","La matriz de confusión nos permite calcular otra serie de medidas para evaluar el desempeño del clasificador. Para introducir estas medidas, vamos a descomponer la matriz de confusión en cuatro partes:\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1TpRcKg1FTp7lcQx-YPwu0aTJQVNd3W2J\" width=500>\n","\n","\n","Los componentes de esta matriz pueden interpretarse como:\n","* **Verdaderos positivos (VP)**. Resultado correcto para la clase positiva.\n","* **Verdaderos negativos (VN)**. Ausencia correcta para la clase positiva.\n","* **Falsos positivos (FP)**. Resultados inesperados.\n","* **Falsos negativos (FN)**. Resultados faltantes.\n","\n","> **Nota**: Vale la pena aclarar que, en clasificación binaria, los términos *positivo* o *negativo* se refieren a la predicción del clasificador (clase), mientras que *verdadero* o *falso* se refieren a si la predicción fue correcta o no."]},{"cell_type":"markdown","metadata":{"id":"hU4LS8WjoFt-"},"source":["De esta matriz podemos volver a escribir las definiciones de *accuracy* y error:\n","\n","* $\\text{accuracy} = \\frac{\\text{VP} + \\text{VN}}{\\text{VP} + \\text{VN} + \\text{FP} + \\text{FN}}$\n","\n","* $\\text{error} = \\frac{\\text{FP} + \\text{FN}}{\\text{VP} + \\text{VN} + \\text{FP} + \\text{FN}}$  \n","\n","Además de estas, podemos definir las siguientes métricas:\n","\n","* **Precisión**: se puede definir como la habilidad del clasificador de **no** clasificar una muestra como positiva cuando es negativa.\n","\n","  > $\\text{PRE} = \\frac{\\text{VP}}{\\text{VP} + \\text{FP}}$\n","\n","\n","* ***Recall* (índice de recuperación)**:  se puede definir como la capacidad del clasificador de encontrar todas las muestras positivas.\n","  > $\\text{REC} = \\frac{\\text{TP}}{\\text{FN} + \\text{TP}}$\n","\n","* **$F_1$ score**: se define como el promedio ponderado entre la precisión y el *recall*.\n","\n","  >$\\text{F}_1 = 2 * \\frac{\\text{PRE}*\\text{REC}}{\\text{PRE} + \\text{REC}}$\n","\n","Evaluemos la precisión y el índice de recuperación de nuestro clasificador $G$:\n","\n","* $\\text{Precision} = \\frac{0}{0}$ = No definida\n","* $\\text{Recall} = \\frac{0}{1} = 0\\%$ Recall\n","\n","*Scikit-learn* provee diferentes funciones para calcular estas tres medidas. Estas son:\n","\n","* **Precisión: `sklearn.metrics.precision_score`**\n","* **_Recall_: `sklearn.metrics.recall_score`**\n","* **$F_1$ score: `sklearn.metrics.f1_score`**\n","\n","\n","Vamos a medir el desempeño sobre el clasificador $G$:"]},{"cell_type":"code","metadata":{"id":"yg3zJJ9poFuA"},"source":["from sklearn import metrics\n","\n","print(f'Precisión: {metrics.precision_score(y_test_G, y_pred_G, pos_label=0)}')\n","print(f'Recall:    {metrics.recall_score(y_test_G, y_pred_G, pos_label=0)}')\n","print(f'F_1 score: {metrics.f1_score(y_test_G, y_pred_G, pos_label=0)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SjIXEbc_oFuO"},"source":["> El argumento **`pos_label`** indica cual etiqueta corresponde a la clase positiva. Para nuestro ejemplo hemos tomado la clase $0$ como la clase positiva. Por otro lado, *Scikit-learn* le asigna el valor $0$ a estas métricas, aunque no estén bien definidas (por ejemplo si el denominador es 0).\n","\n","\n","Regresando al problema de clasificación sobre *Iris*, podemos calcular el valor de la precisión, _recall_ y $F_1$ de la misma manera:"]},{"cell_type":"code","metadata":{"id":"sxCoztLAoFuP"},"source":["print(f'Precisión: {metrics.precision_score(y_test, prediction):.4f}')\n","print(f'Recall:    {metrics.recall_score(y_test, prediction):.4f}')\n","print(f'F_1 score: {metrics.f1_score(y_test, prediction):.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0NgqdQ2hoFuU"},"source":["#**5. Evaluación del desempeño - Clasificación Multiclase**\n","---\n","Esta vez usaremos todos los ejemplos de cada una de las tres especies de flor del *dataset Iris*. Para obtener una representación gráfica, nos limitaremos a dos variables numéricas de entrada (longitud del sépalo en $x$ y longitud del pétalo en $y$).\n","\n","Primero que todo realizamos la partición de los datos en entrenamiento y prueba:"]},{"cell_type":"code","metadata":{"id":"WmYVgNlhmah_"},"source":["# Esta vez usamos las 3 clases y solo 2 variables.\n","\n","X = iris.data[:,[0, 2]]\n","y = iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n","                                                    stratify=y, random_state=31)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tf46KWdUxkTM"},"source":["print('El shape de X_train es:', X_train.shape)\n","print('El shape de y_train es:', y_train.shape)\n","\n","print('El shape de X_test es:', X_test.shape)\n","print('El shape de y_test es:', y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lszYXr-dUouQ"},"source":["Entrenaremos dos modelos *KNN* **`clf_k1`** y **`clf_k1`**, donde **`clf_k5`** usará los $5$ vecinos más cercanos y **`clf_k1`** solo el más cercano.\n","\n","Definimos el clasificador **`clf_k1`** y lo entrenamos:"]},{"cell_type":"code","metadata":{"id":"i77lrCWnsmsv"},"source":["# Clasificador KNN con k = 1.\n","clf_k1 = KNeighborsClassifier(n_neighbors=1)\n","clf_k1.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HWMAYrqUkyP"},"source":["Definimos el clasificador **`clf_k5`** y lo entrenamos:"]},{"cell_type":"code","metadata":{"id":"2llJl613oFuZ"},"source":["# Clasificador KNN con k = 5.\n","clf_k5 = KNeighborsClassifier(n_neighbors=5)\n","clf_k5.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KJ8FTY13oFuh"},"source":["A continuación, visualizamos las regiones de decisión para cada clasificador:"]},{"cell_type":"code","metadata":{"id":"EPUi46DxA8Vj"},"source":["plot_decision_region(X_test, y_test, clf_k1, iris.target_names,\n","                title = 'Región de Decisión KNN (k = 1)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jlMVbbVloFuh"},"source":["plot_decision_region(X_test, y_test, clf_k5, iris.target_names,\n","                title = 'Región de Decisión KNN (k = 5)')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xZG_blhAU3OL"},"source":["Podemos notar que a medida que **`n_neighbors`** es mayor, la región de decisión es más suave. En el caso de **`n_neighbors = 1`**, el modelo se está ajustando a las particularidades de la partición de entrenamiento."]},{"cell_type":"markdown","metadata":{"id":"e1jeIs9voFus"},"source":["### **5.1. Matriz de confusión con más de 2 clases**\n","---\n","\n","La matriz de confusión se puede extender al problema multiclase de la siguiente manera:\n","\n","\n","\n","Primero, visualizaremos la matriz de confusión para el modelo *KNN* con **`n_neighbors=1`**:"]},{"cell_type":"code","metadata":{"id":"KeLaZbzGlv4e"},"source":["y_pred = clf_k1.predict(X_test)\n","\n","# Generamos y mostramos la matriz de confusión.\n","mat = confusion_matrix(y_test, y_pred)\n","list_confusion_matrix(mat, iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YKA9lcZYfoai"},"source":["Ahora calculamos la matriz de confusión para el modelo con **`n_neighbors=5`**:"]},{"cell_type":"code","metadata":{"id":"JYXHMtsVydNb"},"source":["y_pred = clf_k5.predict(X_test)\n","\n","# Generamos y mostramos la matriz de confusión.\n","mat = confusion_matrix(y_test, y_pred)\n","list_confusion_matrix(mat, iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xa_QlLTZoFu1"},"source":["A simple vista podemos identificar que:\n","* La clase *setosa* es fácil de clasificar para ambos clasificadores.\n","* La clase *virginica* es más difícil de clasificar que la clase *versicolor*, pues con **`n_neighbors=5`** el modelo obtiene puntaje perfecto para *versicolor* pero sigue fallando con $2$ ejemplos de *virginica*.\n","\n","De nuevo, es útil usar una medida de desempeño para comparar cuantitativamente el rendimiento de ambos modelos."]},{"cell_type":"markdown","metadata":{"id":"8MG7hb004u9N"},"source":["### **5.2. *Accuracy* multiclase**\n","---\n","\n","El *accuracy* multiclase se define como la fracción de predicciones correctas del clasificador. Se puede calcular con la siguiente fórmula:\n","\n","$$\n","\\texttt{acc}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n-1} 1(\\hat{y}_i = y_i)\n","$$\n","\n","dónde $y$ corresponde a la lista de etiquetas de verdad de nuestro conjunto de datos, mientras $\\hat{y}$ corresponde a los valores predichos por nuestro clasificador para el mismo conjunto de datos **en el mismo orden**, y $n$ corresponde al número de ejemplos del conjunto.\n","\n","*Scikit-Learn* nos permite calcular el *accuracy* de la misma manera que con un modelo de clasificación binaria:"]},{"cell_type":"code","metadata":{"id":"DcRMdejwoFu2"},"source":["print(f'Accuracy n_neighbors = 1: {clf_k1.score(X_test, y_test):.4f}')\n","print(f'Accuracy n_neighbors = 5: {clf_k5.score(X_test, y_test):.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4myYytQloFu-"},"source":["El modelo de regresión logística se desempeña mejor frente al modelo \"*Uno vs Todos*\". El error se puede definir como la fracción de predicciones incorrectas del clasificador:"]},{"cell_type":"code","metadata":{"id":"p83mNNQP5Qol"},"source":["print(f'Error n_neighbors = 1: {1 - clf_k1.score(X_test, y_test):.4f}')\n","print(f'Error n_neighbors = 5: {1 - clf_k5.score(X_test, y_test):.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13I5aDVloFvG"},"source":["### **5.3. Precisión, *recall* y $F_1$ *score* en clasificación multiclase**\n","---\n","\n","La métrica de precisión era calculada con base a la matriz de confusión del problema de clasificación binaria. De igual manera, se puede extender como medida de desempeño para el problema multiclase de varias formas. Recordemos que:\n","\n","* $\\text{Precisión} = \\frac{\\text{VP}}{\\text{VP} + \\text{FP}}$\n","* $\\text{Recall} = \\frac{\\text{VP}}{\\text{VP} + \\text{FN}}$\n","* $F_1 = 2 * \\frac{\\text{PRE}*\\text{REC}}{\\text{PRE} + \\text{REC}}$\n","\n","Para ilustrar como se calcula cada una de estas medidas, usaremos el clasificador con **`n_neighbors=1`**.\n","\n","Primero calculamos la precisión para cada clase y luego determinamos la forma en la que combinamos las precisiones de cada clase. *Scikit-Learn* nos permite calcular la precisión y *recall* por clase así:\n","\n","* **Nota**: Al definir el argumento **`average = None`** se le indica al cálculo de la métrica que se retorne el valor de la métrica por cada clase, en vez de realizar una agregación general para todo el conjunto de datos."]},{"cell_type":"code","metadata":{"id":"2CrAg-qXoFvG"},"source":["from sklearn.metrics import precision_score, recall_score\n","y_pred = clf_k1.predict(X_test)\n","\n","print(f'Orden de las etiquetas: {iris.target_names}')\n","print(f'Precisión por clase: \\t{precision_score(y_test, y_pred, average=None)}')\n","print(f'Recall por clase: \\t{recall_score(y_test, y_pred, average=None)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OO4LvjY1oFvL"},"source":["Añadimos un par de cálculos a nuestra tabla con la matriz de confusión, donde reflejamos la suma de los valores totales de verdaderos positivos, falsos positivos y falsos negativos. Existen varias formas de combinar o agregar las medidas de precisión y *recall* por clase, que son definidas a partir del argumento **`average`** de las métricas mencionadas. Algunos de los posibles valores son:\n","* **`micro`** : Cuenta el total de positivos verdaderos, falsos positivos y falsos negativos para realizar el cálculo de la métrica.\n","* **`macro`** : Calcula la métrica por cada clase y luego la promedia (sin tener en cuenta el balance de clases).\n","* **`weighted`** : Calcula la precisión por clase y luego la promedia teniendo en cuenta el balance de clases.\n","\n","| Clase    | VP   | FP   | FN   | PRE  | REC  |\n","|----------|------|------|------|------|------|\n","|Setosa    | 15   | 0    | 0    | 1.0  | 1.0  |\n","|          |      |      |      |      |      |\n","|Versicolor| 14   | 3    | 1    | 0.824 | 0.933  |\n","|          |      |      |      |      |      |\n","|Virginica | 12   | 1    | 3    | 0.923 | 0.800 |\n","|          |      |      |      |      |      |\n","|Sum(micro)| 41  | 4   | 4   | 0.911 | 0.911 |\n","|          |      |      |      |      |      |\n","|Avg(macro)|      |      |      | 0.916 | 0.911 |\n"]},{"cell_type":"code","metadata":{"id":"JqQukW86oFvM"},"source":["print(f\"Precisión macro: {precision_score(y_test, y_pred, average='macro'):.4f}\")\n","print(f\"Precisión micro: {precision_score(y_test, y_pred, average='micro'):.4f}\")\n","print(f\"Precisión ponderada: {precision_score(y_test, y_pred, average='weighted'):.4f}\\n\")\n","\n","print(f\"Recall macro: {recall_score(y_test, y_pred, average='macro'):.4f}\")\n","print(f\"Recall micro: {recall_score(y_test, y_pred, average='micro'):.4f}\")\n","print(f\"Recall ponderada: {recall_score(y_test, y_pred, average='weighted'):.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6nux56MQoFvU"},"source":["Como observamos, estos valores corresponden a las dos últimas filas que se calcularon sobre la tabla de precisión y *recall*. Vale la pena anotar que **`weighted`** y **`macro`** son iguales cuando la clase es balanceada, tal como en el ejemplo de *Iris*. Esto se puede extender al cálculo del $F_1 \\textit{score}$. Recordemos que el $F_1 \\textit{score}$  es un promedio ponderado de la precisión y el *recall*."]},{"cell_type":"code","metadata":{"id":"ymTIpVw7oFvZ"},"source":["from sklearn.metrics import f1_score\n","\n","print(f\"F1 macro: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n","print(f\"F1 micro: {f1_score(y_test, y_pred, average='micro'):.4f}\")\n","print(f\"F1 ponderada: {f1_score(y_test, y_pred, average='weighted'):.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XrcTy3C2tDxx"},"source":["Para finalizar, *Scikit-Learn* permite realizar un reporte general con todas las métricas mencionadas con la función **`classification_report`** del módulo **`sklearn.metrics`**:"]},{"cell_type":"code","metadata":{"id":"RLvlqghftHHL"},"source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test,\n","                            y_pred,\n","                            target_names=iris.target_names,\n","                            digits=4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eb2mm-1zvkn8"},"source":["Utilizamos el parámetro **`digits`** para indicar cuantos dígitos reportar y **`target_names`** para indicarle a **`classification_report`** los nombres de las clases.\n","\n","> **Pregunta:**\n"," ¿Por qué **`classification_report`** no reporta el promedio **`micro`**?"]},{"cell_type":"markdown","metadata":{"id":"ds1Rp5w5e4vP"},"source":["#**6. Evaluación del desempeño - Regresión**\n","---\n","\n","En esta sección veremos la evaluación del desempeño para modelos de regresión, usando el conjunto de datos *Boston*. Como es usual, primero realizamos una partición de entrenamiento y prueba tomando el $30\\%$ para prueba.\n","\n","> **Nota**: Tenga en cuenta que no realizamos estratificación debido a que se trata de un problema de regresión.\n","\n","Importaremos y particionaremos los datos del conjunto de datos de *Boston*:\n"]},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","\n","boston = fetch_openml(name='boston', as_frame=True)"],"metadata":{"id":"gNs9awgk0UYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFfwGlNr097Y"},"source":["X, y = boston.data, boston.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    random_state=12, test_size=0.3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6aziBHR1xKH"},"source":["### **6.1. KNN como regresor**\n","---\n","\n","El algoritmo *KNN* también es aplicable en problemas de regresión. La clase **`KNeighborsRegressor`** de *Scikit-learn* aplica una interpolación local de la etiqueta de los $n$ vecinos más cercanos para realizar la predicción.\n","\n","Por defecto, **`KNeighborsRegressor`** toma el promedio de la etiqueta de los vecinos. Sin embargo, también se puede tomar un promedio ponderado por el inverso de la distancia especificando el parámetro **`weights = 'distance'`**.\n","\n","Entrenaremos un modelo *KNN* con $5$ vecinos para regresión:"]},{"cell_type":"code","metadata":{"id":"oO3ZT6DP14M3"},"source":["from sklearn.neighbors import KNeighborsRegressor\n","\n","model = KNeighborsRegressor(n_neighbors=5,\n","                            weights='distance')\n","\n","model.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RGDbf9f24YTg"},"source":["Si usamos el método **`score`** del modelo nos retornará la métrica conocida como el **coeficiente de determinación**, y no la exactitud del modelo. En un problema de regresión no tiene sentido hablar de exactitud u otras métricas cómo la precisión o el *recall*."]},{"cell_type":"code","metadata":{"id":"gXJY_SWg4Wn_"},"source":["model.score(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2_TBQSjU4q6V"},"source":["Antes de explorar el concepto del coeficiente de determinación primero introduciremos las métricas de **error cuadrático medio (MSE)** y de la **raíz del error cuadrático medio (RMSE)**."]},{"cell_type":"markdown","metadata":{"id":"uTzbdYWnfFvQ"},"source":["### **6.2. Error cuadrático medio (_MSE, Mean-Squared-Error_)**\n","---\n","\n","El error cuadrático medio se define como:\n","\n","$$\\text{MSE} = \\frac{1}{n}\\sum_{i=0}^{n}(\\hat{y}_i - y_i)^2$$\n","\n","Donde:\n","\n","* $y\\,- \\text{Etiqueta Real}$\n","* $\\hat{y}\\,- \\text{Predicción}$\n","\n","El _MSE_ toma la diferencia entre la etiqueta y la predicción (error) por cada ejemplo, las eleva al cuadrado y las suma y las divide sobre el total de ejemplos. En otras palabras, el _MSE_ es la media del error al cuadrado $(\\hat{y}_i - y_i)^2$. Note que por definición el _MSE_ solo toma valores mayores o iguales a $0$.\n","\n","Tomar el cuadrado de los errores permite evaluar diferencias positivas tanto negativas de la misma manera. Tenga en cuenta que esto también implica que el orden de $\\hat{y}_i$ y $y_i$ no es relevante para el cálculo del error.\n","\n","Tomar el cuadrado también penaliza los errores más grandes. Un _MSE_ pequeño índica que, en promedio, los errores para todos los ejemplos son pequeños. Otra manera de interpretar el _MSE_ es como la varianza de los errores (que tan dispersos son). El _MSE_ tiene muchas interpretaciones estadísticas importantes, como la descomposición en varianza y sesgo, las cuales no están dentro del alcance de este curso.\n","\n","\n","En *Scikit-learn*, el _MSE_ puede ser calculado con el método **`mean_squared_error`** de la siguiente manera:"]},{"cell_type":"code","metadata":{"id":"i_q_pmCEfKyk"},"source":["from sklearn.metrics import mean_squared_error\n","\n","y_pred = model.predict(X_test)\n","\n","mean_squared_error(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0Ig_9rufLY0"},"source":["### **6.3. Raíz del error cuadrático medio (_RMSE, Root-Mean-Squared-Error_)**\n","---\n","\n","La raíz del error cuadrático medio se define como:\n","\n","$$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=0}^{n}(\\hat{y}_i - y_i)^2}$$\n","\n","Donde:\n","\n","* $y\\,- \\text{Etiqueta Real}$\n","* $\\hat{y}\\,- \\text{Predicción}$\n","\n","Aunque sea simplemente la raíz del _MSE_, el _RMSE_ tiene la ventaja de ser interpretable en las unidades originales del problema.\n","\n","EL _RMSE_ puede ser calculado de la siguiente manera:"]},{"cell_type":"code","metadata":{"id":"qXFXPFXcfMrY"},"source":["np.sqrt(mean_squared_error(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJjNgbYCe_mT"},"source":["### **6.4. Coeficiente de Determinación ($\\text{R}^2$)**\n","---\n","\n","El coeficiente de determinación (o $R$ cuadrado) se define como:\n","\n","$$\\text{R}^2 = 1 - \\frac{\\frac{1}{n}\\sum_{i=0}^{n}(\\hat{y}_i - y_i)^2}{\\frac{1}{n}\\sum_{i=0}^{n}(y_i - \\bar{y})^2}$$\n","\n","Donde:\n","\n","* $y\\,- \\text{Etiqueta Real}$\n","\n","* $\\hat{y}\\,- \\text{Predicción}$\n","\n","* $\\bar{y}\\,- \\text{Media de y:}\\, \\frac{1}{n}\\sum_{i=0}^{n}y_i^2$\n","\n","Podemos notar que el numerador de la división corresponde al error cuadrático medio (varianza de los errores) y que el denominador de la división corresponde a la varianza de las etiquetas.\n","\n","La varianza de las etiquetas está escrita de una manera muy similar al _MSE_, de hecho, si definiéramos un modelo que para un conjunto de ejemplos prediga para cada uno de los ejemplos la media de sus etiquetas (llamémoslo modelo de la media) y calculáramos su _MSE_ sería exactamente esta varianza.\n","\n","El modelo de la media es lo que se considera como un *baseline*. Los *baseline* o modelos de línea base son modelos sencillos usados para comparar su desempeño contra modelos más complejos.\n","\n","Dicho lo anterior, si definimos el _MSE_ del modelo de la media como $\\text{MMSE}$ (Mean Model Squared Error) entonces $\\text{R}^2$  puede ser escrito de la siguiente manera:\n","\n","$$\\text{R}^2 = 1 - \\frac{\\text{MSE}}{\\text{MMSE}} = \\frac{\\text{MMSE} - \\text{MSE}}{\\text{MMSE}}$$\n","\n","De esta manera, podemos interpretar el coeficiente de determinación como una proporción de mejora en la predicción de un modelo comparado con el modelo de la media de las etiquetas. El mejor valor de $\\text{R}^2$  es $1$ y también puede tomar valores negativos (para modelos mucho peores). También cabe notar que el coeficiente de determinación es dependiente del conjunto de datos, y por lo tanto no es comparable entre distintos conjuntos de datos.\n","\n","Se dice que el coeficiente representa la proporción de la varianza (de _y_) que ha sido explicada por las variables independientes en el modelo. Indica que tan bien serán predichos ejemplos nunca antes vistos por el modelo, a través de la proporción de esa varianza explicada.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tMn-vnk4RjLI"},"source":["Como ya se mostró, el coeficiente de determinación puede ser calculado a través de la función **`score`** de los modelos de regresión. Sin embargo, también se puede calcular a través del método **`r2_score`** de **`sklearn.metrics`**:"]},{"cell_type":"code","metadata":{"id":"caxGdeKXRilb"},"source":["from sklearn.metrics import r2_score\n","\n","y_pred = model.predict(X_test)\n","\n","print(f'Coeficiente de Determinación usando score:, {model.score(X_test, y_test):.4f}')\n","print(f'Coeficiente de Determinación con r2_score:, {r2_score(y_test, y_pred):.4f}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lnGxv5COU8p2"},"source":["De esta manera podemos determinar que el modelo representa una mejora sobre el modelo de las medias. Sin embargo, aún puede mejorarse el desempeño."]},{"cell_type":"markdown","metadata":{"id":"4r5hSQAz6d-g"},"source":["# **Recursos adicionales**\n","---\n","Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *Scikit-learn* para la evaluación del desempeño de sus modelos, además de material de apoyo teórico para reforzar estos conceptos:\n","\n","- [scikit-learn - Model Evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)\n","- [mlcourse.ai - Decision Trees and KNN](https://mlcourse.ai/articles/topic3-dt-knn/#3.-Nearest-Neiighbors-Method)\n","- [Metrics to understand regression model in plain english](https://towardsdatascience.com/metrics-to-understand-regression-models-in-plain-english-part-1-c902b2f4156f)\n","- [Difference Between Classification and Regression in Machine Learning](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O6dwABE_Zg44"},"source":["# **Créditos**\n","---\n","\n","* **Profesor:** [Fabio Augusto González](https://dis.unal.edu.co/~fgonza/)\n","* **Asistentes docentes:**\n","  * Miguel Angel Ortiz Marín\n","  * Alberto Nicolai Romero Martínez\n","\n","**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"]}]}