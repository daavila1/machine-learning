{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mtUYsR99K1Iv"},"source":["<img src = \"https://drive.google.com/uc?export=view&id=1Jv3o3mNsR42VNsXVJEwasefophZ-TeD9\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"]},{"cell_type":"markdown","metadata":{"id":"Iv9BZCSIArVG"},"source":["#**Introducción al aprendizaje computacional y _scikit-learn_**\n","----\n","\n","<img src = \"https://raw.githubusercontent.com/scikit-learn/scikit-learn/main/doc/logos/scikit-learn-logo.png\" alt = \"sklearn logo\" width = \"40%\">  </img>\n","\n","En este taller guiado haremos un acercamiento básico a varios de los pasos más importantes del aprendizaje computacional usando la librería especializada *Scikit-learn*.\n","\n","Veremos cómo:\n","\n","- cargar conjuntos de datos.\n","- preprocesar datos numéricos y categóricos.\n","- crear particiones de datos entrenamiento - prueba.\n","- entrenar modelos (regresión logística) para clasificación.\n","- evaluar el desempeño de modelos para clasificación.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fDxFO2QCA0uv"},"source":["## **1. Importar scikit-learn** <a class=\"anchor\" id=\"section2\"></a>\n","---\n","\n","\n","*Scikit-learn* es una librería especializada de aprendizaje computacional para el lenguaje de programación *Python*. Cuenta con múltiples paquetes y submódulos que serán importados en sus respectivas secciones.\n","\n","El paquete de *Python* de *Scikit-learn* de **`pip`** se debe instalar/actualizar con el nombre **`scikit-learn`**:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"0hL9owT5gcN3"},"source":["# Usamos el gestor de paquetes pip para instalar 'scikit-learn'\n","!pip install -U scikit-learn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6NcdQJ4g3TR"},"source":["> **Nota:** El nombre del módulo de *Python* NO es **`scikit-learn`**. Para importarlo se debe usar el nombre **`sklearn`**."]},{"cell_type":"code","metadata":{"id":"R27XuqUrUM3y"},"source":["# No se debe confundir el nombre al importar la librería.\n","import sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"53QKEDM1PPVT"},"source":["La manera en que importe los paquetes y funciones es una elección personal. Por ejemplo, puede decidir importar todas las definiciones de un paquete:"]},{"cell_type":"code","metadata":{"id":"yx0pC0bbPXc_"},"source":["# Importa todas las definiciones dentro del submódulo \"sklearn.datasets\"\n","from sklearn.datasets import *\n","\n","iris = load_iris()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4AiraQIPoSM"},"source":["Importar solo las necesarias:"]},{"cell_type":"code","metadata":{"id":"O2kCoLsDPNZD"},"source":["# Importa la definición \"load_iris\" del submódulo \"sklearn.datasets\"\n","from sklearn.datasets import load_iris\n","\n","iris = load_iris"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xuDPuHZYR_0U"},"source":["O importar un paquete y usar sus definiciones:"]},{"cell_type":"code","metadata":{"id":"t-AB5xzfSDwt"},"source":["# Importa el submódulo \"sklearn.datasets\"\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2538w03h8Yvo"},"source":["Además de *Scikit-learn*, utilizaremos algunas librerías de utilidad básicas del ecosistema de computación científica de *Python*."]},{"cell_type":"code","metadata":{"id":"46ALWOzT8l1z"},"source":["# Librerías NumPy, Pandas y Matplotlib para el análisis y manipulación de datos.\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib as mpl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUMP_2CPqwRY"},"source":["# Versiones de Python, NumPy y Pandas.\n","\n","!python --version\n","print('NumPy', np.__version__)\n","print('Pandas', pd.__version__)\n","print('Matplotlib', mpl.__version__)\n","print('Scikit-learn', sklearn.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxNzX3sfq3gZ"},"source":["Este material se realizó con las siguientes versiones:\n","*  *Python*: 3.7.10\n","*  *NumPy*:  1.19.5\n","*  *Pandas*:  1.1.5\n","*  *Matplotlib*:  3.2.2\n","*  *Scikit-learn*: 0.24.1"]},{"cell_type":"markdown","metadata":{"id":"WIcJgtQTA08L"},"source":["## **2. Cargar datos** <a class=\"anchor\" id=\"section3\"></a>\n","___\n","\n","Los modelos de *Scikit-learn* aceptan datos numéricos almacenados en arreglos de *Numpy* o en matrices dispersas de *Scipy*. Otros tipos de datos convertibles a arreglos de *Numpy* también son aceptados, como listas y *DataFrames* de *Pandas*.\n","\n","*Scikit-learn* ofrece funciones de utilidad para cargar una pequeña colección de populares conjuntos de datos, además de ofrecer funciones de utilidad para generar conjuntos de datos sintéticos.\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xnbH2JnBHJyF"},"source":["### **2.1. Conjuntos de datos**\n","---\n","\n","*Scikit-learn* ofrece funciones de utilidad en el paquete **`datasets`** para cargar conjuntos de datos populares, los cuales suelen ser usados para evaluar el desempeño de algoritmos de aprendizaje computacional. Estos conjuntos de datos suelen ser llamados \"conjuntos de juguete\" o *benchmark*."]},{"cell_type":"markdown","metadata":{"id":"KXwTbYXQddGA"},"source":["#### **2.1.1. Loaders**\n","---\n","En el caso de conjuntos de datos pequeños, *scikit-learn* cuenta con una familia de funciones llamada *loaders*. Estos conjuntos de datos vienen incluidos con la instalación de *scikit-learn* y no implican un uso de red adicional para descargarlos.\n","\n","Por ejemplo, veamos uno de los conjuntos de datos más populares: el conjunto de datos de la familia de flores *Iris*. Usaremos la función **`sklearn.datasets.load_iris`**:"]},{"cell_type":"code","metadata":{"id":"a6mnJADVIp-m"},"source":["# sklearn.datasets es el submódulo destinado a la carga de conjuntos de datos.\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()\n","\n","print(type(iris))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s8NPYIrwgOb7"},"source":["Como podemos ver, el conjunto de datos cargado pertenece a la clase **`sklearn.utils.Bunch`**. Los objetos *Bunch* son diccionarios que exponen sus llaves, como los subconjuntos del *dataset* y demás información descriptiva, en forma de atributos.\n","\n","Veamos las llaves de **`iris`**:\n"]},{"cell_type":"code","metadata":{"id":"EeMoOyvHjZVL"},"source":["print(iris.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ts8vVlK4iclX"},"source":["En este caso nos interesan las llaves **`data`**, **`target`**, **`target_names`** y **`feature_names`**.\n"]},{"cell_type":"markdown","metadata":{"id":"B8xShwYmjk7F"},"source":["Las llaves pueden ser accedidas a través de llaves cuadradas (**`[]`**) o como un atributo a través de la notación con punto (**`.`**)."]},{"cell_type":"code","metadata":{"id":"GNqOwkcIgUN6"},"source":["# Las dos líneas de código retornan lo mismo.\n","print(iris.feature_names)\n","print(iris['feature_names'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pTaJG8e5lF3O"},"source":["*Iris* es un conjunto de datos para la clasificación de flores de la familia *Iris* en 3 especies distintas (setosa, versicolor y virginica)."]},{"cell_type":"code","metadata":{"id":"Fd3O6IRslEZC"},"source":["# target_names: Nombre de las etiquetas de la variable objetivo.\n","print(iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-9YI3srlgBg"},"source":["Basado en la longitud y anchura de sus pétalos y sépalos en centímetros."]},{"cell_type":"code","metadata":{"id":"j1GxRkfxivZD"},"source":["# feature_names: Nombre de las variables o características.\n","print(iris.feature_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BuEoVRsEmF6k"},"source":["En general, las *feature* o características hacen referencia a las variables que usaremos para entrenar nuestros modelos de aprendizaje computacional y predecir el *target* u objetivo, también llamado etiqueta.\n","\n","En aprendizaje computacional a un punto, instancia o muestra de un conjunto de datos se le da el nombre de **ejemplo**. Cuando un ejemplo tiene asociado una etiqueta se habla de **datos etiquetados** y cuando no, de **datos no etiquetados**.\n","\n","En **aprendizaje supervisado** usamos datos etiquetados y algoritmos para entrenar modelos los cuales serán usados para predecir la etiqueta de ejemplos de los cuáles no se conoce la etiqueta.\n","\n","Acabamos de ver los nombres de las características y los nombres de las posibles etiquetas del conjunto de datos *Iris*. Para acceder a los datos correspondientes a estos nombres y etiquetas debemos acceder a ellos a través de las llaves **`data`** y **`target`**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rYPu_AMtqq5f"},"source":["La llave **`data`** es una matriz que contiene por cada ejemplo una fila con las 4 características mencionadas."]},{"cell_type":"code","metadata":{"id":"Ymja_026o6Pv"},"source":["print(iris.data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A2GylU33pRWY"},"source":["La llave **`target`** es un vector que contiene la etiqueta para cada ejemplo."]},{"cell_type":"code","metadata":{"id":"8sqTmjpRpf62"},"source":["print(iris.target.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VCS3T0LcxGfg"},"source":["Como acabamos de ver, el conjunto de datos Iris cuenta con $150$ ejemplos y $4$ características.\n","\n","Por ejemplo, si quisiéramos saber las características de unos ejemplos y su etiqueta podemos hacer lo siguiente:"]},{"cell_type":"code","metadata":{"id":"V-lPcDgRoTm7"},"source":["# Lista de ids de los ejemplos que vamos a consultar\n","ids = [0, 25, 50, 100]\n","\n","for i in ids:\n","  print(f'Ejemplo: {i}')\n","  print(f'Características: {iris.data[i]}, etiqueta: {iris.target[i]}\\n')\n","\n","print('Nombres de las características:', iris.feature_names)\n","print('Nombres de las etiquetas:', iris.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnRMWloXpbqB"},"source":["Las características están en el mismo orden que **`feature_names`**. Es decir, el ejemplo $100$ tiene:\n","* $6.3$ cm de longitud de sépalo (**`sepal length (cm)`**).\n","* $3.3$ cm de ancho de sépalo (**`sepal width (cm)`**).\n","* $6.0$ cm de longitud de pétalo (**`petal length (cm)`**).\n","* $2.5$ cm de ancho de pétalo (**`petal width (cm)`**).\n","\n","También podemos observar que las etiquetas están representadas con números.\n","De manera similar, están en el mismo orden que **`target_names`**. Es decir:\n","* El ejemplo $0$ tiene etiqueta **`setosa`**.\n","* El ejemplo $50$ tiene etiqueta **`veriscolor`**.\n","* El ejemplo $100$ tiene etiqueta **`virginica`**."]},{"cell_type":"markdown","metadata":{"id":"ETUcXt7iglMh"},"source":["***\n","En *Scikit-learn* es estándar manejar los datos en el formato **`X, y`**, donde **`X`** es una matriz donde las filas representan ejemplos y las columnas características y **`y`** es un vector que representa la etiqueta u variable objetivo. Podemos notar que **`X`** corresponde a la llave **`data`** y **`y`** a **`target`** en nuestro ejemplo anterior.\n","\n","Usualmente, se tratará de convertir los datos que se tengan a este formato, con el objetivo de tenerlos listos para ser preprocesados y procesados por un algoritmo de aprendizaje computacional.\n","\n","Por ejemplo, para obtener *Iris* en el formato **`X, y`** podríamos hacer lo siguiente:"]},{"cell_type":"code","metadata":{"id":"blq-HoJSfb-U"},"source":["# Desempaquetado de tuplas a partir de los atributos.\n","X, y = iris.data, iris.target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hznhM0y36-q"},"source":["Sin embargo, también es posible (y recomendado) cargar directamente el conjunto de datos en este formato con el argumento booleano **`return_X_y`**:"]},{"cell_type":"code","metadata":{"id":"qnA1FuFD4Ej5"},"source":["# El argumento 'return_X_y' permite obtener directamente ambos arreglos.\n","X, y = datasets.load_iris(return_X_y=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mj3AyamydJuO"},"source":["#### **2.1.2. Fetchers**\n","---\n","En el caso de conjuntos de datos más grandes, *scikit-learn* ofrece la familia de funciones  *fetchers*. Estos conjuntos de datos no están incluidos en la instalación de *scikit-learn* y deben ser descargados con recursos de red.\n","\n","Al ejecutar la siguiente celda notará que se hará un llamado para descargar el conjunto de datos *california housing* (regresión)."]},{"cell_type":"code","metadata":{"id":"JjkQxV3eR0t1"},"source":["# Los Fetcher también hacen parte del submódulo sklearn.datasets.\n","from sklearn import datasets\n","\n","# Este tipo de funciones empieza con el prefijo '.fetch_'\n","california_housing = datasets.fetch_california_housing()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mDIGRRD7oMnP"},"source":["Al igual que muchos otros *fetchers* y *loaders*, el *dataset california_housing* es un objeto **`Bunch`** y puede ser cargado directamente en el formato **`X, y`** directamente."]},{"cell_type":"code","metadata":{"id":"4hssoYJanRiE"},"source":["print(type(california_housing))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izO5K4GRog3w"},"source":["# Lo cargamos en formato X, y con el argumento 'return_X_y'.\n","X, y = datasets.fetch_california_housing(return_X_y=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kyo1P0kGN-an"},"source":["### **2.2. Conjuntos de datos sintéticos**\n","---\n","\n","*Scikit-learn* permite generar una serie de conjuntos de datos sintéticos, los cuales pueden ser útiles para probar el desempeño de un algoritmo de aprendizaje computacional. Estos métodos, a diferencia de los *loaders* y *fetchers* no retornan un objeto **`Bunch`** sino un conjunto de datos en el formato **`X, y`**.\n","\n","Veamos algunos ejemplos. Graficaremos los resultados con *matplotlib*:"]},{"cell_type":"code","metadata":{"id":"f0pZysWPDyMK"},"source":["# Importamos y configuramos la librería de visualización Matplotlib.\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","mpl.rcParams['figure.dpi'] = 110"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"th2NfEkTR3Q9"},"source":["# Conjunto de datos Blobs\n","X, y = datasets.make_blobs()\n","\n","plt.scatter(X[:,0], X[:,1], c=y);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tyOwISZR4vM"},"source":["# Conjunto de datos Moons\n","X, y = datasets.make_moons(n_samples=100)\n","\n","plt.scatter(X[:,0], X[:,1], c=y);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MN6NveX8n3WG"},"source":["# Conjunto de datos para clasificación.\n","X, y = datasets.make_classification()\n","\n","plt.scatter(X[:,0], X[:,1], c=y);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNY2RHkfVjbq"},"source":["Los conjuntos de datos generados de esta manera son generados de manera aleatoria, es decir, en cada ocasión será generado un conjunto de datos potencialmente distinto.\n","\n","Para generar el mismo conjunto de datos puede fijar la semilla con el argumento **`random_state`**:"]},{"cell_type":"code","metadata":{"id":"UHbiQeV2Xwmo"},"source":["# No importa cuantas veces lo ejecute, el resultado siempre será el mismo.\n","X, y = datasets.make_blobs(random_state=42)\n","\n","plt.scatter(X[:,0], X[:,1], c=y);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JG_IO2lVG1FK"},"source":["### **2.3. Conjuntos de datos de archivos externos**\n","___\n","\n","*Scikit-learn* permite usar *DataFrames* de *Pandas* como entrada para sus algoritmos de preprocesamiento y aprendizaje computacional.\n","\n","De aquí en adelante trabajaremos con el conjunto de datos *Titanic* para realizar preprocesamiento, entrenamiento y evaluación del desempeño.\n","\n","A continuación cargamos *Titanic* como un *DataFrame* de *Pandas* usando la función **`pd.read_csv`**. Esta permite leer archivos separados por comas y cargarlos en objetos de tipo **`DataFrame`**."]},{"cell_type":"code","metadata":{"id":"iFbe515tMkeu"},"source":["# Librería de análisis y manipulación de datos Pandas.\n","import pandas as pd\n","\n","# Usamos una url remota para cargar nuestro conjunto.\n","titanic_url = 'https://raw.githubusercontent.com/JuezUN/datasets/master/titanic.csv'\n","titanic_df = pd.read_csv(titanic_url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b14atuyNv-hN"},"source":["Podemos ver información general del conjunto de datos con el método **`info`** de *Pandas*:"]},{"cell_type":"code","metadata":{"id":"P00fRlQ1v9z0"},"source":["titanic_df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UfTeNIkYKmZ"},"source":["El dataset Titanic presenta un problema de clasificación. Se busca predecir la supervivencia de una persona basada en características como la clase del pasajero (**`Pclass`**), su género (**`Sex`**), su edad (**`Age`**), el número de hermanos y pareja a bordo, (**`SibSp`**), el número de padres e hijos a bordo (**`Parch`**), entre otras.\n","\n","Para mantener las cosas sencillas eliminaremos la variable **`Cabin`** ya que presenta muchos datos faltantes y luego eliminaremos los registros que contentan valores faltantes en algunas de las columnas restantes. También eliminaremos la variable **`PassengerId`** ya que es un identificador y no una variable propia de los ejemplos."]},{"cell_type":"code","metadata":{"id":"VumQnw8nlygj"},"source":["df_full = titanic_df.drop(['Cabin', 'PassengerId'], axis=1) # Eliminamos las columnas Cabin y PassengerId.\n","df_nona = df_full.dropna(axis=0) # Eliminamos los ejemplos con valores faltantes.\n","\n","print(df_nona.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tygFls6jej1x"},"source":["Para convertir el *DataFrame* de Titanic en el formato **`X, y`** podemos hacer lo siguiente:"]},{"cell_type":"code","metadata":{"id":"165lAchkebBU"},"source":["X = df_nona.drop(['Survived'], axis=1) # El conjunto de datos sin la variable objetivo 'Survived'.\n","y = df_nona['Survived']  # La columna de la variable objetivo 'Survived'.\n","\n","print(X.shape)\n","print(y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f02hDDy39Ga8"},"source":["Podemos ver que el conjunto de datos resultante tiene $712$ ejemplos con $9$ características.  \n","\n","No incluimos **`Survived`** en **`X`** porque es la etiqueta que buscamos predecir. Incluirla sería un error conocido como **filtración de etiquetas**, que ocurre cuando se incluyen características durante el entrenamiento que proporcionan información de la etiqueta (o la misma etiqueta), que podría no estar disponible durante el tiempo de predicción. Imagínese entrenar un modelo para predecir la etiqueta, pero necesitarla como dato de entrada."]},{"cell_type":"markdown","metadata":{"id":"frzcfEbP9VmX"},"source":["Aunque *Scikit-learn* acepta objetos convertibles a arreglos de *NumPy* como *DataFrames* y listas. Nos adelantaremos y convertiremos **`X`** y **`y`** en arreglos de NumPy.\n","\n"]},{"cell_type":"code","metadata":{"id":"oXNywslzyBWn"},"source":["print(type(X))\n","print(type(y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cC6E-KB-xAH-"},"source":["Primero veamos como convertir un objeto de *Pandas* a un arreglo de *NumPy*, esto se logra con el atributo **`values`** de un *DataFrame* o una *Serie*."]},{"cell_type":"code","metadata":{"id":"Sm2cI7sBw23-"},"source":["# .values retorna un arreglo de NumPy.\n","y = y.values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O3e0ZEGQw95I"},"source":["Separaremos **`X`** en dos arreglos de *NumPy*. Guardaremos las variables numéricas en **`X_numeric`** y las variables categóricas en **`X_categoric`**."]},{"cell_type":"markdown","metadata":{"id":"nB6AljSABDlT"},"source":["Las variables numéricas del conjunto de datos son: **`Age`**, **`SibSp`**, **`Parch`**, y **`Fare`**."]},{"cell_type":"code","metadata":{"id":"fY7f4k268ZWb"},"source":["numeric = ['Age', 'SibSp', 'Parch', 'Fare']\n","\n","# .values retorna un arreglo de NumPy.\n","X_numeric = X[numeric].values\n","\n","print(X_numeric.shape)\n","print(type(X_numeric))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YoiIC1gRytZo"},"source":["Veamos algunos ejemplos:"]},{"cell_type":"code","metadata":{"id":"XbC9ufSEyswQ"},"source":["for i in range(5):\n","  print(f'Ejemplo {i}:')\n","  print('Variables:', X_numeric[i])\n","  print('Etiqueta:', y[i])\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CK7iLrFP0qLL"},"source":["Cómo podemos ver, son todas variables numéricas."]},{"cell_type":"markdown","metadata":{"id":"yvJZGKN3-Olq"},"source":["\n","Las variables categóricas del conjunto de datos son: **`Pclass`**, **`Name`**, **`Sex`**, **`Ticket`** y **`Embarked`**.\n","\n","> Si bien **`Pclass`** está almacenada como un tipo numérico, representa una variable categórica ordinal.\n","\n","Primero veamos cuántos valores únicos tiene cada una:"]},{"cell_type":"code","metadata":{"id":"TH3HGht-9Csb"},"source":["categoric = ['Name', 'Ticket', 'Pclass', 'Sex', 'Embarked']\n","\n","for var in categoric:\n","  print(f'Valores posibles de {var}: \\t{X[var].nunique()}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8iNDLX6AIMA"},"source":["No tendremos en cuenta **`Name`** y **`Ticket`** para el siguiente ejemplo por su gran cantidad de valores posibles. En este caso usaremos solamente las variables **`Pclass`**, **`Sex`** y **`Embarked`**."]},{"cell_type":"code","metadata":{"id":"Acng6VSSAAxg"},"source":["# .values retorna un arreglo de numpy\n","X_categoric = X[['Pclass', 'Sex', 'Embarked']].values\n","\n","print(X_categoric.shape)\n","print(type(X_categoric))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3aDlO1H2zUDD"},"source":["Veamos algunos ejemplos:"]},{"cell_type":"code","metadata":{"id":"7cQ9NpJFzVJQ"},"source":["ids = [0, 1, 15, 20]\n","\n","for i in ids:\n","  print(f'Ejemplo {i}:')\n","  print('Variables:', X_categoric[i])\n","  print('Etiqueta:', y[i])\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKH7UbpizcVa"},"source":["* Los valores $1$, $2$ y $3$ corresponden a la clase de viaje del pasajero de la variable **`Pclass`**.\n","* Los valores **`male`** y **`female`** corresponden a la variable **`Sex`** (género de la persona).\n","* Los valores **`S`**, **`C`** y **`Q`** corresponden a la variable **`Embarked`**. Estos indican el puerto de embarque que utilizó la persona, donde **`C = Cherbourg`**, **`Q = Queenstown`** y **`S = Southampton`**.\n"]},{"cell_type":"markdown","metadata":{"id":"wrIMJNG3A1DT"},"source":["## **3. Preprocesamiento**\n","---\n","*Scikit-learn* expone el paquete **`preprocessing`** el cual contiene una serie de transformaciones para variables numéricas tanto como categóricas.\n","\n","La importancia del preprocesamiento radica en que puede potencialmente mejorar (o empeorar) el desempeño de los algoritmos de aprendizaje computacional. En el caso de variables categóricas para el caso de *Scikit-learn* no pueden ser usadas sin aplicar un preprocesamiento.\n","\n","Las transformaciones de *Scikit-learn* son fáciles de usar. Estas implementan la interfaz **`Transformer`**, la cual expone los 3 siguientes métodos:\n","\n","- **`fit(X)`**: *(del español ajustar)* permite aprender un conjunto de parámetros de **`X`** que son necesarios para aplicar la transformación (e.g la media, el mínimo o el máximo, el número de características, etc).\n","\n","- **`transform(X)`**: *(del español transformar)* aplica el preprocesamiento a **`X`** y retorna **`X`** transformado.\n","\n","- **`fit_transform(X)`**:*(del español ajustar y transformar)* aplica **`fit`** a **`X`** y retorna **`X`** transformado. Es utilizado como un atajo de una línea.\n","\n","Algunas transformaciones no pueden usar **`transform`** sin haber usado **`fit`** previamente. De igual manera algunas transformaciones no necesitan parámetros y **`fit`** no tiene ningún efecto secundario.\n","\n","\n","En esta ocasión nosotros solo utilizaremos **`fit_transform`** para realizar el preprocesamiento.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AxP2DPDUMe9N"},"source":["### **3.1. Variables numéricas**\n","---\n","En esta ocasión introduciremos métodos de preprocesamiento numéricos bastante sencillos:\n","\n","- **`StandardScaler`**\n","- **`MinMaxScaler`**\n"]},{"cell_type":"markdown","metadata":{"id":"zGJhQX6qw1QG"},"source":["#### **3.1.1. `StandardScaler`**\n","---\n","Veamos primero **`StandardScaler`**:\n","\n","Este permite aplicar la transformación:\n","\n","$$X^{\\prime} = \\frac{X - \\mu}{\\sigma}$$\n","\n","Donde:\n","- $\\mu\\,$: Media aritmética de los datos.\n","- $\\sigma\\,$: Desviación estándar de los datos.\n","\n","La transformación produce un nuevo conjunto de datos centrado en $0$ y con una desviación estándar de $1$."]},{"cell_type":"code","metadata":{"id":"Jj3XJn_UMefu"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()  # Declaramos el Transformer \"StandardScaler\"\n","X_numeric_standarized = scaler.fit_transform(X_numeric) # Transformamos la matriz \"X_numeric\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mTYf6omU05FY"},"source":["Aunque **`X_numeric`** tiene varias características numéricas, la transformación se aplica a cada una de las columnas de manera independiente."]},{"cell_type":"markdown","metadata":{"id":"a--cLHL303jL"},"source":["Veamos algunos ejemplos:"]},{"cell_type":"code","metadata":{"id":"Zg-vQsam05T3"},"source":["for i in range(3):\n","  print('Ejemplo:', i)\n","  print('Original: ', X_numeric[i])\n","  print('Estandarizado: ', X_numeric_standarized[i])\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PXDKbDjj1sjt"},"source":["#### **3.1.2. `MinMaxScaler`**\n","---\n","**`MinMaxScaler`** permite escalar los datos a un rango específico, es decir, si una característica se encuentra en el rango **`[min(X), max(X)]`** y el argumento **`feature_range = (0, 1)`**, entonces cada valor será escalado de tal manera que esté en el rango **`[0, 1]`**."]},{"cell_type":"code","metadata":{"id":"DYK36v8wfSzt"},"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler(feature_range=(0, 1))  # Declaramos el Transformer \"MinMaxScaler\"\n","X_numeric_minmax = scaler.fit_transform(X_numeric) # Transformamos la matriz \"X_numeric\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8uOr_aF-K6B"},"source":["Al igual que **`StandardScaler`**, **`MinMaxScaler`** aplica su transformación a cada columna de manera independiente."]},{"cell_type":"markdown","metadata":{"id":"yBSWVy0b1qBG"},"source":["Veamos algunos ejemplos:\n"]},{"cell_type":"code","metadata":{"id":"V61z3nkg1rhw"},"source":["for i in range(3):\n","  print('Ejemplo:', i)\n","  print('Original: ', X_numeric[i])\n","  print('MinMax: ', X_numeric_minmax[i])\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SlKydMiUZgI"},"source":["# Valores mínimo y máximo de todo el dataset.\n","X_numeric_minmax.min(), X_numeric_minmax.max()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bhk4NLC81y24"},"source":["Como vemos, todos los valores están entre $0$ y $1$."]},{"cell_type":"markdown","metadata":{"id":"8Wj5I7IFFLT7"},"source":["**`StandardScaler`** y **`MinMaxScaler`** realizan transformaciones similares y el desempeño de cada una es dependediente del conjunto de datos.\n","\n","En nuestro ejemplo usaremos **`X_numeric_minmax`** para entrenar nuestros modelos."]},{"cell_type":"markdown","metadata":{"id":"tVW5bcvhM0aL"},"source":["### **3.2. Variables categóricas**\n","---\n","\n","Típicamente, los modelos de aprendizaje computacional no aceptan como entrada variables categóricas las cuales pueden estar representadas con cadenas de texto. Antes de ser empleadas necesitan ser preprocesadas en valores numéricos.\n","\n","En esta ocasión veremos un método muy popular conocido como *One Hot Encoding*.\n","\n","Emplearemos *One Hot Encoding* sobre la variable **`Embarked`**.\n","\n","*One Hot Encoding* codifica una variable con $n$ valores posibles enumerados como $1, 2, ..., n$ en un vector de tamaño $n$; donde la $i$-ésima posición del vector está asociada con el $i$-ésimo valor posible.\n","\n","Asumiendo que un ejemplo tiene el $j$-ésimo valor posible de la variable original, se procesa de la siguiente manera:\n","\n","- Se asigna 1 en la posición $j$.\n","- Se asigna 0 al resto.\n","\n","La variable **`Embarked`** tiene los siguientes valores únicos: **`S, C, Q`**.\n","\n","Lo verificamos con el método **`unique`** de *NumPy*."]},{"cell_type":"code","metadata":{"id":"pwNb4GydMei3"},"source":["import numpy as np\n","\n","# Obtenemos los valores únicos de un arreglo de NumPy con el método \"unique\".\n","print(np.unique(X_categoric[:,2]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p9TKNBLxnEk9"},"source":["Por lo tanto, al aplicar *One Hot Encoding* a los siguientes datos:\n","\n","|Embarked|\n","|:--:|\n","|S|\n","|C|\n","|Q|\n","|C|\n","\n","Se transformarían de la siguiente manera:\n","\n","|S|C|Q|\n","|--|--|--|\n","|**1**|0|0|\n","|0|**1**|0|\n","|0|0|**1**|\n","|0|**1**|0|"]},{"cell_type":"markdown","metadata":{"id":"phpidGQy-GTy"},"source":["*One Hot Encoding* se puede de usar de manera muy sencilla en *Scikit-learn* con el método **`OneHotEncoder`**:"]},{"cell_type":"markdown","metadata":{"id":"q2RzPh8S-_yr"},"source":["Por defecto **`OneHotEncoder`** retorna matrices *sparse* de *SciPy*, una implementación que mejora el desempeño de las operaciones matriciales cuando se tienen muchas entradas de una matriz en $0$ (¡perfecto para One Hot Encoding!).\n","\n","Para mantener las cosas sencillas con **`sparse=False`** le podemos pedir a **`OneHotEncoder`** que retorne arreglos de *NumPy*."]},{"cell_type":"code","metadata":{"id":"UH784dXbnEGq"},"source":["from sklearn.preprocessing import OneHotEncoder\n","\n","enc = OneHotEncoder(sparse=False)     # Declaramos el Transformer \"OneHotEncoder\".\n","X_categoric_onehot = enc.fit_transform(X_categoric) # Usamos \"fit_transform\" para obtener la matriz transformada.\n","print(X_categoric_onehot.shape)\n","print(type(X_categoric_onehot))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pzSkpZT-A2gT"},"source":["Cómo podemos ver, la variable **`Sex`** con $2$ valores únicos, la variable **`Pclass`** con $3$ valores únicos y la variable **`Embarked`** con $3$ valores únicos fueron transformadas en $8$ variables distintas en total."]},{"cell_type":"markdown","metadata":{"id":"iHSSV0vk2CAE"},"source":["Veamos algunos ejemplos:"]},{"cell_type":"code","metadata":{"id":"p_LiDYel2DW0"},"source":["ids = [0, 1, 15, 20]\n","for i in ids:\n","  print('Ejemplo:', i)\n","  print('Original: ', X_categoric[i])\n","  print('One Hot: ', X_categoric_onehot[i])\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8TfhHjY3_pT7"},"source":["Antes de continuar al entrenamiento de modelos de aprendizaje computacional, usando *NumPy* juntaremos las variables numéricas preprocesadas y las variables categóricas preprocesadas en el arreglo **`X_full`**. Para esto usaremos la función **`np.concatenate`** para concatenar **`X_numeric_minmax`** y **`X_categoric_onehot`** a través del axis $1$ (columnas).\n","\n"]},{"cell_type":"code","metadata":{"id":"VksrD4pctO82"},"source":["import numpy as np\n","\n","X_full = np.concatenate((X_numeric_minmax, X_categoric_onehot),\n","                        axis=1) # Concatenamos por el eje vertical (columnas)\n","print(X_full.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"prh5CQVoA1JT"},"source":["## **4. Entrenamiento de modelos**\n","---\n","\n","En esta sección entrenaremos dos modelos de regresión logística.\n","- Uno utilizando solo las variables numéricas preprocesadas.\n","- Otro usando las variables numéricas y categóricas, ambas preprocesadas.\n","\n","Generalmente los algoritmos de aprendizaje computacional son entrenados en una partición de **entrenamiento** (***train***) y probados en una partición de datos de **prueba** (***test***).\n","\n","- Los datos de **entrenamiento** son aquellos datos de los cuales el algoritmo aprende.\n","- Los datos de **prueba** son aquellos que se usan para estimar el desempeño del algoritmo en datos desconocidos por el modelo.\n","\n","Las particiones **NO** deben compartir datos. Con ayuda de *scikit-learn* podemos crear particiones de entrenamiento y prueba para hacer esto fácilmente."]},{"cell_type":"markdown","metadata":{"id":"eSHaf5qJJiGk"},"source":["### **4.1. Partición de entrenamiento y prueba**\n","---\n","\n","*Scikit-learn* permite realizar una partición de entrenamiento y prueba fácilmente con la función **`train_test_split`** del paquete **`model_selection`**.\n","\n","**`train_test_split(X, y)`** retorna una tupla **`X_train, X_test, y_train, y_test`** donde **`X_train, X_test`** son la partición entrenamiento - prueba de **`X`** y **`y_train, y_test`** son la partición de entrenamiento y prueba de **`y`**.\n","\n","Tenga en cuenta que usted le puede poner cualquier nombre a las variables que retorna train_test_split, lo anterior es solo una convención.\n","\n","Usando el parámetro **`test_size`** podemos indicar, con un número entre 0 y 1, el porcentaje de datos que deseamos usar para la partición de prueba.\n","\n","Un ejemplo básico de uso, con $30\\%$ de los datos para pruebas y $70\\%$ para entrenamiento sería el siguiente:\n","\n","```python\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","```"]},{"cell_type":"markdown","metadata":{"id":"ND-iGBUYHVNK"},"source":["En nuestro caso le indicamos a **`train_test_split`** que utilice el $30\\%$ de los datos como datos de prueba y la utilizamos con **`X_numeric_minmax`** y **`X_full`**."]},{"cell_type":"markdown","metadata":{"id":"fODuadTq7Z1f"},"source":["A continuación importamos **`train_test_split`** del submódulo **`sklearn.model_selection`**."]},{"cell_type":"code","metadata":{"id":"tEdtXWv47Y7H"},"source":["# Submódulo de selección de modelos y partición de datos.\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-kLvycl7eks"},"source":["Lo usamos sobre **`X_numeric_minmax`**:"]},{"cell_type":"code","metadata":{"id":"WlG_tfh5JtHZ"},"source":["X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_numeric_minmax,\n","                                                                    y,\n","                                                                    test_size=0.3,\n","                                                                    random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"La9XSfAJ7erz"},"source":["Y lo usamos sobre **`X_full`**:"]},{"cell_type":"code","metadata":{"id":"kJo0NVHU4NTe"},"source":["X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full,\n","                                                                        y,\n","                                                                        test_size=0.3,\n","                                                                        random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x3gGb9K2H0C2"},"source":["**`train_test_split`** realiza la partición de manera aleatoria. Para especificar la semilla aleatoria se puede utilizar el parámetro **`random_state`**.\n","\n","En este caso como tenemos dos versiones de **`X`** (**`X_numeric_minmax`** y **`X_full`**) y hemos utilizado la misma semilla aleatoria en ambos llamados de la función para asegurarnos que los ejemplos, aún con diferentes características, sean consistentes sobre cada partición."]},{"cell_type":"markdown","metadata":{"id":"Wqb19OrvEvBM"},"source":["Podemos verificar que efectivamente se respetó el ordenamiento:"]},{"cell_type":"code","metadata":{"id":"boAabr_7gJGV"},"source":["print(all(y_train_num == y_train_full))\n","print(all(y_test_num == y_test_full))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ltFWAXKTKxqR"},"source":["Para simplificar las cosas asignamos las variables **`y_train`** y **`y_test`**:"]},{"cell_type":"code","metadata":{"id":"egXLCO4OK1DS"},"source":["y_train = y_train_num\n","y_test = y_test_num"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JksSCAhNJu1n"},"source":["### **4.2. Entrenamiento**\n","---\n","\n","Debido a que el conjunto de datos *Titanic* plantea un problema de clasificación (supervivencia), usaremos un modelo de clasificación lineal llamado regresión logística.\n","\n","Los modelos de clasificación buscan discernir el grupo al que pertenece un ejemplo (i.e., predecir su etiqueta).\n","\n","Un modelo de clasificación recibe un conjunto de variables **`x`** (características) y produce una salida **`y`** (etiqueta) la cual es la predicción del modelo.\n","\n","La salida de un modelo de clasificación suele estar codificada como un número. El numero está asociado a la clase (que el modelo predice) que pertenece el ejemplo.\n","\n","Utilizaremos el modelo generado por la función **`LogisticRegression`** del paquete **`linear_model`** de *Scikit-learn*.\n","\n","En *scikit-learn* los modelos suelen implementar la interfaz **`Estimator`** y **`Predictor`**.\n","\n","Por ahora nos interesa saber que:\n","\n","- Los **`Estimator`** implementan **`fit(X, y)`**.\n","- Los **`Predictor`** implementan **`predict(X)`**.\n","\n","Los modelos deben ser *ajustados* antes de ser utilizados para realizar cualquier predicción.\n","\n","En *scikit-learn* entrenar un modelo de aprendizaje computacional es tan sencillo como importarlo, crear una instancia y utilizar **`fit`**.\n","\n","> **Nota:** Para nuestro ejemplo, en el entrenamiento utilizaremos cada versión de **`X_train`** (**`X_train_num`** y **`X_train_full`**) con el objetivo de entrenar dos modelos distintos."]},{"cell_type":"markdown","metadata":{"id":"O5hhIAWD681M"},"source":["### **4.3. Clasificador de variables numéricas**\n","---\n","\n","Primero entrenaremos una regresión logística utilizando únicamente las variables numéricas.\n","\n","Importamos el paquete **`linear_model`** que incluye la clase **`LogisticRegression`**."]},{"cell_type":"code","metadata":{"id":"Sqhl96SrhV8y"},"source":["# Submódulo de modelos lineales.\n","from sklearn import linear_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ew9c-S9QhqP3"},"source":["Creamos una instancia de **`LogisticRegression`** y la guardamos en la variable **`clf_numeric`**."]},{"cell_type":"code","metadata":{"id":"dz9YYSHVhxqQ"},"source":["clf_numeric = linear_model.LogisticRegression(random_state=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"22ITWuP7h0Ke"},"source":["**`clf_numeric`** no ha sido entrenado, para esto usamos el método **`fit`** con:\n"," - **`X_train_num`**: matriz con las características numéricas de la partición de entrenamiento.\n"," - **`y_train`**: vector con las etiquetas de la partición de entrenamiento."]},{"cell_type":"code","metadata":{"id":"4sjWh5ryYkky"},"source":["clf_numeric.fit(X_train_num, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oO52cCxM7CWn"},"source":["### **4.4. Clasificador de variables numéricas y categóricas**\n","---\n","Para entrenar un segundo modelo con todas las variables numéricas y categóricas (preprocesadas) realizamos los siguientes pasos:\n","\n","Creamos una instancia y la guardamos en **`clf_full`**:"]},{"cell_type":"code","metadata":{"id":"viX4StDWtBAh"},"source":["# Variables numéricas y categóricas.\n","clf_full = linear_model.LogisticRegression(random_state=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6I0lk-qxi6nf"},"source":["Utilizamos **`fit`** pero esta vez con **`X_train_full`**, la matriz con las características tanto numéricas como categóricas de la partición de entrenamiento."]},{"cell_type":"code","metadata":{"id":"C-U-1aU1i0ZN"},"source":["clf_full.fit(X_train_full, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5WRdRjd6A14b"},"source":["## **5. Evaluación**\n","---\n","\n","Calcularemos la exactitud y el error de cada clasificador entrenado en la partición de entrenamiento y prueba.\n","\n","La exactitud se define como:\n","\n","$$\\text{exactitud} = \\frac{\\text{#ejemplos clasificados correctamente}}{\\text{#ejemplos}}$$\n","\n","y el error se define como:\n","\n","$$\\text{error} = 1.0\\, - \\text{exactitud}$$\n","\n","En *scikit-learn* la **exactitud** se puede calcular mediante la función **`accuracy_score`** del paquete **`metrics`**.\n","\n","> **Nota**: Se profundizará en distintas métricas de rendimiento en las unidades siguientes.\n","\n","A continuación, importamos **`accuracy_score`**."]},{"cell_type":"code","metadata":{"id":"h505h7UbhobH"},"source":["from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B16z3oyDh0Gc"},"source":["### **5.1. Clasificador variables numéricas**\n","---\n","\n","Primero veamos algunas predicciones del modelo sobre la partición de prueba, para esto debemos usar el método **`predict`**:"]},{"cell_type":"code","metadata":{"id":"SECWrSjD8vz6"},"source":["# El método predict se debería utilizar sobre un clasificador entrenado previamente.\n","\n","y_pred = clf_numeric.predict(X_test_num) # Retorna un arreglo con la predicción de la variable objetivo por cada ejemplo.\n","\n","\n","for i in range(5):\n","  print(f'Predicho: {y_pred[i]}, Etiqueta: {y_test[i]}\\n')\n",""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bkQA1NGg9W1D"},"source":["Como podemos ver, el modelo se equivoca en $2$ de los primeros $5$ ejemplos. Note que **`predict`** acepta una matriz, un error común es tratar de usar **`predict`** con vectores.\n","\n","Para calcular la exactitud sobre toda la partición de prueba utilizamos **`accuracy_score`**:"]},{"cell_type":"markdown","metadata":{"id":"rUYuSE1t8MAU"},"source":["> **`accuracy_score`** recibe como primer parámetro las etiquetas reales y como segundo parámetro las etiquetas predichas."]},{"cell_type":"code","metadata":{"id":"m7v5IIpBg7tO"},"source":["# Obtenemos la predicción del clasificador usando variables numéricas.\n","y_pred = clf_numeric.predict(X_test_num)\n","\n","# Calculamos la exactitud de la predicción.\n","acc = accuracy_score(y_test, y_pred)\n","\n","print(f'Exactitud en prueba {acc}')\n","print(f'Error en prueba: {1.0 - acc}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RiLAW2A__Ta1"},"source":["Veamos las métricas sobre la partición de entrenamiento:"]},{"cell_type":"code","metadata":{"id":"5qcbC_4H8d0L"},"source":["# Obtenemos la predicción del clasificador usando tanto variables numéricas como categóricas.\n","y_pred = clf_numeric.predict(X_train_num)\n","\n","# Calculamos la exactitud de la predicción.\n","acc = accuracy_score(y_train, y_pred)\n","\n","print(f'Exactitud en entrenamiento {acc}')\n","print(f'Error en entrenamiento: {1.0 - acc}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DG5qy3UlkoTe"},"source":["Como podemos ver, el error de entrenamiento es menor que el error de prueba."]},{"cell_type":"markdown","metadata":{"id":"T7AmsF16iGh8"},"source":["### **5.2. Clasificador variables numéricas y categóricas**\n","---\n","Veamos las métricas sobre la partición de entrenamiento:"]},{"cell_type":"code","metadata":{"id":"OcOhWrljiRIH"},"source":["y_pred = clf_full.predict(X_train_full)\n","acc = accuracy_score(y_train, y_pred)\n","\n","print(f'Exactitud en entrenamiento {acc}')\n","print(f'Error en entrenamiento: {1.0 - acc}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mk9UZCqPiKrq"},"source":["Veamos las métricas sobre la partición de prueba:"]},{"cell_type":"code","metadata":{"id":"i91cSzZn-rhh"},"source":["y_pred = clf_full.predict(X_test_full)\n","acc = accuracy_score(y_test, y_pred)\n","\n","print(f'Exactitud en prueba {acc}')\n","print(f'Error en prueba: {1.0 - acc}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yOvjRDpnOimw"},"source":["Cómo podemos ver incluir las variables categóricas mejora el desempeño del mismo algoritmo substancialmente.\n","\n","En *Titanic* un indicador de supervivencia muy importante es el género, una proporción mucho más grande de mujeres que de hombres sobrevivieron a la tragedia. Esto puede ser utilizado para interpretar la mejora de desempeño del modelo."]},{"cell_type":"markdown","metadata":{"id":"z67Vyq2ySfXu"},"source":["## **Recursos adicionales**\n","---\n","Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *Scikit-learn*:\n","\n","- [*Scikit-learn - Datasets*](https://scikit-learn.org/stable/datasets.html)\n","- [*Scikit-learn - Preprocessing*](https://scikit-learn.org/stable/modules/preprocessing.html)\n","- [*Scikit-learn - Linear models*](https://scikit-learn.org/stable/modules/linear_model.html)"]},{"cell_type":"markdown","metadata":{"id":"B4Zv4dF3ieMk"},"source":["## **Créditos**\n","---\n","\n","* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n","* **Asistentes docentes:**\n","  * Miguel Angel Ortiz Marín\n","  * Alberto Nicolai Romero Martínez\n","\n","**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"]}]}